{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jVKNjhdLFUQ"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/EmGarr/od.git\n",
    "# Useful for tensorboard\n",
    "!pip install --upgrade grpcio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CET-72i5EmKn"
   },
   "outputs": [],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ews_7qF9OBi8"
   },
   "source": [
    "# Download COCO/2017\n",
    "\n",
    "Download and preprocess COCO/2017 to the following format (required by od networks):\n",
    "\n",
    "```python\n",
    "dataset = {\n",
    "        'images' : A tensor of float32 and shape [1, height, widht, 3],\n",
    "        'images_info': A tensor of float32 and shape [1, 2] ,\n",
    "        'bbox': A tensor of float32 and shape [1, num_boxes, 4],\n",
    "        'labels': A tensor of int32 and shape [1, num_boxes],\n",
    "        'num_boxes': A tensor of int32 and shape [1, 1],\n",
    "        'weights': A tensor of float32 and shape [1, num_boxes]\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from od.dataset.preprocessing import resize_to_min_dim\n",
    "from od.core.standard_fields import DatasetField, BoxField\n",
    "from od.core.box_ops import compute_area\n",
    "\n",
    "def filter_crowded_boxes(boxes, crowd):\n",
    "    \"\"\"Coco has boxes flagged as crowded which are not used during the training.\n",
    "    This function will discard them.\n",
    "    \"\"\"\n",
    "    ind_uncrowded_boxes = tf.where(tf.equal(crowd, False))\n",
    "    return tf.gather_nd(boxes, ind_uncrowded_boxes)\n",
    "\n",
    "\n",
    "def filter_bad_area(boxes):\n",
    "    \"\"\"Few boxes have an area equal to 0 it will clean them\n",
    "    \"\"\"\n",
    "    area = compute_area(boxes)\n",
    "    return tf.gather_nd(boxes, tf.where(area > 0))\n",
    "\n",
    "\n",
    "def preprocess(inputs):\n",
    "    \"\"\"This operations performs a classical preprocessing operations for localization datasets:\n",
    "\n",
    "    - COCO\n",
    "    - Pascal Voc\n",
    "\n",
    "    You can download easily those dataset using [tensorflow dataset](https://www.tensorflow.org/datasets/catalog/overview).\n",
    "\n",
    "    Argument:\n",
    "\n",
    "    - *inputs*: It can be either a [FeaturesDict](https://www.tensorflow.org/datasets/api_docs/python/tfds/features/FeaturesDict) or a dict.\n",
    "    but it should have the following structures.\n",
    "\n",
    "    ```python\n",
    "    inputs = FeaturesDict({\n",
    "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
    "        'objects': Sequence({\n",
    "            'area': Tensor(shape=(), dtype=tf.int64), # area\n",
    "            'bbox': BBoxFeature(shape=(4,), dtype=tf.float32), # The values are between 0 and 1\n",
    "            'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=80),\n",
    "        }),\n",
    "    })\n",
    "    ```\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    - *inputs*:\n",
    "        1. image: A 3D tensor of float32 and shape [None, None, 3]\n",
    "        2. image_information: A 1D tensor of float32 and shape [(height, width),]. It contains the shape\n",
    "        of the image without any padding. It can be usefull if it followed by a `padded_batch` operations.\n",
    "        The models needs those information in order to clip the boxes to the proper dimension.\n",
    "    - *inputs*: A dict with the following information\n",
    "\n",
    "    ```\n",
    "    inputs = {\n",
    "        BoxField.BOXES: A tensor of shape [num_boxes, (y1, x1, y2, x2)] and resized to the image shape\n",
    "        BoxField.LABELS: A tensor of shape [num_boxes, ]\n",
    "        BoxField.NUM_BOXES: A tensor of shape (). It is usefull to unpad the data in case of a batched training\n",
    "    }\n",
    "    ```\n",
    "    \"\"\"\n",
    "    image = resize_to_min_dim(inputs['image'], 800.0, 1300.0)\n",
    "    image_information = tf.cast(tf.shape(image)[:2], dtype=tf.float32)\n",
    "    boxes = inputs['objects'][BoxField.BOXES] * tf.tile(tf.expand_dims(image_information, axis=0),\n",
    "                                                        [1, 2])\n",
    "    boxes = filter_crowded_boxes(boxes, inputs['objects']['is_crowd'])\n",
    "    boxes = filter_bad_area(boxes)\n",
    "    \n",
    "    return {\n",
    "        DatasetField.IMAGES: image,\n",
    "        DatasetField.IMAGES_INFO: image_information,\n",
    "        BoxField.BOXES: boxes,\n",
    "        BoxField.LABELS: inputs['objects'][BoxField.LABELS],\n",
    "        BoxField.NUM_BOXES: tf.shape(inputs['objects'][BoxField.LABELS]),\n",
    "        BoxField.WEIGHTS: tf.fill(tf.shape(inputs['objects'][BoxField.LABELS]), 1.0)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cC2k8osNGFw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from od.dataset.preprocessing import expand_dims_for_single_batch\n",
    "\n",
    "ds_train, ds_info = tfds.load(name=\"coco/2017\", split=\"train\", shuffle_files=True, with_info=True)\n",
    "ds_train = ds_train.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.map(expand_dims_for_single_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test = tfds.load(name=\"coco/2017\", split=\"validation\", shuffle_files=False)\n",
    "ds_test = ds_test.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.map(expand_dims_for_single_batch, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fip6g2i-B3pi"
   },
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tt34CM6P-gr"
   },
   "source": [
    "# Load and train the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r4o3t4PCLagO"
   },
   "outputs": [],
   "source": [
    "from od.model.faster_rcnn import build_fpn_resnet50_faster_rcnn\n",
    "from od.core.standard_fields import BoxField\n",
    "from od.core.learning_rate_schedule import WarmupLearningRateScheduler\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "# Number of classes of COCO\n",
    "classes = ds_info.features['objects']['label'].names\n",
    "num_classes = len(classes)\n",
    "batch_size = 1\n",
    "\n",
    "model_faster_rcnn = build_fpn_resnet50_faster_rcnn(num_classes, batch_size)\n",
    "base_lr = 0.02\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=base_lr)\n",
    "model_faster_rcnn.compile(optimizer=optimizer, loss=None)\n",
    "callbacks = [WarmupLearningRateScheduler(base_lr, 1, epochs=[8, 10], init_lr=0.0001), TensorBoard(), ModelCheckpoint('.checkpoints/')]\n",
    "\n",
    "model_faster_rcnn.fit(ds_train, validation_data=ds_test, epochs=11, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights for the serving\n",
    "model_faster_rcnn.save_weights('final_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CD14aaUMEudZ"
   },
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec4-mdjcR_wy"
   },
   "outputs": [],
   "source": [
    "# Load TENSORBOARD\n",
    "%load_ext tensorboard\n",
    "# Start TENSORBOARD\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export for inference\n",
    "\n",
    "When you are in training mode all the ground_truths are used as inputs:\n",
    "- BoxField.BOXES\n",
    "- BoxField.LABELS\n",
    "- BoxField.NUM_BOXES\n",
    "- BoxField.WEIGHTS\n",
    "\n",
    "We want to remove those for the serving.\n",
    "\n",
    "The first step is to rebuild the graph in inference mode. Reload the `final_weights.h5` and save using the save method from `tf.keras.Model`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from od.model.faster_rcnn import build_fpn_resnet50_faster_rcnn\n",
    "\n",
    "model_faster_rcnn_inference = build_fpn_resnet50_faster_rcnn(num_classes, None, training=False)\n",
    "model_faster_rcnn_inference.load_weights('final_weights.h5')\n",
    "model_faster_rcnn_inference.save('serving_model', include_optimizer=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pascal_voc_training_fpn50.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
