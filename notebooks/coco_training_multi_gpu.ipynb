{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with Faster RCNN and FPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/EmGarr/kerod.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_per_gpu = 2\n",
    "num_gpus = 8\n",
    "batch_size = batch_size_per_gpu * num_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and prepare COCO/2017\n",
    "\n",
    "Download and preprocess COCO/2017 to the following format (required by od networks):\n",
    "\n",
    "```python\n",
    "dataset = {\n",
    "        'images' : A tensor of float32 and shape [1, height, widht, 3],\n",
    "        'images_info': A tensor of float32 and shape [1, 2] ,\n",
    "        'bbox': A tensor of float32 and shape [1, num_boxes, 4],\n",
    "        'labels': A tensor of int32 and shape [1, num_boxes],\n",
    "        'num_boxes': A tensor of int32 and shape [1, 1],\n",
    "        'weights': A tensor of float32 and shape [1, num_boxes]\n",
    "    }\n",
    "```\n",
    "\n",
    "If you need to download the dataset in a specific directory you can use the argument `data_dir` of `tfds.load`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cC2k8osNGFw"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from kerod.core.standard_fields import BoxField, DatasetField\n",
    "from kerod.dataset.preprocessing import preprocess_coco_example\n",
    "import functools\n",
    "\n",
    "\n",
    "padded_shape = ({\n",
    "  DatasetField.IMAGES: [None, None, 3],\n",
    "  DatasetField.IMAGES_INFO: [2]\n",
    "},\n",
    "{\n",
    "  BoxField.BOXES: [None, 4],\n",
    "  BoxField.LABELS: [None],\n",
    "  BoxField.NUM_BOXES: [1],\n",
    "  BoxField.WEIGHTS: [None]\n",
    "})\n",
    "\n",
    "ds_train, ds_info = tfds.load(name=\"coco/2017\", split=\"train\", shuffle_files=True, with_info=True)\n",
    "ds_train = ds_train.map(functools.partial(preprocess_coco_example, bgr=True),\n",
    "                        num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# Filter example with no boxes after preprocessing\n",
    "ds_train =  ds_train.filter(lambda x, y: tf.shape(y[BoxField.BOXES])[0] > 1)\n",
    "ds_train =  ds_train.padded_batch(batch_size, padded_shape)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_val = tfds.load(name=\"coco/2017\", split=\"validation\", shuffle_files=False)\n",
    "ds_val = ds_val.map(functools.partial(preprocess_coco_example, horizontal_flip=False, bgr=True),\n",
    "                      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# Filter example with no boxes after preprocessing\n",
    "ds_val =  ds_val.filter(lambda x, y: tf.shape(y[BoxField.BOXES])[0] > 1)\n",
    "ds_val =  ds_val.padded_batch(batch_size, padded_shape)\n",
    "ds_val = ds_val.prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tt34CM6P-gr"
   },
   "source": [
    "# Load and train the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "colab_type": "code",
    "id": "r4o3t4PCLagO",
    "outputId": "3c2acc9f-eb93-452d-c7cf-6459e389ae1c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kerod.core.standard_fields import BoxField\n",
    "from kerod.core.learning_rate_schedule import LearningRateScheduler\n",
    "from kerod.model import factory\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "# Number of classes of COCO\n",
    "classes = ds_info.features['objects']['label'].names\n",
    "num_classes = len(classes)\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "with mirrored_strategy.scope(): \n",
    "    model = factory.build_model(num_classes)\n",
    "    base_lr = 0.02\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=base_lr)\n",
    "    model.compile(optimizer=optimizer, loss=None)\n",
    "  \n",
    "callbacks = [\n",
    "    LearningRateScheduler(base_lr, num_gpus, epochs=[8, 10]),\n",
    "    TensorBoard('log_tensorboard'),\n",
    "    ModelCheckpoint('checkpoints/')\n",
    "]\n",
    "\n",
    "history = model.fit(ds_train, validation_data=ds_val, epochs=12, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec4-mdjcR_wy"
   },
   "outputs": [],
   "source": [
    "model.save_weights('awesome_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export a saved model for serving purposes\n",
    "model.export_for_serving('serving')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coco evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = factory.build_model(num_classes)\n",
    "model.load_weights('awesome_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "ds_val, ds_info = tfds.load(name=\"coco/2017\", split=\"validation\", data_dir='dataset_tensorflow/', shuffle_files=False, with_info=True)\n",
    "# category_ids basicaly map the index 0 the id\n",
    "# e.g: 0 -> 1, 2 -> 3, 79 -> 90\n",
    "category_ids = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super dirty but the evaluation works\n",
    "\n",
    "####Â Perform the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from kerod.core.standard_fields import DatasetField, BoxField             \n",
    "from kerod.core.box_ops import convert_to_center_coordinates              \n",
    "from kerod.dataset.preprocessing import resize_to_min_dim                 \n",
    "                                                                       \n",
    "results = []                                                           \n",
    "                                                                       \n",
    "for i, example in enumerate(ds_val): \n",
    "    print(i)\n",
    "    # preprocess image \n",
    "    image = example['image'][:, :, ::-1]\n",
    "    image = resize_to_min_dim(image, 800.0, 1333.0)         \n",
    "    image_information = tf.cast(tf.shape(image)[:2], dtype=tf.float32) \n",
    "    inputs = {\n",
    "        'images': tf.expand_dims(image, axis=0),\n",
    "        'images_information':tf.expand_dims(image_information, axis=0)\n",
    "    }\n",
    "                                                                 \n",
    "    # predict                                                          \n",
    "    nmsed_boxes, nmsed_scores, nmsed_labels, valid_detections = model.predict_on_batch(inputs)\n",
    "                                                                       \n",
    "    # Post processing and append to coco results                       \n",
    "    bbox = nmsed_boxes[0] * tf.tile(tf.expand_dims(tf.cast(example['image'].shape[:2], tf.float32)                    \n",
    "        , axis=0), [1, 2])                   \n",
    "    scores = nmsed_scores[0]                                           \n",
    "    labels = nmsed_labels[0]                                           \n",
    "    for i in range(valid_detections[0]):\n",
    "        # Convert from [y_min, x_min, y_max, x_max] to coco format [x_min, y_min, w, h]\n",
    "        sbox = bbox[i].numpy()\n",
    "        sbox = [sbox[1], sbox[0], sbox[3] - sbox[1], sbox[2] - sbox[0]]\n",
    "        res = {                                                        \n",
    "                'image_id': int(example['image/id']),                       \n",
    "                'category_id': category_ids[int(labels[i])],           \n",
    "                'bbox': [round(float(c), 4) for c in sbox],\n",
    "                'score': round(float(scores[i]), 4),                     \n",
    "            }                                                          \n",
    "        results.append(res)                                            \n",
    "                                                   \n",
    "                                                                       \n",
    "with open('coco_results.json', 'w') as f:                              \n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the coco library to compute the performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip annotations_trainval2017.zip\n",
    "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "with open('coco_results.json', 'r') as f:                              \n",
    "    results = json.load(f)\n",
    "coco = COCO('./annotations/instances_val2017.json')\n",
    "ret = {}\n",
    "\n",
    "cocoDt = coco.loadRes(results)\n",
    "cocoEval = COCOeval(coco, cocoDt, 'bbox')\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "coco_training_multi_gpu.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
