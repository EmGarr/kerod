



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="shortcut icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-5.5.14">
    
    
      
        <title>Detr - kerod</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.d3202873.min.css">
      
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.ff0a5ce4.min.css">
      
      
        
        
        <meta name="theme-color" content="#4cae4f">
      
    
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="green" data-md-color-accent="lightgreen">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#module-kerodmodeldetr" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../../../.." title="kerod" class="md-header-nav__button md-logo" aria-label="kerod">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            kerod
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              Detr
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/EmGarr/kerod/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    kerod
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
        
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="kerod" class="md-nav__button md-logo" aria-label="kerod">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    kerod
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/EmGarr/kerod/" title="Go to repository" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    kerod
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../../../.." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../CONTRIBUTING/" title="Contributing" class="md-nav__link">
      Contributing
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../../../docs/BENCHMARKS/" title="Benchmarks" class="md-nav__link">
      Benchmarks
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4" checked>
    
    <label class="md-nav__link" for="nav-4">
      Reference
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Reference" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon"></span>
        Reference
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1" type="checkbox" id="nav-4-1" checked>
    
    <label class="md-nav__link" for="nav-4-1">
      Kerod
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Kerod" data-md-level="2">
      <label class="md-nav__title" for="nav-4-1">
        <span class="md-nav__icon md-icon"></span>
        Kerod
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1-2" type="checkbox" id="nav-4-1-2">
    
    <label class="md-nav__link" for="nav-4-1-2">
      Core
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Core" data-md-level="3">
      <label class="md-nav__title" for="nav-4-1-2">
        <span class="md-nav__icon md-icon"></span>
        Core
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/box_coder/" title="Box Coder" class="md-nav__link">
      Box Coder
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/box_ops/" title="Box Ops" class="md-nav__link">
      Box Ops
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/constants/" title="Constants" class="md-nav__link">
      Constants
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/learning_rate_schedule/" title="Learning Rate Schedule" class="md-nav__link">
      Learning Rate Schedule
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/losses/" title="Losses" class="md-nav__link">
      Losses
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/matcher/" title="Matcher" class="md-nav__link">
      Matcher
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/sampling_ops/" title="Sampling Ops" class="md-nav__link">
      Sampling Ops
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/similarity/" title="Similarity" class="md-nav__link">
      Similarity
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/standard_fields/" title="Standard Fields" class="md-nav__link">
      Standard Fields
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../core/target_assigner/" title="Target Assigner" class="md-nav__link">
      Target Assigner
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1-3" type="checkbox" id="nav-4-1-3">
    
    <label class="md-nav__link" for="nav-4-1-3">
      Dataset
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Dataset" data-md-level="3">
      <label class="md-nav__title" for="nav-4-1-3">
        <span class="md-nav__icon md-icon"></span>
        Dataset
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../dataset/augmentation/" title="Augmentation" class="md-nav__link">
      Augmentation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../dataset/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../dataset/preprocessing/" title="Preprocessing" class="md-nav__link">
      Preprocessing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../dataset/utils/" title="Utils" class="md-nav__link">
      Utils
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1-4" type="checkbox" id="nav-4-1-4" checked>
    
    <label class="md-nav__link" for="nav-4-1-4">
      Model
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Model" data-md-level="3">
      <label class="md-nav__title" for="nav-4-1-4">
        <span class="md-nav__icon md-icon"></span>
        Model
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Detr
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="./" title="Detr" class="md-nav__link md-nav__link--active">
      Detr
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#functions" class="md-nav__link">
    Functions
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compute_detr_metrics" class="md-nav__link">
    compute_detr_metrics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#detr" class="md-nav__link">
    DeTr
  </a>
  
    <nav class="md-nav" aria-label="DeTr">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attributes" class="md-nav__link">
    Attributes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_config" class="md-nav__link">
    from_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with_name_scope" class="md-nav__link">
    with_name_scope
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../factory/" title="Factory" class="md-nav__link">
      Factory
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../faster_rcnn/" title="Faster Rcnn" class="md-nav__link">
      Faster Rcnn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../smca_detr/" title="Smca Detr" class="md-nav__link">
      Smca Detr
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1-4-6" type="checkbox" id="nav-4-1-4-6">
    
    <label class="md-nav__link" for="nav-4-1-4-6">
      Backbone
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Backbone" data-md-level="4">
      <label class="md-nav__title" for="nav-4-1-4-6">
        <span class="md-nav__icon md-icon"></span>
        Backbone
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../backbone/fpn/" title="Fpn" class="md-nav__link">
      Fpn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../backbone/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../backbone/resnet/" title="Resnet" class="md-nav__link">
      Resnet
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1-4-7" type="checkbox" id="nav-4-1-4-7">
    
    <label class="md-nav__link" for="nav-4-1-4-7">
      Detection
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Detection" data-md-level="4">
      <label class="md-nav__title" for="nav-4-1-4-7">
        <span class="md-nav__icon md-icon"></span>
        Detection
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../detection/abstract_detection_head/" title="Abstract Detection Head" class="md-nav__link">
      Abstract Detection Head
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../detection/fast_rcnn/" title="Fast Rcnn" class="md-nav__link">
      Fast Rcnn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../detection/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../detection/pooling_ops/" title="Pooling Ops" class="md-nav__link">
      Pooling Ops
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../detection/rpn/" title="Rpn" class="md-nav__link">
      Rpn
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1-4-8" type="checkbox" id="nav-4-1-4-8">
    
    <label class="md-nav__link" for="nav-4-1-4-8">
      Layers
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Layers" data-md-level="4">
      <label class="md-nav__title" for="nav-4-1-4-8">
        <span class="md-nav__icon md-icon"></span>
        Layers
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../layers/anchors/" title="Anchors" class="md-nav__link">
      Anchors
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../layers/attentions/" title="Attentions" class="md-nav__link">
      Attentions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../layers/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../layers/positional_encoding/" title="Positional Encoding" class="md-nav__link">
      Positional Encoding
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../layers/transformer/" title="Transformer" class="md-nav__link">
      Transformer
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1-4-8-6" type="checkbox" id="nav-4-1-4-8-6">
    
    <label class="md-nav__link" for="nav-4-1-4-8-6">
      Smca
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Smca" data-md-level="5">
      <label class="md-nav__title" for="nav-4-1-4-8-6">
        <span class="md-nav__icon md-icon"></span>
        Smca
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../layers/smca/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../layers/smca/reference_points/" title="Reference Points" class="md-nav__link">
      Reference Points
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../layers/smca/weight_map/" title="Weight Map" class="md-nav__link">
      Weight Map
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1-4-9" type="checkbox" id="nav-4-1-4-9">
    
    <label class="md-nav__link" for="nav-4-1-4-9">
      Post Processing
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Post Processing" data-md-level="4">
      <label class="md-nav__title" for="nav-4-1-4-9">
        <span class="md-nav__icon md-icon"></span>
        Post Processing
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../post_processing/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../post_processing/non_maximum_suppression/" title="Non Maximum Suppression" class="md-nav__link">
      Non Maximum Suppression
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../post_processing/post_processing_detr/" title="Post Processing Detr" class="md-nav__link">
      Post Processing Detr
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
          
          
          


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4-1-5" type="checkbox" id="nav-4-1-5">
    
    <label class="md-nav__link" for="nav-4-1-5">
      Utils
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Utils" data-md-level="3">
      <label class="md-nav__title" for="nav-4-1-5">
        <span class="md-nav__icon md-icon"></span>
        Utils
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../utils/drawing/" title="Drawing" class="md-nav__link">
      Drawing
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../utils/" title="Index" class="md-nav__link">
      Index
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../utils/ops/" title="Ops" class="md-nav__link">
      Ops
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../utils/training/" title="Training" class="md-nav__link">
      Training
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#functions" class="md-nav__link">
    Functions
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compute_detr_metrics" class="md-nav__link">
    compute_detr_metrics
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#classes" class="md-nav__link">
    Classes
  </a>
  
    <nav class="md-nav" aria-label="Classes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#detr" class="md-nav__link">
    DeTr
  </a>
  
    <nav class="md-nav" aria-label="DeTr">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#attributes" class="md-nav__link">
    Attributes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ancestors-in-mro" class="md-nav__link">
    Ancestors (in MRO)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#descendants" class="md-nav__link">
    Descendants
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#static-methods" class="md-nav__link">
    Static methods
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from_config" class="md-nav__link">
    from_config
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with_name_scope" class="md-nav__link">
    with_name_scope
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#instance-variables" class="md-nav__link">
    Instance variables
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/EmGarr/kerod/edit/master/reference/kerod/model/detr.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  
                
                
                <h1 id="module-kerodmodeldetr">Module kerod.model.detr</h1>
<p>None</p>
<p>None</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

<span class="kn">from</span> <span class="nn">kerod.core.box_ops</span> <span class="kn">import</span> <span class="p">(</span><span class="n">convert_to_center_coordinates</span><span class="p">,</span> <span class="n">convert_to_xyxy_coordinates</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">kerod.core.losses</span> <span class="kn">import</span> <span class="n">L1Loss</span>

<span class="kn">from</span> <span class="nn">kerod.core.matcher</span> <span class="kn">import</span> <span class="n">hungarian_matching</span>

<span class="kn">from</span> <span class="nn">kerod.core.similarity</span> <span class="kn">import</span> <span class="n">DetrSimilarity</span>

<span class="kn">from</span> <span class="nn">kerod.core.standard_fields</span> <span class="kn">import</span> <span class="n">BoxField</span><span class="p">,</span> <span class="n">DatasetField</span>

<span class="kn">from</span> <span class="nn">kerod.core.target_assigner</span> <span class="kn">import</span> <span class="n">TargetAssigner</span>

<span class="kn">from</span> <span class="nn">kerod.model.backbone.resnet</span> <span class="kn">import</span> <span class="n">ResNet50</span><span class="p">,</span> <span class="n">ResNet50PytorchStyle</span>

<span class="kn">from</span> <span class="nn">kerod.model.layers</span> <span class="kn">import</span> <span class="n">PositionEmbeddingSine</span><span class="p">,</span> <span class="n">Transformer</span>

<span class="kn">from</span> <span class="nn">kerod.model.post_processing.post_processing_detr</span> <span class="kn">import</span> \

    <span class="n">post_processing</span> <span class="k">as</span> <span class="n">detr_postprocessing</span>

<span class="kn">from</span> <span class="nn">kerod.utils</span> <span class="kn">import</span> <span class="n">item_assignment</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.losses</span> <span class="kn">import</span> <span class="n">SparseCategoricalCrossentropy</span>

<span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="kn">import</span> <span class="n">data_adapter</span>

<span class="kn">from</span> <span class="nn">tensorflow_addons.losses.giou_loss</span> <span class="kn">import</span> <span class="n">GIoULoss</span>

<span class="k">class</span> <span class="nc">DeTr</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Build a DeTr model according to the paper</span>

<span class="sd">    [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)</span>

<span class="sd">    You can use it as follow:</span>

<span class="sd">    ```python</span>

<span class="sd">    model = DeTrResnet50Pytorch(80)</span>

<span class="sd">    base_lr = 0.1</span>

<span class="sd">    optimizer = tf.keras.optimizers.SGD(learning_rate=base_lr)</span>

<span class="sd">    model.compile(optimizer=optimizer, loss=None)</span>

<span class="sd">    model.fit(ds_train, validation_data=ds_test, epochs=11,)</span>

<span class="sd">    ```</span>

<span class="sd">    Arguments:</span>

<span class="sd">        num_classes: The number of classes of your dataset</span>

<span class="sd">            (**do not include the background class** it is handle for you)</span>

<span class="sd">        backbone: A vision model like ResNet50.</span>

<span class="sd">        num_queries: number of object queries, ie detection slot.</span>

<span class="sd">            This is the maximal number of objects</span>

<span class="sd">            DETR can detect in a single image. For COCO, we recommend 100 queries.</span>

<span class="sd">    Call arguments:</span>

<span class="sd">        inputs: Tuple</span>

<span class="sd">            1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</span>

<span class="sd">            2. image_informations: A 1D tensor of float32 and shape [(height, width),].</span>

<span class="sd">                It contains the shape of the image without any padding.</span>

<span class="sd">            3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None]</span>

<span class="sd">                composed of 0 and 1 which allows to know where a padding has been applied.</span>

<span class="sd">        training: Is automatically set to `True` in train mode</span>

<span class="sd">    Call returns:</span>

<span class="sd">        logits: A Tensor of shape [batch_size, h, num_classes + 1] class logits</span>

<span class="sd">        boxes: A Tensor of shape [batch_size, h, 4]</span>

<span class="sd">    where h is num_queries * transformer_decoder.transformer_num_layers if</span>

<span class="sd">    training is true and num_queries otherwise.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">backbone</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">num_classes</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_queries</span> <span class="o">=</span> <span class="n">num_queries</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">256</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span> <span class="o">=</span> <span class="n">backbone</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_proj</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span> <span class="o">=</span> <span class="n">PositionEmbeddingSine</span><span class="p">(</span><span class="n">output_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_num_layers</span> <span class="o">=</span> <span class="mi">6</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span> <span class="o">=</span> <span class="n">Transformer</span><span class="p">(</span><span class="n">num_layers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_num_layers</span><span class="p">,</span>

                                       <span class="n">d_model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span>

                                       <span class="n">num_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>

                                       <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">2048</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># (x1, y1, x2, y2)</span>

        <span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">class_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="c1"># Will create a learnable embedding matrix for all our queries</span>

        <span class="c1"># It is a matrix of [num_queries, self.hidden_dim]</span>

        <span class="c1"># The embedding layers</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">query_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_queries</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">all_the_queries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">num_queries</span><span class="p">)</span>

        <span class="c1"># Loss computation</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weight_class</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_l1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_giou</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span>

        <span class="n">similarity_func</span> <span class="o">=</span> <span class="n">DetrSimilarity</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_class</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_l1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_giou</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">target_assigner</span> <span class="o">=</span> <span class="n">TargetAssigner</span><span class="p">(</span><span class="n">similarity_func</span><span class="p">,</span>

                                              <span class="n">hungarian_matching</span><span class="p">,</span>

                                              <span class="k">lambda</span> <span class="n">gt</span><span class="p">,</span> <span class="n">pred</span><span class="p">:</span> <span class="n">gt</span><span class="p">,</span>

                                              <span class="n">negative_class_weight</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

        <span class="c1"># Relative classification weight applied to the no-object category</span>

        <span class="c1"># It down-weight the log-probability term of a no-object</span>

        <span class="c1"># by a factor 10 to account for class imbalance</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">non_object_weight</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span>

        <span class="c1"># Losses</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">giou</span> <span class="o">=</span> <span class="n">GIoULoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">L1Loss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scc</span> <span class="o">=</span> <span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span>

                                                 <span class="n">from_logits</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="c1"># Metrics</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">giou_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;giou_last_layer&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">l1_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;l1_last_layer&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">scc_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;scc_last_layer&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">precision_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()</span>

        <span class="c1"># Object recall = foreground</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">recall_metric</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;object_recall&quot;</span><span class="p">)</span>

    <span class="nd">@property</span>

    <span class="k">def</span> <span class="nf">metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

        <span class="k">return</span> <span class="p">[</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">giou_metric</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1_metric</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scc_metric</span><span class="p">,</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">precision_metric</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">recall_metric</span>

        <span class="p">]</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Perform an inference in training.</span>

<span class="sd">        Arguments:</span>

<span class="sd">        - *inputs*: Tuple</span>

<span class="sd">            1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</span>

<span class="sd">            2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape</span>

<span class="sd">            of the image without any padding.</span>

<span class="sd">            3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None] composed of 0 and 1 which allows to know where a padding has been applied.</span>

<span class="sd">        - *training*: Is automatically set to `True` in train mode</span>

<span class="sd">        Returns:</span>

<span class="sd">        - *logits*: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="sd">        - *boxes*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="sd">        where h is num_queries * transformer_decoder.transformer_num_layers if</span>

<span class="sd">        training is true and num_queries otherwise.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">images</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">]</span>

        <span class="n">images_padding_masks</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES_PMASK</span><span class="p">]</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">images</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># The preprocessing dedicated to the backbone is done inside the model.</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">images</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">images_padding_masks</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>

                                        <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span>

                                        <span class="n">method</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">image</span><span class="o">.</span><span class="n">ResizeMethod</span><span class="o">.</span><span class="n">NEAREST_NEIGHBOR</span><span class="p">)</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>

        <span class="c1"># Positional_encoding for the backbone</span>

        <span class="n">pos_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_embed</span><span class="p">(</span><span class="n">features_mask</span><span class="p">)</span>

        <span class="c1"># [batch_size, num_queries, self.hidden_dim]</span>

        <span class="n">all_the_queries</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">all_the_queries</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># [batch_size, num_queries, self.hidden_dim]</span>

        <span class="n">query_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">query_embed</span><span class="p">(</span><span class="n">all_the_queries</span><span class="p">)</span>

        <span class="c1"># add positional_encoding to x [batch_size, h, w, self.hidden_dim]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Flatten the position embedding and the spatial tensor</span>

        <span class="c1"># to allow the preprocessing by the Transformer</span>

        <span class="c1"># [batch_size, h * w,  self.hidden_dim]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="c1"># Flatten the padding masks</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">decoder_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>

                                          <span class="n">pos_embed</span><span class="p">,</span>

                                          <span class="n">query_embed</span><span class="p">,</span>

                                          <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">features_mask</span><span class="p">,</span>

                                          <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="n">boxes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">:</span> <span class="n">logits</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">:</span> <span class="n">boxes</span><span class="p">,</span>

        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span>

        <span class="bp">self</span><span class="p">,</span>

        <span class="n">ground_truths</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>

        <span class="n">y_pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>

        <span class="n">input_shape</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>

    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>

        <span class="sd">&quot;&quot;&quot;Apply the GIoU, L1 and SCC to each layers of the transformer decoder</span>

<span class="sd">        Arguments:</span>

<span class="sd">        - *ground_truths*:</span>

<span class="sd">           see output kerod.dataset.preprocessing for the doc</span>

<span class="sd">        - *y_pred*: A dict</span>

<span class="sd">            - *scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="sd">            - *bbox*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="sd">        - *input_shape*: [height, width] of the input tensor. It is the shape of the images will all the</span>

<span class="sd">        padding included. It is used to normalize the ground_truths boxes.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">normalized_boxes</span> <span class="o">=</span> <span class="n">ground_truths</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">]</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="bp">None</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

        <span class="n">centered_normalized_boxes</span> <span class="o">=</span> <span class="n">convert_to_center_coordinates</span><span class="p">(</span><span class="n">normalized_boxes</span><span class="p">)</span>

        <span class="n">ground_truths</span> <span class="o">=</span> <span class="p">{</span>

            <span class="c1"># We add one because the background is not counted in ground_truths [BoxField.LABELS]</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">:</span>

                <span class="n">ground_truths</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">:</span>

                <span class="n">centered_normalized_boxes</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">WEIGHTS</span><span class="p">:</span>

                <span class="n">ground_truths</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">WEIGHTS</span><span class="p">],</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">NUM_BOXES</span><span class="p">:</span>

                <span class="n">ground_truths</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">NUM_BOXES</span><span class="p">]</span>

        <span class="p">}</span>

        <span class="n">boxes_per_lvl</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_num_layers</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">logits_per_lvl</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_num_layers</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">y_pred_per_lvl</span> <span class="o">=</span> <span class="p">[{</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">:</span> <span class="n">boxes</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">:</span> <span class="n">logits</span>

        <span class="p">}</span> <span class="k">for</span> <span class="n">boxes</span><span class="p">,</span> <span class="n">logits</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">boxes_per_lvl</span><span class="p">,</span> <span class="n">logits_per_lvl</span><span class="p">)]</span>

        <span class="n">num_boxes</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">NUM_BOXES</span><span class="p">]),</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Compute the Giou, L1 and SCC at each layers of the transformer decoder</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">y_pred</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y_pred_per_lvl</span><span class="p">):</span>

            <span class="c1"># Logs the metrics for the last layer of the decoder</span>

            <span class="n">compute_metrics</span> <span class="o">=</span> <span class="n">i</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_num_layers</span> <span class="o">-</span> <span class="mi">1</span>

            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span>

                                       <span class="n">ground_truths</span><span class="p">,</span>

                                       <span class="n">num_boxes</span><span class="p">,</span>

                                       <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss</span>

    <span class="k">def</span> <span class="nf">_compute_loss</span><span class="p">(</span>

        <span class="bp">self</span><span class="p">,</span>

        <span class="n">y_pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>

        <span class="n">ground_truths</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>

        <span class="n">num_boxes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>

        <span class="n">compute_metrics</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>

    <span class="p">):</span>

        <span class="n">y_true</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_assigner</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">)</span>

        <span class="c1"># Reduce the class imbalanced by applying to the weights</span>

        <span class="c1"># self.non_object_weight for the non object (pos 0)</span>

        <span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">]</span> <span class="o">=</span> <span class="n">item_assignment</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">],</span>

                                                   <span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>

                                                   <span class="bp">self</span><span class="o">.</span><span class="n">non_object_weight</span><span class="p">)</span>

        <span class="c1"># Caveats GIoU is buggy and if the batch_size is 1 and the sample_weight</span>

        <span class="c1"># is provided will raise an error</span>

        <span class="n">giou</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">giou</span><span class="p">(</span><span class="n">convert_to_xyxy_coordinates</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">]),</span>

                         <span class="n">convert_to_xyxy_coordinates</span><span class="p">(</span><span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">]),</span>

                         <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">])</span>

        <span class="n">l1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">],</span>

                     <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">],</span>

                     <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">])</span>

        <span class="c1"># SparseCategoricalCrossentropy</span>

        <span class="n">scc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scc</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">],</span>

                       <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">],</span>

                       <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">])</span>

        <span class="n">giou</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_giou</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">giou</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_boxes</span>

        <span class="n">l1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_l1</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">l1</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_boxes</span>

        <span class="n">scc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_class</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">scc</span><span class="p">)</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">compute_metrics</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">giou_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">giou</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">l1_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">l1</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">scc_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">scc</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">precision_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">],</span>

                                               <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">],</span>

                                               <span class="n">sample_weight</span><span class="o">=</span><span class="n">weights</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">])</span>

            <span class="n">recall</span> <span class="o">=</span> <span class="n">compute_detr_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">LABELS</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">])</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">recall_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">recall</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">giou</span> <span class="o">+</span> <span class="n">l1</span> <span class="o">+</span> <span class="n">scc</span>

    <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>

            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

            <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span> <span class="n">tape</span><span class="o">=</span><span class="n">tape</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># To compute the loss we need to get the results of each decoder layer</span>

        <span class="c1"># Setting training to True will provide it</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="sd">&quot;&quot;&quot;Perform an inference and returns the boxes, scores and labels associated.</span>

<span class="sd">        Background is discarded the max and argmax operation are performed.</span>

<span class="sd">        It means that if background was predicted the second maximum score would</span>

<span class="sd">        be outputed.</span>

<span class="sd">        Example: background + 3 classes</span>

<span class="sd">        [0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</span>

<span class="sd">        &quot;To optimize for AP, we override the prediction of these slots</span>

<span class="sd">        with the second highest scoring class, using the corresponding confidence&quot;</span>

<span class="sd">        Part 4. Experiments of Object Detection with Transformers</span>

<span class="sd">        Returns:</span>

<span class="sd">        - *boxes*: A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]</span>

<span class="sd">        containing the boxes with the coordinates between 0 and 1.</span>

<span class="sd">        - *scores*: A Tensor of shape [batch_size, self.num_queries] containing</span>

<span class="sd">        the score of the boxes.</span>

<span class="sd">        - *classes*: A Tensor of shape [batch_size, self.num_queries]</span>

<span class="sd">        containing the class of the boxes [0, num_classes).</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

        <span class="n">boxes_without_padding</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">detr_postprocessing</span><span class="p">(</span>

            <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">BOXES</span><span class="p">],</span>

            <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="o">.</span><span class="n">SCORES</span><span class="p">],</span>

            <span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES_INFO</span><span class="p">],</span>

            <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span>

        <span class="p">)</span>

        <span class="k">return</span> <span class="n">boxes_without_padding</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span>

<span class="k">class</span> <span class="nc">DeTrResnet50</span><span class="p">(</span><span class="n">DeTr</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">resnet</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="n">num_queries</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DeTrResnet50Pytorch</span><span class="p">(</span><span class="n">DeTr</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

        <span class="n">resnet</span> <span class="o">=</span> <span class="n">ResNet50PytorchStyle</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">resnet</span><span class="p">,</span> <span class="n">num_queries</span><span class="o">=</span><span class="n">num_queries</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_detr_metrics</span><span class="p">(</span><span class="n">y_true</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Useful metrics that allows to track how behave the training.</span>

<span class="sd">    Arguments:</span>

<span class="sd">    - *y_true*: A one-hot encoded vector with shape [batch_size, num_object_queries, num_classes]</span>

<span class="sd">    - *y_pred*: A tensor with shape [batch_size, num_object_queries, num_classes],</span>

<span class="sd">    representing the classification logits.</span>

<span class="sd">    Returns:</span>

<span class="sd">    - *recall*: Among all the boxes that we had to find how much did we found.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1">#Even if the softmax has not been applyed the argmax can be usefull</span>

    <span class="n">prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;label_prediction&#39;</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">correct</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">prediction</span> <span class="o">==</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Compute accuracy and false negative on all the foreground boxes</span>

    <span class="n">fg_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_true</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

    <span class="n">recall</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="n">fg_inds</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;recall&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">recall</span>
</code></pre></div>

</details>
<h2 id="functions">Functions</h2>
<h3 id="compute_detr_metrics">compute_detr_metrics</h3>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_detr_metrics</span><span class="p">(</span>
    <span class="n">y_true</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span>
</code></pre></div>

<p>Useful metrics that allows to track how behave the training.</p>
<p>Arguments:</p>
<ul>
<li><em>y_true</em>: A one-hot encoded vector with shape [batch_size, num_object_queries, num_classes]</li>
<li><em>y_pred</em>: A tensor with shape [batch_size, num_object_queries, num_classes],
representing the classification logits.</li>
</ul>
<p>Returns:</p>
<ul>
<li><em>recall</em>: Among all the boxes that we had to find how much did we found.</li>
</ul>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="n">def</span> <span class="n">compute_detr_metrics</span><span class="p">(</span><span class="nl">y_true:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nl">y_pred:</span> <span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">)</span><span class="o">:</span>

    <span class="s">&quot;&quot;&quot;Useful metrics that allows to track how behave the training.</span>

    <span class="nl">Arguments:</span>

    <span class="o">-</span> <span class="o">*</span><span class="n">y_true</span><span class="o">*:</span> <span class="n">A</span> <span class="n">one</span><span class="o">-</span><span class="n">hot</span> <span class="n">encoded</span> <span class="n">vector</span> <span class="n">with</span> <span class="n">shape</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_object_queries</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">]</span>

    <span class="o">-</span> <span class="o">*</span><span class="n">y_pred</span><span class="o">*:</span> <span class="n">A</span> <span class="n">tensor</span> <span class="n">with</span> <span class="n">shape</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_object_queries</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">],</span>

    <span class="n">representing</span> <span class="n">the</span> <span class="n">classification</span> <span class="n">logits</span><span class="p">.</span>

    <span class="nl">Returns:</span>

    <span class="o">-</span> <span class="o">*</span><span class="n">recall</span><span class="o">*:</span> <span class="n">Among</span> <span class="n">all</span> <span class="n">the</span> <span class="n">boxes</span> <span class="n">that</span> <span class="n">we</span> <span class="n">had</span> <span class="n">to</span> <span class="n">find</span> <span class="n">how</span> <span class="n">much</span> <span class="n">did</span> <span class="n">we</span> <span class="n">found</span><span class="p">.</span>

    <span class="s">&quot;&quot;&quot;</span>

    <span class="p">#</span><span class="n">Even</span> <span class="k">if</span> <span class="n">the</span> <span class="n">softmax</span> <span class="n">has</span> <span class="k">not</span> <span class="n">been</span> <span class="n">applyed</span> <span class="n">the</span> <span class="n">argmax</span> <span class="n">can</span> <span class="n">be</span> <span class="n">usefull</span>

    <span class="n">prediction</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mh">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="p">&#39;</span><span class="n">label_prediction</span><span class="p">&#39;,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">correct</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">prediction</span> <span class="o">==</span> <span class="n">y_true</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="p">#</span> <span class="n">Compute</span> <span class="n">accuracy</span> <span class="k">and</span> <span class="n">false</span> <span class="n">negative</span> <span class="n">on</span> <span class="n">all</span> <span class="n">the</span> <span class="n">foreground</span> <span class="n">boxes</span>

    <span class="n">fg_inds</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_true</span> <span class="o">&gt;</span> <span class="mh">0</span><span class="p">)</span>

    <span class="n">recall</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">gather_nd</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="n">fg_inds</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="p">&#39;</span><span class="n">recall</span><span class="p">&#39;)</span>

    <span class="k">return</span> <span class="n">recall</span>
</code></pre></div>

</details>
<h2 id="classes">Classes</h2>
<h3 id="detr">DeTr</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">DeTr</span><span class="p">(</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">backbone</span><span class="p">,</span>
    <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<h4 id="attributes">Attributes</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>num_classes</td>
<td>None</td>
<td>The number of classes of your dataset</td>
<td></td>
</tr>
<tr>
<td>(<strong>do not include the background class</strong> it is handle for you)</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>backbone</td>
<td>None</td>
<td>A vision model like ResNet50.</td>
<td>None</td>
</tr>
<tr>
<td>num_queries</td>
<td>None</td>
<td>number of object queries, ie detection slot.</td>
<td></td>
</tr>
<tr>
<td>This is the maximal number of objects</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>DETR can detect in a single image. For COCO, we recommend 100 queries.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Call arguments: | None |
| inputs | None | Tuple
1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]
2. image_informations: A 1D tensor of float32 and shape [(height, width),].
    It contains the shape of the image without any padding.
3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None]
    composed of 0 and 1 which allows to know where a padding has been applied. | None |
| training | None | Is automatically set to <code>True</code> in train mode
Call returns: | None |
| logits | None | A Tensor of shape [batch_size, h, num_classes + 1] class logits | None |
| boxes | None | A Tensor of shape [batch_size, h, 4]
where h is num_queries * transformer_decoder.transformer_num_layers if
training is true and num_queries otherwise. | None |</p>
<h4 id="ancestors-in-mro">Ancestors (in MRO)</h4>
<ul>
<li>tensorflow.python.keras.engine.training.Model</li>
<li>tensorflow.python.keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>tensorflow.python.keras.utils.version_utils.LayerVersionSelector</li>
<li>tensorflow.python.keras.utils.version_utils.ModelVersionSelector</li>
</ul>
<h4 id="descendants">Descendants</h4>
<ul>
<li>kerod.model.detr.DeTrResnet50</li>
<li>kerod.model.detr.DeTrResnet50Pytorch</li>
</ul>
<h4 id="static-methods">Static methods</h4>
<h4 id="from_config">from_config</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span>
    <span class="n">config</span><span class="p">,</span>
    <span class="n">custom_objects</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a layer from its config.</p>
<p>This method is the reverse of <code>get_config</code>,
capable of instantiating the same layer from the config
dictionary. It does not handle layer connectivity
(handled by Network), nor weights (handled by <code>set_weights</code>).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>config</td>
<td>None</td>
<td>A Python dictionary, typically the</td>
<td></td>
</tr>
<tr>
<td>output of get_config.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nd">@classmethod</span>

  <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

    <span class="c1"># Since only FunctionalModel produces config, the model can only</span>

    <span class="c1"># be constructed for FunctionalModel</span>

    <span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="kn">import</span> <span class="n">functional</span>  <span class="c1"># pylint: disable=g-import-not-at-top</span>

    <span class="k">return</span> <span class="n">functional</span><span class="o">.</span><span class="n">Functional</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span>

        <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">custom_objects</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="with_name_scope">with_name_scope</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">with_name_scope</span><span class="p">(</span>
    <span class="n">method</span>
<span class="p">)</span>
</code></pre></div>

<p>Decorator to automatically enter the module name scope.</p>
<blockquote>
<blockquote>
<blockquote>
<p>class MyModule(tf.Module):
...   @tf.Module.with_name_scope
...   def <strong>call</strong>(self, x):
...     if not hasattr(self, 'w'):
...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))
...     return tf.matmul(x, self.w)</p>
</blockquote>
</blockquote>
</blockquote>
<p>Using the above module would produce <code>tf.Variable</code>s and <code>tf.Tensor</code>s whose
names included the module name:</p>
<blockquote>
<blockquote>
<blockquote>
<p>mod = MyModule()
mod(tf.ones([1, 2]))
<tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>
mod.w
<tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,
numpy=..., dtype=float32)></p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>method</td>
<td>None</td>
<td>The method to wrap.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The original method wrapped such that it enters the module's name scope.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@classmethod</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">with_name_scope</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span><span class="w"> </span><span class="k">method</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Decorator to automatically enter the module name scope.</span>

<span class="ss">    &gt;&gt;&gt; class MyModule(tf.Module):</span>

<span class="ss">    ...   @tf.Module.with_name_scope</span>

<span class="ss">    ...   def __call__(self, x):</span>

<span class="ss">    ...     if not hasattr(self, &#39;w&#39;):</span>

<span class="ss">    ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))</span>

<span class="ss">    ...     return tf.matmul(x, self.w)</span>

<span class="ss">    Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose</span>

<span class="ss">    names included the module name:</span>

<span class="ss">    &gt;&gt;&gt; mod = MyModule()</span>

<span class="ss">    &gt;&gt;&gt; mod(tf.ones([1, 2]))</span>

<span class="ss">    &lt;tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)&gt;</span>

<span class="ss">    &gt;&gt;&gt; mod.w</span>

<span class="ss">    &lt;tf.Variable &#39;my_module/Variable:0&#39; shape=(2, 3) dtype=float32,</span>

<span class="ss">    numpy=..., dtype=float32)&gt;</span>

<span class="ss">    Args:</span>

<span class="ss">      method: The method to wrap.</span>

<span class="ss">    Returns:</span>

<span class="ss">      The original method wrapped such that it enters the module&#39;s name scope.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">method_with_name_scope</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">name_scope</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">method</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tf_decorator</span><span class="p">.</span><span class="n">make_decorator</span><span class="p">(</span><span class="k">method</span><span class="p">,</span><span class="w"> </span><span class="n">method_with_name_scope</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="instance-variables">Instance variables</h4>
<div class="codehilite"><pre><span></span><code><span class="n">activity_regularizer</span>
</code></pre></div>

<p>Optional regularizer function for the output of this layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">compute_dtype</span>
</code></pre></div>

<p>The dtype of the layer's computations.</p>
<p>This is equivalent to <code>Layer.dtype_policy.compute_dtype</code>. Unless
mixed precision is used, this is the same as <code>Layer.dtype</code>, the dtype of
the weights.</p>
<p>Layers automatically cast their inputs to the compute dtype, which causes
computations and the output to be in the compute dtype as well. This is done
by the base Layer class in <code>Layer.__call__</code>, so you do not have to insert
these casts if implementing your own layer.</p>
<p>Layers often perform certain internal computations in higher precision when
<code>compute_dtype</code> is float16 or bfloat16 for numeric stability. The output
will still typically be float16 or bfloat16 in such cases.</p>
<div class="codehilite"><pre><span></span><code><span class="n">distribute_strategy</span>
</code></pre></div>

<p>The <code>tf.distribute.Strategy</code> this model was created under.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dtype</span>
</code></pre></div>

<p>The dtype of the layer weights.</p>
<p>This is equivalent to <code>Layer.dtype_policy.variable_dtype</code>. Unless
mixed precision is used, this is the same as <code>Layer.compute_dtype</code>, the
dtype of the layer's computations.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dtype_policy</span>
</code></pre></div>

<p>The dtype policy associated with this layer.</p>
<p>This is an instance of a <code>tf.keras.mixed_precision.Policy</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dynamic</span>
</code></pre></div>

<p>Whether the layer is dynamic (eager-only); set in the constructor.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inbound_nodes</span>
</code></pre></div>

<p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>
<div class="codehilite"><pre><span></span><code><span class="nb">input</span>
</code></pre></div>

<p>Retrieves the input tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_mask</span>
</code></pre></div>

<p>Retrieves the input mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>
<p>Returns:
    Input mask tensor (potentially None) or list of input
    mask tensors.</p>
<p>Raises:
    AttributeError: if the layer is connected to
    more than one incoming layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_shape</span>
</code></pre></div>

<p>Retrieves the input shape(s) of a layer.</p>
<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer, or if all inputs
have the same shape.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_spec</span>
</code></pre></div>

<p><code>InputSpec</code> instance(s) describing the input format for this layer.</p>
<p>When you create a layer subclass, you can set <code>self.input_spec</code> to enable
the layer to run input compatibility checks when it is called.
Consider a <code>Conv2D</code> layer: it can only be called on a single input tensor
of rank 4. As such, you can set, in <code>__init__()</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputSpec</span><span class="p">(</span><span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div>

<p>Now, if you try to call the layer on an input that isn't rank 4
(for instance, an input of shape <code>(2,)</code>, it will raise a nicely-formatted
error:</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span> <span class="n">Input</span> <span class="mi">0</span> <span class="n">of</span> <span class="n">layer</span> <span class="n">conv2d</span> <span class="k">is</span> <span class="n">incompatible</span> <span class="k">with</span> <span class="n">the</span> <span class="n">layer</span><span class="o">:</span>
<span class="n">expected</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="o">,</span> <span class="n">found</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="o">.</span> <span class="n">Full</span> <span class="n">shape</span> <span class="n">received</span><span class="o">:</span> <span class="o">[</span><span class="mi">2</span><span class="o">]</span>
</code></pre></div>

<p>Input checks that can be specified via <code>input_spec</code> include:
- Structure (e.g. a single input, a list of 2 inputs, etc)
- Shape
- Rank (ndim)
- Dtype</p>
<p>For more information, see <code>tf.keras.layers.InputSpec</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">layers</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">losses</span>
</code></pre></div>

<p>List of losses added using the <code>add_loss()</code> API.</p>
<p>Variable regularization tensors are created when this property is accessed,
so it is eager safe: accessing <code>losses</code> under a <code>tf.GradientTape</code> will
propagate gradients back to the corresponding variables.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>class MyLayer(tf.keras.layers.Layer):
...   def call(self, inputs):
...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))
...     return inputs
l = MyLayer()
l(np.ones((10, 1)))
l.losses
[1.0]</p>
<p>inputs = tf.keras.Input(shape=(10,))
x = tf.keras.layers.Dense(10)(inputs)
outputs = tf.keras.layers.Dense(1)(x)
model = tf.keras.Model(inputs, outputs)</p>
<h1 id="activity-regularization">Activity regularization.</h1>
<p>len(model.losses)
0
model.add_loss(tf.abs(tf.reduce_mean(x)))
len(model.losses)
1</p>
<p>inputs = tf.keras.Input(shape=(10,))
d = tf.keras.layers.Dense(10, kernel_initializer='ones')
x = d(inputs)
outputs = tf.keras.layers.Dense(1)(x)
model = tf.keras.Model(inputs, outputs)</p>
<h1 id="weight-regularization">Weight regularization.</h1>
<p>model.add_loss(lambda: tf.reduce_mean(d.kernel))
model.losses
[<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]</p>
</blockquote>
</blockquote>
</blockquote>
<p>Returns:
  A list of tensors.</p>
<div class="codehilite"><pre><span></span><code><span class="n">metrics</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">metrics_names</span>
</code></pre></div>

<p>Returns the model's display labels for all outputs.</p>
<p>Note: <code>metrics_names</code> are available only after a <code>keras.Model</code> has been
trained/evaluated on actual data.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>inputs = tf.keras.layers.Input(shape=(3,))
outputs = tf.keras.layers.Dense(2)(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
model.compile(optimizer="Adam", loss="mse", metrics=["mae"])
model.metrics_names
[]</p>
<p>x = np.random.random((2, 3))
y = np.random.randint(0, 2, (2, 2))
model.fit(x, y)
model.metrics_names
['loss', 'mae']</p>
<p>inputs = tf.keras.layers.Input(shape=(3,))
d = tf.keras.layers.Dense(2, name='out')
output_1 = d(inputs)
output_2 = d(inputs)
model = tf.keras.models.Model(
...    inputs=inputs, outputs=[output_1, output_2])
model.compile(optimizer="Adam", loss="mse", metrics=["mae", "acc"])
model.fit(x, (y, y))
model.metrics_names
['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',
'out_1_acc']</p>
</blockquote>
</blockquote>
</blockquote>
<div class="codehilite"><pre><span></span><code><span class="n">name</span>
</code></pre></div>

<p>Name of the layer (string), set in the constructor.</p>
<div class="codehilite"><pre><span></span><code><span class="n">name_scope</span>
</code></pre></div>

<p>Returns a <code>tf.name_scope</code> instance for this class.</p>
<div class="codehilite"><pre><span></span><code><span class="n">non_trainable_variables</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">non_trainable_weights</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">outbound_nodes</span>
</code></pre></div>

<p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output</span>
</code></pre></div>

<p>Retrieves the output tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one output,
i.e. if it is connected to one incoming layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output_mask</span>
</code></pre></div>

<p>Retrieves the output mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>
<p>Returns:
    Output mask tensor (potentially None) or list of output
    mask tensors.</p>
<p>Raises:
    AttributeError: if the layer is connected to
    more than one incoming layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output_shape</span>
</code></pre></div>

<p>Retrieves the output shape(s) of a layer.</p>
<p>Only applicable if the layer has one output,
or if all outputs have the same shape.</p>
<div class="codehilite"><pre><span></span><code><span class="n">run_eagerly</span>
</code></pre></div>

<p>Settable attribute indicating whether the model should run eagerly.</p>
<p>Running eagerly means that your model will be run step by step,
like Python code. Your model might run slower, but it should become easier
for you to debug it by stepping into individual layer calls.</p>
<p>By default, we will attempt to compile your model to a static graph to
deliver the best execution performance.</p>
<div class="codehilite"><pre><span></span><code><span class="n">state_updates</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Returns the <code>updates</code> from all layers that are stateful.</p>
<p>This is useful for separating training updates and
state updates, e.g. when we need to update a layer's internal state
during prediction.</p>
<div class="codehilite"><pre><span></span><code><span class="n">stateful</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">submodules</span>
</code></pre></div>

<p>Sequence of all sub-modules.</p>
<p>Submodules are modules which are properties of this module, or found as
properties of modules which are properties of this module (and so on).</p>
<blockquote>
<blockquote>
<blockquote>
<p>a = tf.Module()
b = tf.Module()
c = tf.Module()
a.b = b
b.c = c
list(a.submodules) == [b, c]
True
list(b.submodules) == [c]
True
list(c.submodules) == []
True</p>
</blockquote>
</blockquote>
</blockquote>
<div class="codehilite"><pre><span></span><code><span class="n">supports_masking</span>
</code></pre></div>

<p>Whether this layer supports computing a mask using <code>compute_mask</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">trainable</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">trainable_variables</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">trainable_weights</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">updates</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">variable_dtype</span>
</code></pre></div>

<p>Alias of <code>Layer.dtype</code>, the dtype of the weights.</p>
<div class="codehilite"><pre><span></span><code><span class="n">variables</span>
</code></pre></div>

<p>Returns the list of all layer variables/weights.</p>
<p>Alias of <code>self.weights</code>.</p>
<p>Note: This will not track the weights of nested <code>tf.Modules</code> that are not
themselves Keras layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">weights</span>
</code></pre></div>

<p>Returns the list of all layer variables/weights.</p>
<p>Note: This will not track the weights of nested <code>tf.Modules</code> that are not
themselves Keras layers.</p>
<h4 id="methods">Methods</h4>
<h4 id="add_loss">add_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">losses</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Add loss tensor(s), potentially dependent on layer inputs.</p>
<p>Some losses (for instance, activity regularization losses) may be dependent
on the inputs passed when calling a layer. Hence, when reusing the same
layer on different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.losses</code> may
be dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>
<p>This method can be used inside a subclassed layer or model's <code>call</code>
function, in which case <code>losses</code> should be a Tensor or list of Tensors.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">inputs</span>
</code></pre></div>

<p>This method can also be called directly on a Functional Model during
construction. In this case, any loss Tensors passed to this Model must
be symbolic and be able to be traced back to the model's <code>Input</code>s. These
losses become part of the model's topology and are tracked in <code>get_config</code>.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="c1"># Activity regularization.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</code></pre></div>

<p>If this is not the case for your loss (if, for example, your loss references
a <code>Variable</code> of one of the model's layers), you can wrap your loss in a
zero-argument lambda. These losses are not tracked as part of the model's
topology since they can't be serialized.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">d</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="c1"># Weight regularization.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">kernel</span><span class="p">))</span>
</code></pre></div>

<p>Arguments:
  losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses
    may also be zero-argument callables which create a loss tensor.
  **kwargs: Additional keyword arguments for backward compatibility.
    Accepted values:
      inputs - Deprecated, will be automatically inferred.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">add_loss</span>(<span class="nb">self</span>, <span class="n">losses</span>, **<span class="n">kwargs</span>):

    <span class="s">&quot;&quot;&quot;Add loss tensor(s), potentially dependent on layer inputs.</span>

<span class="s">    Some losses (for instance, activity regularization losses) may be dependent</span>

<span class="s">    on the inputs passed when calling a layer. Hence, when reusing the same</span>

<span class="s">    layer on different inputs `a` and `b`, some entries in `layer.losses` may</span>

<span class="s">    be dependent on `a` and some on `b`. This method automatically keeps track</span>

<span class="s">    of dependencies.</span>

<span class="s">    This method can be used inside a subclassed layer or model&#39;s `call`</span>

<span class="s">    function, in which case `losses` should be a Tensor or list of Tensors.</span>

<span class="s">    Example:</span>

<span class="s">    ```python</span>

<span class="s">    class MyLayer(tf.keras.layers.Layer):</span>

<span class="s">      def call(self, inputs):</span>

<span class="s">        self.add_loss(tf.abs(tf.reduce_mean(inputs)))</span>

<span class="s">        return inputs</span>

<span class="s">    ```</span>

<span class="s">    This method can also be called directly on a Functional Model during</span>

<span class="s">    construction. In this case, any loss Tensors passed to this Model must</span>

<span class="s">    be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>

<span class="s">    losses become part of the model&#39;s topology and are tracked in `get_config`.</span>

<span class="s">    Example:</span>

<span class="s">    ```python</span>

<span class="s">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s">    x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s">    # Activity regularization.</span>

<span class="s">    model.add_loss(tf.abs(tf.reduce_mean(x)))</span>

<span class="s">    ```</span>

<span class="s">    If this is not the case for your loss (if, for example, your loss references</span>

<span class="s">    a `Variable` of one of the model&#39;s layers), you can wrap your loss in a</span>

<span class="s">    zero-argument lambda. These losses are not tracked as part of the model&#39;s</span>

<span class="s">    topology since they can&#39;t be serialized.</span>

<span class="s">    Example:</span>

<span class="s">    ```python</span>

<span class="s">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s">    d = tf.keras.layers.Dense(10)</span>

<span class="s">    x = d(inputs)</span>

<span class="s">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s">    # Weight regularization.</span>

<span class="s">    model.add_loss(lambda: tf.reduce_mean(d.kernel))</span>

<span class="s">    ```</span>

<span class="s">    Arguments:</span>

<span class="s">      losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses</span>

<span class="s">        may also be zero-argument callables which create a loss tensor.</span>

<span class="s">      **kwargs: Additional keyword arguments for backward compatibility.</span>

<span class="s">        Accepted values:</span>

<span class="s">          inputs - Deprecated, will be automatically inferred.</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="n">kwargs</span>.<span class="nb">pop</span>(<span class="s">&#39;inputs&#39;</span>, <span class="n">None</span>)

    <span class="k">if</span> <span class="n">kwargs:</span>

      <span class="n">raise</span> <span class="n">TypeError</span>(<span class="s">&#39;Unknown keyword arguments: %s&#39;</span> % (<span class="n">kwargs</span>.<span class="nb">keys</span>(),))

    <span class="n">def</span> <span class="n">_tag_callable</span>(<span class="n">loss</span>):

      <span class="s">&quot;&quot;&quot;Tags callable loss tensor as `_unconditional_loss`.&quot;&quot;&quot;</span>

      <span class="k">if</span> <span class="n">callable</span>(<span class="n">loss</span>):

        <span class="c1"># We run the loss without autocasting, as regularizers are often</span>

        <span class="c1"># numerically unstable in float16.</span>

        <span class="k">with</span> <span class="n">autocast_variable</span>.<span class="n">enable_auto_cast_variables</span>(<span class="n">None</span>):

          <span class="n">loss</span> = <span class="n">loss</span>()

      <span class="k">if</span> <span class="n">loss</span> <span class="k">is</span> <span class="n">None:</span>

        <span class="k">return</span> <span class="n">None</span>  <span class="c1"># Will be filtered out when computing the .losses property</span>

      <span class="k">if</span> <span class="nb">not</span> <span class="n">tensor_util</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>):

        <span class="n">loss</span> = <span class="n">ops</span>.<span class="n">convert_to_tensor_v2_with_dispatch</span>(

            <span class="n">loss</span>, <span class="n">dtype</span>=<span class="n">backend</span>.<span class="n">floatx</span>())

      <span class="n">loss</span>.<span class="n">_unconditional_loss</span> = <span class="nb">True</span>  <span class="c1"># pylint: disable=protected-access</span>

      <span class="k">return</span> <span class="n">loss</span>

    <span class="n">losses</span> = <span class="n">nest</span>.<span class="n">flatten</span>(<span class="n">losses</span>)

    <span class="n">callable_losses</span> = []

    <span class="n">eager_losses</span> = []

    <span class="n">symbolic_losses</span> = []

    <span class="k">for</span> <span class="n">loss</span> <span class="nb">in</span> <span class="n">losses:</span>

      <span class="k">if</span> <span class="n">callable</span>(<span class="n">loss</span>):

        <span class="n">callable_losses</span>.<span class="nb">append</span>(<span class="n">functools</span>.<span class="n">partial</span>(<span class="n">_tag_callable</span>, <span class="n">loss</span>))

        <span class="n">continue</span>

      <span class="k">if</span> <span class="n">loss</span> <span class="k">is</span> <span class="n">None:</span>

        <span class="n">continue</span>

      <span class="k">if</span> <span class="nb">not</span> <span class="n">tensor_util</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>) <span class="o">and</span> <span class="nb">not</span> <span class="n">isinstance</span>(

          <span class="n">loss</span>, <span class="n">keras_tensor</span>.<span class="n">KerasTensor</span>):

        <span class="n">loss</span> = <span class="n">ops</span>.<span class="n">convert_to_tensor_v2_with_dispatch</span>(

            <span class="n">loss</span>, <span class="n">dtype</span>=<span class="n">backend</span>.<span class="n">floatx</span>())

      <span class="c1"># TF Functions should take the eager path.</span>

      <span class="k">if</span> ((<span class="n">tf_utils</span>.<span class="n">is_symbolic_tensor</span>(<span class="n">loss</span>) <span class="o">or</span>

           <span class="n">isinstance</span>(<span class="n">loss</span>, <span class="n">keras_tensor</span>.<span class="n">KerasTensor</span>)) <span class="o">and</span>

          <span class="nb">not</span> <span class="n">base_layer_utils</span>.<span class="n">is_in_tf_function</span>()):

        <span class="n">symbolic_losses</span>.<span class="nb">append</span>(<span class="n">loss</span>)

      <span class="n">elif</span> <span class="n">tensor_util</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>):

        <span class="n">eager_losses</span>.<span class="nb">append</span>(<span class="n">loss</span>)

    <span class="nb">self</span>.<span class="n">_callable_losses</span>.<span class="n">extend</span>(<span class="n">callable_losses</span>)

    <span class="n">in_call_context</span> = <span class="n">base_layer_utils</span>.<span class="n">call_context</span>().<span class="n">in_call</span>

    <span class="k">if</span> <span class="n">eager_losses</span> <span class="o">and</span> <span class="nb">not</span> <span class="n">in_call_context:</span>

      <span class="n">raise</span> <span class="n">ValueError</span>(

          <span class="s">&#39;Expected a symbolic Tensors or a callable for the loss value. &#39;</span>

          <span class="s">&#39;Please wrap your loss computation in a zero argument `lambda`.&#39;</span>)

    <span class="nb">self</span>.<span class="n">_eager_losses</span>.<span class="n">extend</span>(<span class="n">eager_losses</span>)

    <span class="k">if</span> <span class="n">in_call_context</span> <span class="o">and</span> <span class="nb">not</span> <span class="n">keras_tensor</span>.<span class="n">keras_tensors_enabled</span>():

      <span class="k">for</span> <span class="n">symbolic_loss</span> <span class="nb">in</span> <span class="n">symbolic_losses:</span>

        <span class="nb">self</span>.<span class="n">_losses</span>.<span class="nb">append</span>(<span class="n">symbolic_loss</span>)

    <span class="n">else:</span>

      <span class="k">for</span> <span class="n">symbolic_loss</span> <span class="nb">in</span> <span class="n">symbolic_losses:</span>

        <span class="k">if</span> <span class="n">getattr</span>(<span class="nb">self</span>, <span class="s">&#39;_is_graph_network&#39;</span>, <span class="nb">False</span>):

          <span class="nb">self</span>.<span class="n">_graph_network_add_loss</span>(<span class="n">symbolic_loss</span>)

        <span class="n">else:</span>

          <span class="c1"># Possible a loss was added in a Layer&#39;s `build`.</span>

          <span class="nb">self</span>.<span class="n">_losses</span>.<span class="nb">append</span>(<span class="n">symbolic_loss</span>)
</code></pre></div>

</details>
<h4 id="add_metric">add_metric</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_metric</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">value</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Adds metric tensor to the layer.</p>
<p>This method can be used inside the <code>call()</code> method of a subclassed layer
or model.</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyMetricLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyMetricLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_metric_layer&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_2&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span>
</code></pre></div>

<p>This method can also be called directly on a Functional Model during
construction. In this case, any tensor passed to this Model must
be symbolic and be able to be traced back to the model's <code>Input</code>s. These
metrics become part of the model's topology and are tracked when you
save the model via <code>save()</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

<p>Note: Calling <code>add_metric()</code> with the result of a metric object on a
Functional Model, as shown in the example below, is not supported. This is
because we cannot trace the metric result tensor back to the model's inputs.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">()(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>None</td>
<td>Metric tensor.</td>
<td>None</td>
</tr>
<tr>
<td>name</td>
<td>None</td>
<td>String metric name.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments for backward compatibility.</td>
<td></td>
</tr>
<tr>
<td>Accepted values:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>aggregation</code> - When the <code>value</code> tensor provided is not the result of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>calling a <code>keras.Metric</code> instance, it will be aggregated by default</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>using a <code>keras.Metric.Mean</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">add_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="k">value</span><span class="p">,</span> <span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Adds metric tensor to the layer.</span>

<span class="s2">    This method can be used inside the `call()` method of a subclassed layer</span>

<span class="s2">    or model.</span>

<span class="s2">    ```python</span>

<span class="s2">    class MyMetricLayer(tf.keras.layers.Layer):</span>

<span class="s2">      def __init__(self):</span>

<span class="s2">        super(MyMetricLayer, self).__init__(name=&#39;my_metric_layer&#39;)</span>

<span class="s2">        self.mean = tf.keras.metrics.Mean(name=&#39;metric_1&#39;)</span>

<span class="s2">      def call(self, inputs):</span>

<span class="s2">        self.add_metric(self.mean(x))</span>

<span class="s2">        self.add_metric(tf.reduce_sum(x), name=&#39;metric_2&#39;)</span>

<span class="s2">        return inputs</span>

<span class="s2">    ```</span>

<span class="s2">    This method can also be called directly on a Functional Model during</span>

<span class="s2">    construction. In this case, any tensor passed to this Model must</span>

<span class="s2">    be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>

<span class="s2">    metrics become part of the model&#39;s topology and are tracked when you</span>

<span class="s2">    save the model via `save()`.</span>

<span class="s2">    ```python</span>

<span class="s2">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s2">    x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s2">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s2">    model.add_metric(math_ops.reduce_sum(x), name=&#39;metric_1&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    Note: Calling `add_metric()` with the result of a metric object on a</span>

<span class="s2">    Functional Model, as shown in the example below, is not supported. This is</span>

<span class="s2">    because we cannot trace the metric result tensor back to the model&#39;s inputs.</span>

<span class="s2">    ```python</span>

<span class="s2">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s2">    x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s2">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s2">    model.add_metric(tf.keras.metrics.Mean()(x), name=&#39;metric_1&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    Args:</span>

<span class="s2">      value: Metric tensor.</span>

<span class="s2">      name: String metric name.</span>

<span class="s2">      **kwargs: Additional keyword arguments for backward compatibility.</span>

<span class="s2">        Accepted values:</span>

<span class="s2">        `aggregation` - When the `value` tensor provided is not the result of</span>

<span class="s2">        calling a `keras.Metric` instance, it will be aggregated by default</span>

<span class="s2">        using a `keras.Metric.Mean`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">kwargs_keys</span> <span class="o">=</span> <span class="k">list</span><span class="p">(</span><span class="n">kwargs</span><span class="p">.</span><span class="k">keys</span><span class="p">())</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">or</span>

        <span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">and</span> <span class="n">kwargs_keys</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span> <span class="o">!=</span> <span class="s1">&#39;aggregation&#39;</span><span class="p">))</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">TypeError</span><span class="p">(</span><span class="s1">&#39;Unknown keyword arguments: &#39;</span><span class="p">,</span> <span class="n">str</span><span class="p">(</span><span class="n">kwargs</span><span class="p">.</span><span class="k">keys</span><span class="p">()))</span>

    <span class="n">from_metric_obj</span> <span class="o">=</span> <span class="n">hasattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="s1">&#39;_metric_obj&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">keras_tensor</span><span class="p">.</span><span class="n">keras_tensors_enabled</span><span class="p">()</span><span class="o">:</span>

      <span class="n">is_symbolic</span> <span class="o">=</span> <span class="n">isinstance</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="n">keras_tensor</span><span class="p">.</span><span class="n">KerasTensor</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">is_symbolic</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">is_symbolic_tensor</span><span class="p">(</span><span class="k">value</span><span class="p">)</span>

    <span class="n">in_call_context</span> <span class="o">=</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">call_context</span><span class="p">().</span><span class="n">in_call</span>

    <span class="k">if</span> <span class="k">name</span> <span class="k">is</span> <span class="k">None</span> <span class="k">and</span> <span class="k">not</span> <span class="n">from_metric_obj</span><span class="o">:</span>

      <span class="c1"># Eg. `self.add_metric(math_ops.reduce_sum(x))`</span>

      <span class="c1"># In eager mode, we use metric name to lookup a metric. Without a name,</span>

      <span class="c1"># a new Mean metric wrapper will be created on every model/layer call.</span>

      <span class="c1"># So, we raise an error when no name is provided.</span>

      <span class="c1"># We will do the same for symbolic mode for consistency although a name</span>

      <span class="c1"># will be generated if no name is provided.</span>

      <span class="c1"># We will not raise this error in the foll use case for the sake of</span>

      <span class="c1"># consistency as name in provided in the metric constructor.</span>

      <span class="c1"># mean = metrics.Mean(name=&#39;my_metric&#39;)</span>

      <span class="c1"># model.add_metric(mean(outputs))</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Please provide a name for your metric like &#39;</span>

                       <span class="s1">&#39;`self.add_metric(tf.reduce_sum(inputs), &#39;</span>

                       <span class="s1">&#39;name=</span><span class="se">\&#39;</span><span class="s1">mean_activation</span><span class="se">\&#39;</span><span class="s1">)`&#39;</span><span class="p">)</span>

    <span class="n">elif</span> <span class="n">from_metric_obj</span><span class="o">:</span>

      <span class="k">name</span> <span class="o">=</span> <span class="k">value</span><span class="p">.</span><span class="n">_metric_obj</span><span class="p">.</span><span class="k">name</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">in_call_context</span> <span class="k">and</span> <span class="k">not</span> <span class="n">is_symbolic</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Expected a symbolic Tensor for the metric value, &#39;</span>

                       <span class="s1">&#39;received: &#39;</span> <span class="o">+</span> <span class="n">str</span><span class="p">(</span><span class="k">value</span><span class="p">))</span>

    <span class="c1"># If a metric was added in a Layer&#39;s `call` or `build`.</span>

    <span class="k">if</span> <span class="n">in_call_context</span> <span class="k">or</span> <span class="k">not</span> <span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_is_graph_network&#39;</span><span class="p">,</span> <span class="no">False</span><span class="p">)</span><span class="o">:</span>

      <span class="c1"># TF Function path should take the eager path.</span>

      <span class="c1"># If the given metric is available in `metrics` list we just update state</span>

      <span class="c1"># on it, otherwise we create a new metric instance and</span>

      <span class="c1"># add it to the `metrics` list.</span>

      <span class="n">metric_obj</span> <span class="o">=</span> <span class="n">getattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="s1">&#39;_metric_obj&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>

      <span class="c1"># Tensors that come from a Metric object already updated the Metric state.</span>

      <span class="n">should_update_state</span> <span class="o">=</span> <span class="k">not</span> <span class="n">metric_obj</span>

      <span class="k">name</span> <span class="o">=</span> <span class="n">metric_obj</span><span class="p">.</span><span class="k">name</span> <span class="k">if</span> <span class="n">metric_obj</span> <span class="k">else</span> <span class="k">name</span>

      <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">_metrics_lock</span><span class="o">:</span>

        <span class="k">match</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_get_existing_metric</span><span class="p">(</span><span class="k">name</span><span class="p">)</span>

        <span class="k">if</span> <span class="k">match</span><span class="o">:</span>

          <span class="n">metric_obj</span> <span class="o">=</span> <span class="k">match</span>

        <span class="n">elif</span> <span class="n">metric_obj</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

        <span class="k">else</span><span class="o">:</span>

          <span class="c1"># Build the metric object with the value&#39;s dtype if it defines one</span>

          <span class="n">metric_obj</span> <span class="o">=</span> <span class="n">metrics_mod</span><span class="p">.</span><span class="n">Mean</span><span class="p">(</span>

              <span class="k">name</span><span class="o">=</span><span class="k">name</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">getattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">))</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">should_update_state</span><span class="o">:</span>

        <span class="n">metric_obj</span><span class="p">(</span><span class="k">value</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">from_metric_obj</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Using the result of calling a `Metric` object &#39;</span>

                         <span class="s1">&#39;when calling `add_metric` on a Functional &#39;</span>

                         <span class="s1">&#39;Model is not supported. Please pass the &#39;</span>

                         <span class="s1">&#39;Tensor to monitor directly.&#39;</span><span class="p">)</span>

      <span class="c1"># Insert layers into the Keras Graph Network.</span>

      <span class="n">aggregation</span> <span class="o">=</span> <span class="k">None</span> <span class="k">if</span> <span class="n">from_metric_obj</span> <span class="k">else</span> <span class="s1">&#39;mean&#39;</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_graph_network_add_metric</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="n">aggregation</span><span class="p">,</span> <span class="k">name</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="add_update">add_update</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_update</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">updates</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Add update op(s), potentially dependent on layer inputs.</p>
<p>Weight updates (for instance, the updates of the moving mean and variance
in a BatchNormalization layer) may be dependent on the inputs passed
when calling a layer. Hence, when reusing the same layer on
different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.updates</code> may be
dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>
<p>This call is ignored when eager execution is enabled (in that case, variable
updates are run on the fly and thus do not need to be tracked for later
execution).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>updates</td>
<td>None</td>
<td>Update op, or list/tuple of update ops, or zero-arg callable</td>
<td></td>
</tr>
<tr>
<td>that returns an update op. A zero-arg callable should be passed in</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>order to disable running the updates by setting <code>trainable=False</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>on this Layer, when executing in Eager mode.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>inputs</td>
<td>None</td>
<td>Deprecated, will be automatically inferred.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_doc_inheritable</span>

  <span class="n">def</span> <span class="n">add_update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Add update op(s), potentially dependent on layer inputs.</span>

<span class="s2">    Weight updates (for instance, the updates of the moving mean and variance</span>

<span class="s2">    in a BatchNormalization layer) may be dependent on the inputs passed</span>

<span class="s2">    when calling a layer. Hence, when reusing the same layer on</span>

<span class="s2">    different inputs `a` and `b`, some entries in `layer.updates` may be</span>

<span class="s2">    dependent on `a` and some on `b`. This method automatically keeps track</span>

<span class="s2">    of dependencies.</span>

<span class="s2">    This call is ignored when eager execution is enabled (in that case, variable</span>

<span class="s2">    updates are run on the fly and thus do not need to be tracked for later</span>

<span class="s2">    execution).</span>

<span class="s2">    Arguments:</span>

<span class="s2">      updates: Update op, or list/tuple of update ops, or zero-arg callable</span>

<span class="s2">        that returns an update op. A zero-arg callable should be passed in</span>

<span class="s2">        order to disable running the updates by setting `trainable=False`</span>

<span class="s2">        on this Layer, when executing in Eager mode.</span>

<span class="s2">      inputs: Deprecated, will be automatically inferred.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">inputs</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">tf_logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span>

          <span class="s1">&#39;`add_update` `inputs` kwarg has been deprecated. You no longer need &#39;</span>

          <span class="s1">&#39;to pass a value to `inputs` as it is being automatically inferred.&#39;</span><span class="p">)</span>

    <span class="n">call_context</span> <span class="o">=</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">call_context</span><span class="p">()</span>

    <span class="c1"># No need to run updates during Functional API construction.</span>

    <span class="k">if</span> <span class="n">call_context</span><span class="p">.</span><span class="n">in_keras_graph</span><span class="o">:</span>

      <span class="k">return</span>

    <span class="c1"># Callable updates are disabled by setting `trainable=False`.</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">call_context</span><span class="p">.</span><span class="n">frozen</span><span class="o">:</span>

      <span class="k">for</span> <span class="k">update</span> <span class="k">in</span> <span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span><span class="o">:</span>

        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="k">update</span><span class="p">)</span><span class="o">:</span>

          <span class="k">update</span><span class="p">()</span>  <span class="c1"># pylint: disable=not-callable</span>
</code></pre></div>

</details>
<h4 id="add_variable">add_variable</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_variable</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use! Alias for <code>add_weight</code>.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_doc_inheritable</span>

  <span class="n">def</span> <span class="n">add_variable</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use! Alias for `add_weight`.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.add_variable` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `layer.add_weight` method instead.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">add_weight</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="add_weight">add_weight</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_weight</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">trainable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_resource</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">synchronization</span><span class="o">=&lt;</span><span class="n">VariableSynchronization</span><span class="o">.</span><span class="n">AUTO</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=&lt;</span><span class="n">VariableAggregation</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Adds a new variable to the layer.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>None</td>
<td>Variable name.</td>
<td>None</td>
</tr>
<tr>
<td>shape</td>
<td>None</td>
<td>Variable shape. Defaults to scalar if unspecified.</td>
<td>scalar if unspecified</td>
</tr>
<tr>
<td>dtype</td>
<td>None</td>
<td>The type of the variable. Defaults to <code>self.dtype</code>.</td>
<td><code>self.dtype</code></td>
</tr>
<tr>
<td>initializer</td>
<td>None</td>
<td>Initializer instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>regularizer</td>
<td>None</td>
<td>Regularizer instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>trainable</td>
<td>None</td>
<td>Boolean, whether the variable should be part of the layer's</td>
<td></td>
</tr>
<tr>
<td>"trainable_variables" (e.g. variables, biases)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>or "non_trainable_variables" (e.g. BatchNorm mean and variance).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Note that <code>trainable</code> cannot be <code>True</code> if <code>synchronization</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>is set to <code>ON_READ</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>constraint</td>
<td>None</td>
<td>Constraint instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>use_resource</td>
<td>None</td>
<td>Whether to use <code>ResourceVariable</code>.</td>
<td>None</td>
</tr>
<tr>
<td>synchronization</td>
<td>None</td>
<td>Indicates when a distributed a variable will be</td>
<td></td>
</tr>
<tr>
<td>aggregated. Accepted values are constants defined in the class</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.VariableSynchronization</code>. By default the synchronization is set to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>AUTO</code> and the current <code>DistributionStrategy</code> chooses</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>when to synchronize. If <code>synchronization</code> is set to <code>ON_READ</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>trainable</code> must not be set to <code>True</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>aggregation</td>
<td>None</td>
<td>Indicates how a distributed variable will be aggregated.</td>
<td></td>
</tr>
<tr>
<td>Accepted values are constants defined in the class</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.VariableAggregation</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments. Accepted values are <code>getter</code>,</td>
<td></td>
</tr>
<tr>
<td><code>collections</code>, <code>experimental_autocast</code> and <code>caching_device</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The variable created.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>When giving unsupported dtype and no initializer or when</td>
</tr>
<tr>
<td>trainable has been set to True with synchronization set as <code>ON_READ</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.for_subclass_implementers</span>

  <span class="n">def</span> <span class="n">add_weight</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                 <span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">shape</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">dtype</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">initializer</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">regularizer</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">trainable</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="k">constraint</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">use_resource</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">synchronization</span><span class="o">=</span><span class="n">tf_variables</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="p">.</span><span class="n">AUTO</span><span class="p">,</span>

                 <span class="n">aggregation</span><span class="o">=</span><span class="n">tf_variables</span><span class="p">.</span><span class="n">VariableAggregation</span><span class="p">.</span><span class="k">NONE</span><span class="p">,</span>

                 <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Adds a new variable to the layer.</span>

<span class="s2">    Arguments:</span>

<span class="s2">      name: Variable name.</span>

<span class="s2">      shape: Variable shape. Defaults to scalar if unspecified.</span>

<span class="s2">      dtype: The type of the variable. Defaults to `self.dtype`.</span>

<span class="s2">      initializer: Initializer instance (callable).</span>

<span class="s2">      regularizer: Regularizer instance (callable).</span>

<span class="s2">      trainable: Boolean, whether the variable should be part of the layer&#39;s</span>

<span class="s2">        &quot;</span><span class="n">trainable_variables</span><span class="s2">&quot; (e.g. variables, biases)</span>

<span class="s2">        or &quot;</span><span class="n">non_trainable_variables</span><span class="s2">&quot; (e.g. BatchNorm mean and variance).</span>

<span class="s2">        Note that `trainable` cannot be `True` if `synchronization`</span>

<span class="s2">        is set to `ON_READ`.</span>

<span class="s2">      constraint: Constraint instance (callable).</span>

<span class="s2">      use_resource: Whether to use `ResourceVariable`.</span>

<span class="s2">      synchronization: Indicates when a distributed a variable will be</span>

<span class="s2">        aggregated. Accepted values are constants defined in the class</span>

<span class="s2">        `tf.VariableSynchronization`. By default the synchronization is set to</span>

<span class="s2">        `AUTO` and the current `DistributionStrategy` chooses</span>

<span class="s2">        when to synchronize. If `synchronization` is set to `ON_READ`,</span>

<span class="s2">        `trainable` must not be set to `True`.</span>

<span class="s2">      aggregation: Indicates how a distributed variable will be aggregated.</span>

<span class="s2">        Accepted values are constants defined in the class</span>

<span class="s2">        `tf.VariableAggregation`.</span>

<span class="s2">      **kwargs: Additional keyword arguments. Accepted values are `getter`,</span>

<span class="s2">        `collections`, `experimental_autocast` and `caching_device`.</span>

<span class="s2">    Returns:</span>

<span class="s2">      The variable created.</span>

<span class="s2">    Raises:</span>

<span class="s2">      ValueError: When giving unsupported dtype and no initializer or when</span>

<span class="s2">        trainable has been set to True with synchronization set as `ON_READ`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">shape</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">shape</span> <span class="o">=</span> <span class="p">()</span>

    <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;partitioner&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>  <span class="c1"># Ignored.</span>

    <span class="c1"># Validate optional keyword arguments.</span>

    <span class="k">for</span> <span class="n">kwarg</span> <span class="k">in</span> <span class="n">kwargs</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">kwarg</span> <span class="k">not</span> <span class="k">in</span> <span class="err">[</span><span class="s1">&#39;collections&#39;</span><span class="p">,</span> <span class="s1">&#39;experimental_autocast&#39;</span><span class="p">,</span>

                       <span class="s1">&#39;caching_device&#39;</span><span class="p">,</span> <span class="s1">&#39;getter&#39;</span><span class="err">]</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">TypeError</span><span class="p">(</span><span class="s1">&#39;Unknown keyword argument:&#39;</span><span class="p">,</span> <span class="n">kwarg</span><span class="p">)</span>

    <span class="n">collections_arg</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;collections&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>

    <span class="c1"># &#39;experimental_autocast&#39; can be set to False by the caller to indicate an</span>

    <span class="c1"># AutoCastVariable should never be created.</span>

    <span class="n">autocast</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;experimental_autocast&#39;</span><span class="p">,</span> <span class="no">True</span><span class="p">)</span>

    <span class="c1"># See the docstring for tf.Variable about the details for caching_device.</span>

    <span class="n">caching_device</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;caching_device&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">dtype</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">dtype</span> <span class="k">or</span> <span class="n">backend</span><span class="p">.</span><span class="n">floatx</span><span class="p">()</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="p">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">variable_dtype</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="c1"># The policy is &quot;_infer&quot;, so we infer the policy from the variable dtype.</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_set_dtype_policy</span><span class="p">(</span><span class="n">policy</span><span class="p">.</span><span class="n">Policy</span><span class="p">(</span><span class="n">dtype</span><span class="p">.</span><span class="n">base_dtype</span><span class="p">.</span><span class="k">name</span><span class="p">))</span>

    <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>

    <span class="n">regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="n">regularizer</span><span class="p">)</span>

    <span class="k">constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="k">constraint</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">synchronization</span> <span class="o">==</span> <span class="n">tf_variables</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="p">.</span><span class="n">ON_READ</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">trainable</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

            <span class="s1">&#39;Synchronization value can be set to &#39;</span>

            <span class="s1">&#39;VariableSynchronization.ON_READ only for non-trainable variables. &#39;</span>

            <span class="s1">&#39;You have specified trainable=True and &#39;</span>

            <span class="s1">&#39;synchronization=VariableSynchronization.ON_READ.&#39;</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="c1"># Set trainable to be false when variable is to be synced on read.</span>

        <span class="n">trainable</span> <span class="o">=</span> <span class="no">False</span>

    <span class="n">elif</span> <span class="n">trainable</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">trainable</span> <span class="o">=</span> <span class="no">True</span>

    <span class="c1"># Initialize variable when no initializer provided</span>

    <span class="k">if</span> <span class="n">initializer</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="c1"># If dtype is DT_FLOAT, provide a uniform unit scaling initializer</span>

      <span class="k">if</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_floating</span><span class="o">:</span>

        <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">)</span>

      <span class="c1"># If dtype is DT_INT/DT_UINT, provide a default value `zero`</span>

      <span class="c1"># If dtype is DT_BOOL, provide a default value `FALSE`</span>

      <span class="n">elif</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_integer</span> <span class="k">or</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_unsigned</span> <span class="k">or</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_bool</span><span class="o">:</span>

        <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="s1">&#39;zeros&#39;</span><span class="p">)</span>

      <span class="c1"># NOTES:Do we need to support for handling DT_STRING and DT_COMPLEX here?</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;An initializer for variable %s of type %s is required&#39;</span>

                         <span class="s1">&#39; for layer %s&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="k">name</span><span class="p">,</span> <span class="n">dtype</span><span class="p">.</span><span class="n">base_dtype</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="k">name</span><span class="p">))</span>

    <span class="n">getter</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;getter&#39;</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">make_variable</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">autocast</span> <span class="k">and</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">compute_dtype</span> <span class="o">!=</span> <span class="n">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">variable_dtype</span>

        <span class="k">and</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_floating</span><span class="p">)</span><span class="o">:</span>

      <span class="n">old_getter</span> <span class="o">=</span> <span class="n">getter</span>

      <span class="c1"># Wrap variable constructor to return an AutoCastVariable.</span>

      <span class="n">def</span> <span class="n">getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>  <span class="c1"># pylint: disable=function-redefined</span>

        <span class="n">variable</span> <span class="o">=</span> <span class="n">old_getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">autocast_variable</span><span class="p">.</span><span class="n">create_autocast_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

      <span class="c1"># Also the caching_device does not work with the mixed precision API,</span>

      <span class="c1"># disable it if it is specified.</span>

      <span class="c1"># TODO(b/142020079): Reenable it once the bug is fixed.</span>

      <span class="k">if</span> <span class="n">caching_device</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

        <span class="n">tf_logging</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`caching_device` does not work with mixed precision &#39;</span>

                        <span class="s1">&#39;API. Ignoring user specified `caching_device`.&#39;</span><span class="p">)</span>

        <span class="n">caching_device</span> <span class="o">=</span> <span class="k">None</span>

    <span class="n">variable</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_add_variable_with_custom_getter</span><span class="p">(</span>

        <span class="k">name</span><span class="o">=</span><span class="k">name</span><span class="p">,</span>

        <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>

        <span class="c1"># TODO(allenl): a `make_variable` equivalent should be added as a</span>

        <span class="c1"># `Trackable` method.</span>

        <span class="n">getter</span><span class="o">=</span><span class="n">getter</span><span class="p">,</span>

        <span class="c1"># Manage errors in Layer rather than Trackable.</span>

        <span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

        <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>

        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>

        <span class="k">constraint</span><span class="o">=</span><span class="k">constraint</span><span class="p">,</span>

        <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>

        <span class="n">use_resource</span><span class="o">=</span><span class="n">use_resource</span><span class="p">,</span>

        <span class="n">collections</span><span class="o">=</span><span class="n">collections_arg</span><span class="p">,</span>

        <span class="n">synchronization</span><span class="o">=</span><span class="n">synchronization</span><span class="p">,</span>

        <span class="n">aggregation</span><span class="o">=</span><span class="n">aggregation</span><span class="p">,</span>

        <span class="n">caching_device</span><span class="o">=</span><span class="n">caching_device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">regularizer</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="c1"># TODO(fchollet): in the future, this should be handled at the</span>

      <span class="c1"># level of variable creation, and weight regularization losses</span>

      <span class="c1"># should be variable attributes.</span>

      <span class="n">name_in_scope</span> <span class="o">=</span> <span class="n">variable</span><span class="p">.</span><span class="k">name</span><span class="err">[</span><span class="o">:</span><span class="n">variable</span><span class="p">.</span><span class="k">name</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)</span><span class="err">]</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_handle_weight_regularization</span><span class="p">(</span><span class="n">name_in_scope</span><span class="p">,</span>

                                         <span class="n">variable</span><span class="p">,</span>

                                         <span class="n">regularizer</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">is_split_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span><span class="o">:</span>

      <span class="k">for</span> <span class="n">v</span> <span class="k">in</span> <span class="n">variable</span><span class="o">:</span>

        <span class="n">backend</span><span class="p">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">trainable</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="k">else</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_non_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">backend</span><span class="p">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">trainable</span><span class="o">:</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_non_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">variable</span>
</code></pre></div>

</details>
<h4 id="apply">apply</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">apply</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>This is an alias of <code>self.__call__</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Input tensor(s).</td>
<td>None</td>
</tr>
<tr>
<td>*args</td>
<td>None</td>
<td>additional positional arguments to be passed to <code>self.call</code>.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>additional keyword arguments to be passed to <code>self.call</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Output tensor(s).</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">apply</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Deprecated, do NOT use!</span>

<span class="ss">    This is an alias of `self.__call__`.</span>

<span class="ss">    Arguments:</span>

<span class="ss">      inputs: Input tensor(s).</span>

<span class="ss">      *args: additional positional arguments to be passed to `self.call`.</span>

<span class="ss">      **kwargs: additional keyword arguments to be passed to `self.call`.</span>

<span class="ss">    Returns:</span>

<span class="ss">      Output tensor(s).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.apply` is deprecated and &#39;</span><span class="w"></span>

<span class="w">                  </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">                  </span><span class="s1">&#39;Please use `layer.__call__` method instead.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">__call__</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="build">build</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_shape</span>
<span class="p">)</span>
</code></pre></div>

<p>Builds the model based on input shapes received.</p>
<p>This is to be used for subclassed models, which do not know at instantiation
time what their inputs look like.</p>
<p>This method only exists for users who want to call <code>model.build()</code> in a
standalone way (as a substitute for calling the model on real data to
build it). It will never be called by the framework (and thus it will
never throw unexpected errors in an unrelated workflow).</p>
<p>Args:
 input_shape: Single tuple, TensorShape, or list/dict of shapes, where
     shapes are tuples, integers, or TensorShapes.</p>
<p>Raises:
  ValueError:
    1. In case of invalid user-provided data (not of type tuple,
       list, TensorShape, or dict).
    2. If the model requires call arguments that are agnostic
       to the input shapes (positional or kwarg in call signature).
    3. If not all layers were properly built.
    4. If float type inputs are not supported within the layers.</p>
<p>In each of these cases, the user should build their model by calling it
  on real tensor data.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="s s-Atom">@generic_utils</span><span class="p">.</span><span class="s s-Atom">default</span>

  <span class="s s-Atom">def</span> <span class="nf">build</span><span class="p">(</span><span class="s s-Atom">self</span><span class="p">,</span> <span class="s s-Atom">input_shape</span><span class="p">)</span><span class="s s-Atom">:</span>

    <span class="s2">&quot;&quot;&quot;Builds the model based on input shapes received.</span>

<span class="s2">    This is to be used for subclassed models, which do not know at instantiation</span>

<span class="s2">    time what their inputs look like.</span>

<span class="s2">    This method only exists for users who want to call `model.build()` in a</span>

<span class="s2">    standalone way (as a substitute for calling the model on real data to</span>

<span class="s2">    build it). It will never be called by the framework (and thus it will</span>

<span class="s2">    never throw unexpected errors in an unrelated workflow).</span>

<span class="s2">    Args:</span>

<span class="s2">     input_shape: Single tuple, TensorShape, or list/dict of shapes, where</span>

<span class="s2">         shapes are tuples, integers, or TensorShapes.</span>

<span class="s2">    Raises:</span>

<span class="s2">      ValueError:</span>

<span class="s2">        1. In case of invalid user-provided data (not of type tuple,</span>

<span class="s2">           list, TensorShape, or dict).</span>

<span class="s2">        2. If the model requires call arguments that are agnostic</span>

<span class="s2">           to the input shapes (positional or kwarg in call signature).</span>

<span class="s2">        3. If not all layers were properly built.</span>

<span class="s2">        4. If float type inputs are not supported within the layers.</span>

<span class="s2">      In each of these cases, the user should build their model by calling it</span>

<span class="s2">      on real tensor data.</span>

<span class="s2">    &quot;&quot;&quot;</span>

    <span class="s s-Atom">if</span> <span class="s s-Atom">self</span><span class="p">.</span><span class="k">_</span><span class="s s-Atom">is_graph_network:</span>

      <span class="nf">super</span><span class="p">(</span><span class="nv">Model</span><span class="p">,</span> <span class="s s-Atom">self</span><span class="p">).</span><span class="nf">build</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>

      <span class="s s-Atom">return</span>

    <span class="s s-Atom">if</span> <span class="s s-Atom">input_shape</span> <span class="o">is</span> <span class="nv">None</span><span class="s s-Atom">:</span>

      <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;Input shape must be defined when calling build on a &#39;</span>

                       <span class="s s-Atom">&#39;model subclass network.&#39;</span><span class="p">)</span>

    <span class="s s-Atom">valid_types</span> <span class="o">=</span> <span class="p">(</span><span class="s s-Atom">tuple</span><span class="p">,</span> <span class="s s-Atom">list</span><span class="p">,</span> <span class="s s-Atom">tensor_shape</span><span class="p">.</span><span class="nv">TensorShape</span><span class="p">,</span> <span class="s s-Atom">dict</span><span class="p">)</span>

    <span class="s s-Atom">if</span> <span class="o">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">valid_types</span><span class="p">)</span><span class="s s-Atom">:</span>

      <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;Specified input shape is not one of the valid types. &#39;</span>

                       <span class="s s-Atom">&#39;Please specify a batch input shape of type tuple or &#39;</span>

                       <span class="s s-Atom">&#39;list of input shapes. User provided &#39;</span>

                       <span class="s s-Atom">&#39;input type: {}&#39;</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">type</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)))</span>

    <span class="s s-Atom">if</span> <span class="s s-Atom">input_shape</span> <span class="s s-Atom">and</span> <span class="o">not</span> <span class="s s-Atom">self</span><span class="p">.</span><span class="nn">inputs</span><span class="p">:</span>

      <span class="s s-Atom">#</span> <span class="nv">We</span> <span class="s s-Atom">create</span> <span class="s s-Atom">placeholders</span> <span class="s s-Atom">for</span> <span class="s s-Atom">the</span> <span class="err">`</span><span class="nv">None</span><span class="err">`</span><span class="s s-Atom">s</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">shape</span> <span class="s s-Atom">and</span> <span class="s s-Atom">build</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model</span>

      <span class="s s-Atom">#</span> <span class="s s-Atom">in</span> <span class="s s-Atom">a</span> <span class="nv">Graph</span><span class="p">.</span> <span class="nv">Since</span> <span class="s s-Atom">tf</span><span class="p">.</span><span class="nv">Variable</span> <span class="o">is</span> <span class="s s-Atom">compatible</span> <span class="s s-Atom">with</span> <span class="s s-Atom">both</span> <span class="s s-Atom">eager</span> <span class="s s-Atom">execution</span>

      <span class="s s-Atom">#</span> <span class="s s-Atom">and</span> <span class="s s-Atom">graph</span> <span class="s s-Atom">building</span><span class="p">,</span> <span class="s s-Atom">the</span> <span class="s s-Atom">variables</span> <span class="s s-Atom">created</span> <span class="s s-Atom">after</span> <span class="s s-Atom">building</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model</span> <span class="s s-Atom">in</span>

      <span class="s s-Atom">#</span> <span class="s s-Atom">a</span> <span class="nv">Graph</span> <span class="s s-Atom">are</span> <span class="s s-Atom">still</span> <span class="s s-Atom">valid</span> <span class="s s-Atom">when</span> <span class="s s-Atom">executing</span> <span class="s s-Atom">eagerly</span><span class="p">.</span>

      <span class="s s-Atom">if</span> <span class="s s-Atom">context</span><span class="p">.</span><span class="nf">executing_eagerly</span><span class="p">()</span><span class="s s-Atom">:</span>

        <span class="s s-Atom">graph</span> <span class="o">=</span> <span class="s s-Atom">func_graph</span><span class="p">.</span><span class="nv">FuncGraph</span><span class="p">(</span><span class="s s-Atom">&#39;build_graph&#39;</span><span class="p">)</span>

      <span class="nn">else</span><span class="p">:</span>

        <span class="s s-Atom">graph</span> <span class="o">=</span> <span class="s s-Atom">backend</span><span class="p">.</span><span class="nf">get_graph</span><span class="p">()</span>

      <span class="s s-Atom">with</span> <span class="s s-Atom">graph</span><span class="p">.</span><span class="nf">as_default</span><span class="p">()</span><span class="s s-Atom">:</span>

        <span class="nf">if</span> <span class="p">(</span><span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">list</span><span class="p">)</span> <span class="s s-Atom">and</span>

            <span class="nf">all</span><span class="p">(</span><span class="s s-Atom">d</span> <span class="o">is</span> <span class="nv">None</span> <span class="s s-Atom">or</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">d</span><span class="p">,</span> <span class="s s-Atom">int</span><span class="p">)</span> <span class="s s-Atom">for</span> <span class="s s-Atom">d</span> <span class="s s-Atom">in</span> <span class="s s-Atom">input_shape</span><span class="p">))</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">input_shape</span> <span class="o">=</span> <span class="nf">tuple</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>

        <span class="s s-Atom">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">list</span><span class="p">)</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">x</span> <span class="o">=</span> <span class="p">[</span><span class="s s-Atom">base_layer_utils</span><span class="p">.</span><span class="nf">generate_placeholders_from_shape</span><span class="p">(</span><span class="s s-Atom">shape</span><span class="p">)</span>

               <span class="s s-Atom">for</span> <span class="s s-Atom">shape</span> <span class="s s-Atom">in</span> <span class="s s-Atom">input_shape</span><span class="p">]</span>

        <span class="s s-Atom">elif</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">dict</span><span class="p">)</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">x</span> <span class="o">=</span> <span class="p">{</span>

              <span class="nn">k</span><span class="p">:</span> <span class="s s-Atom">base_layer_utils</span><span class="p">.</span><span class="nf">generate_placeholders_from_shape</span><span class="p">(</span><span class="s s-Atom">shape</span><span class="p">)</span>

              <span class="s s-Atom">for</span> <span class="s s-Atom">k</span><span class="p">,</span> <span class="s s-Atom">shape</span> <span class="s s-Atom">in</span> <span class="s s-Atom">input_shape</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span>

          <span class="p">}</span>

        <span class="nn">else</span><span class="p">:</span>

          <span class="s s-Atom">x</span> <span class="o">=</span> <span class="s s-Atom">base_layer_utils</span><span class="p">.</span><span class="nf">generate_placeholders_from_shape</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>

        <span class="s s-Atom">kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="s s-Atom">call_signature</span> <span class="o">=</span> <span class="s s-Atom">self</span><span class="p">.</span><span class="k">_</span><span class="s s-Atom">call_full_argspec</span>

        <span class="s s-Atom">call_args</span> <span class="o">=</span> <span class="s s-Atom">call_signature</span><span class="p">.</span><span class="s s-Atom">args</span>

        <span class="s s-Atom">#</span> <span class="nv">Exclude</span> <span class="err">`</span><span class="s s-Atom">self</span><span class="err">`</span><span class="p">,</span> <span class="err">`</span><span class="s s-Atom">inputs</span><span class="err">`</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">any</span> <span class="s s-Atom">argument</span> <span class="s s-Atom">with</span> <span class="s s-Atom">a</span> <span class="s s-Atom">default</span> <span class="s s-Atom">value</span><span class="p">.</span>

        <span class="s s-Atom">if</span> <span class="nf">len</span><span class="p">(</span><span class="s s-Atom">call_args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">if</span> <span class="s s-Atom">call_signature</span><span class="p">.</span><span class="nn">defaults</span><span class="p">:</span>

            <span class="s s-Atom">call_args</span> <span class="o">=</span> <span class="s s-Atom">call_args</span><span class="p">[</span><span class="mi">2</span><span class="p">:-</span><span class="nf">len</span><span class="p">(</span><span class="s s-Atom">call_signature</span><span class="p">.</span><span class="s s-Atom">defaults</span><span class="p">)]</span>

          <span class="nn">else</span><span class="p">:</span>

            <span class="s s-Atom">call_args</span> <span class="o">=</span> <span class="s s-Atom">call_args</span><span class="p">[</span><span class="mi">2</span><span class="s s-Atom">:</span><span class="p">]</span>

          <span class="s s-Atom">for</span> <span class="s s-Atom">arg</span> <span class="s s-Atom">in</span> <span class="s s-Atom">call_args:</span>

            <span class="s s-Atom">if</span> <span class="s s-Atom">arg</span> <span class="o">==</span> <span class="s s-Atom">&#39;training&#39;:</span>

              <span class="s s-Atom">#</span> <span class="nv">Case</span> <span class="s s-Atom">where</span> <span class="err">`</span><span class="s s-Atom">training</span><span class="err">`</span> <span class="o">is</span> <span class="s s-Atom">a</span> <span class="s s-Atom">positional</span> <span class="s s-Atom">arg</span> <span class="s s-Atom">with</span> <span class="s s-Atom">no</span> <span class="s s-Atom">default</span><span class="p">.</span>

              <span class="s s-Atom">kwargs</span><span class="p">[</span><span class="s s-Atom">&#39;training&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nv">False</span>

            <span class="nn">else</span><span class="p">:</span>

              <span class="s s-Atom">#</span> <span class="nv">Has</span> <span class="s s-Atom">invalid</span> <span class="s s-Atom">call</span> <span class="s s-Atom">signature</span> <span class="s s-Atom">with</span> <span class="s s-Atom">unknown</span> <span class="s s-Atom">positional</span> <span class="s s-Atom">arguments</span><span class="p">.</span>

              <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span>

                  <span class="s s-Atom">&#39;Currently, you cannot build your model if it has &#39;</span>

                  <span class="s s-Atom">&#39;positional or keyword arguments that are not &#39;</span>

                  <span class="s s-Atom">&#39;inputs to the model, but are required for its &#39;</span>

                  <span class="s s-Atom">&#39;`call` method. Instead, in order to instantiate &#39;</span>

                  <span class="s s-Atom">&#39;and build your model, `call` your model on real &#39;</span>

                  <span class="s s-Atom">&#39;tensor data with all expected call arguments.&#39;</span><span class="p">)</span>

        <span class="s s-Atom">elif</span> <span class="nf">len</span><span class="p">(</span><span class="s s-Atom">call_args</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">#</span> <span class="nv">Signature</span> <span class="s s-Atom">without</span> <span class="err">`</span><span class="s s-Atom">inputs</span><span class="err">`</span><span class="p">.</span>

          <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;You can only call `build` on a model if its `call` &#39;</span>

                           <span class="s s-Atom">&#39;method accepts an `inputs` argument.&#39;</span><span class="p">)</span>

        <span class="nn">try</span><span class="p">:</span>

          <span class="s s-Atom">self</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="s s-Atom">x</span><span class="p">,</span> <span class="s s-Atom">**kwargs</span><span class="p">)</span>

        <span class="nf">except</span> <span class="p">(</span><span class="s s-Atom">errors</span><span class="p">.</span><span class="nv">InvalidArgumentError</span><span class="p">,</span> <span class="nv">TypeError</span><span class="p">)</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;You cannot build your model by calling `build` &#39;</span>

                           <span class="s s-Atom">&#39;if your layers do not support float type inputs. &#39;</span>

                           <span class="s s-Atom">&#39;Instead, in order to instantiate and build your &#39;</span>

                           <span class="s s-Atom">&#39;model, `call` your model on real tensor data (of &#39;</span>

                           <span class="s s-Atom">&#39;the correct dtype).&#39;</span><span class="p">)</span>

    <span class="nf">super</span><span class="p">(</span><span class="nv">Model</span><span class="p">,</span> <span class="s s-Atom">self</span><span class="p">).</span><span class="nf">build</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="call">call</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">training</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference in training.</p>
<p>Arguments:</p>
<ul>
<li>
<p><em>inputs</em>: Tuple</p>
<ol>
<li>images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</li>
<li>image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape
of the image without any padding.</li>
<li>images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None] composed of 0 and 1 which allows to know where a padding has been applied.</li>
</ol>
</li>
<li>
<p><em>training</em>: Is automatically set to <code>True</code> in train mode</p>
</li>
</ul>
<p>Returns:</p>
<ul>
<li><em>logits</em>: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</li>
<li><em>boxes</em>: A Tensor of shape [batch_size, num_queries, 4]</li>
</ul>
<p>where h is num_queries * transformer_decoder.transformer_num_layers if
training is true and num_queries otherwise.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Perform an inference in training.</span>

<span class="s2">        Arguments:</span>

<span class="s2">        - *inputs*: Tuple</span>

<span class="s2">            1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</span>

<span class="s2">            2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape</span>

<span class="s2">            of the image without any padding.</span>

<span class="s2">            3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None] composed of 0 and 1 which allows to know where a padding has been applied.</span>

<span class="s2">        - *training*: Is automatically set to `True` in train mode</span>

<span class="s2">        Returns:</span>

<span class="s2">        - *logits*: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="s2">        - *boxes*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="s2">        where h is num_queries * transformer_decoder.transformer_num_layers if</span>

<span class="s2">        training is true and num_queries otherwise.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="n">images</span> <span class="o">=</span> <span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="err">]</span>

        <span class="n">images_padding_masks</span> <span class="o">=</span> <span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES_PMASK</span><span class="err">]</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

        <span class="c1"># The preprocessing dedicated to the backbone is done inside the model.</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="o">-</span><span class="mi">1</span><span class="err">]</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">images_padding_masks</span><span class="err">[</span><span class="p">...,</span> <span class="k">None</span><span class="err">]</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span>

                                        <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="err">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">3</span><span class="err">]</span><span class="p">,</span>

                                        <span class="n">method</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">ResizeMethod</span><span class="p">.</span><span class="n">NEAREST_NEIGHBOR</span><span class="p">)</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="kt">bool</span><span class="p">)</span>

        <span class="c1"># Positional_encoding for the backbone</span>

        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">pos_embed</span><span class="p">(</span><span class="n">features_mask</span><span class="p">)</span>

        <span class="c1"># [batch_size, num_queries, self.hidden_dim]</span>

        <span class="n">all_the_queries</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">all_the_queries</span><span class="err">[</span><span class="k">None</span><span class="err">]</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># [batch_size, num_queries, self.hidden_dim]</span>

        <span class="n">query_embed</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">query_embed</span><span class="p">(</span><span class="n">all_the_queries</span><span class="p">)</span>

        <span class="c1"># add positional_encoding to x [batch_size, h, w, self.hidden_dim]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">input_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Flatten the position embedding and the spatial tensor</span>

        <span class="c1"># to allow the preprocessing by the Transformer</span>

        <span class="c1"># [batch_size, h * w,  self.hidden_dim]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="c1"># Flatten the padding masks</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">decoder_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>

                                          <span class="n">pos_embed</span><span class="p">,</span>

                                          <span class="n">query_embed</span><span class="p">,</span>

                                          <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">features_mask</span><span class="p">,</span>

                                          <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="n">boxes</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">bbox_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">class_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span>

        <span class="k">return</span> <span class="err">{</span>

            <span class="n">BoxField</span><span class="p">.</span><span class="n">SCORES</span><span class="o">:</span> <span class="n">logits</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="p">.</span><span class="n">BOXES</span><span class="o">:</span> <span class="n">boxes</span><span class="p">,</span>

        <span class="err">}</span>
</code></pre></div>

</details>
<h4 id="compile">compile</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Configures the model for training.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>optimizer</td>
<td>None</td>
<td>String (name of optimizer) or optimizer instance. See</td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.optimizers</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>loss</td>
<td>None</td>
<td>String (name of objective function), objective function or</td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.losses.Loss</code> instance. See <code>tf.keras.losses</code>. An objective</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function is any callable with the signature `loss = fn(y_true,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>y_pred)`, where y_true = ground truth values with shape =</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>[batch_size, d0, .. dN]</code>, except sparse loss functions such as sparse</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>categorical crossentropy where shape = <code>[batch_size, d0, .. dN-1]</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>y_pred = predicted values with shape = <code>[batch_size, d0, .. dN]</code>. It</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returns a weighted loss float tensor. If a custom <code>Loss</code> instance is</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>used and reduction is set to NONE, return value has the shape</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>[batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>otherwise, it is a scalar. If the model has multiple outputs, you can</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>use a different loss on each output by passing a dictionary or a list</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of losses. The loss value that will be minimized by the model will</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>then be the sum of all individual losses.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>metrics</td>
<td>None</td>
<td>List of metrics to be evaluated by the model during training</td>
<td></td>
</tr>
<tr>
<td>and testing. Each of this can be a string (name of a built-in</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function), function or a <code>tf.keras.metrics.Metric</code> instance. See</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics</code>. Typically you will use <code>metrics=['accuracy']</code>. A</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function is any callable with the signature `result = fn(y_true,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>y_pred)`. To specify different metrics for different outputs of a</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>multi-output model, you could also pass a dictionary, such as</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>You can also pass a list (len = len(outputs)) of lists of metrics</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>such as <code>metrics=[['accuracy'], ['accuracy', 'mse']]</code> or</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>metrics=['accuracy', ['accuracy', 'mse']]</code>. When you pass the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>strings 'accuracy' or 'acc', we convert this to one of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics.BinaryAccuracy</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics.CategoricalAccuracy</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics.SparseCategoricalAccuracy</code> based on the loss</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function used and the model output shape. We do a similar</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>conversion for the strings 'crossentropy' and 'ce' as well.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>loss_weights</td>
<td>None</td>
<td>Optional list or dictionary specifying scalar coefficients</td>
<td></td>
</tr>
<tr>
<td>(Python floats) to weight the loss contributions of different model</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>outputs. The loss value that will be minimized by the model will then</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>be the <em>weighted sum</em> of all individual losses, weighted by the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>loss_weights</code> coefficients.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>If a list, it is expected to have a 1:1 mapping to the model's</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>outputs. If a dict, it is expected to map output names (strings)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>to scalar coefficients.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>weighted_metrics</td>
<td>None</td>
<td>List of metrics to be evaluated and weighted by</td>
<td></td>
</tr>
<tr>
<td>sample_weight or class_weight during training and testing.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>run_eagerly</td>
<td>None</td>
<td>Bool. Defaults to <code>False</code>. If <code>True</code>, this <code>Model</code>'s</td>
<td></td>
</tr>
<tr>
<td>logic will not be wrapped in a <code>tf.function</code>. Recommended to leave</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>this as <code>None</code> unless your <code>Model</code> cannot be run inside a</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.function</code>.</td>
<td><code>False</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td>steps_per_execution</td>
<td>None</td>
<td>Int. Defaults to 1. The number of batches to</td>
<td></td>
</tr>
<tr>
<td>run during each <code>tf.function</code> call. Running multiple batches</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>inside a single <code>tf.function</code> call can greatly improve performance</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>on TPUs or small models with a large Python overhead.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>At most, one full epoch will be run each</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>execution. If a number larger than the size of the epoch is passed,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the execution will be truncated to the size of the epoch.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Note that if <code>steps_per_execution</code> is set to <code>N</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>Callback.on_batch_begin</code> and <code>Callback.on_batch_end</code> methods</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>will only be called every <code>N</code> batches</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(i.e. before/after each <code>tf.function</code> execution).</td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Arguments supported for backwards compatibility only.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>In case of invalid arguments for</td>
</tr>
<tr>
<td><code>optimizer</code>, <code>loss</code> or <code>metrics</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">compile</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

              <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>

              <span class="n">loss</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">metrics</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">loss_weights</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">weighted_metrics</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">run_eagerly</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">steps_per_execution</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Configures the model for training.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        optimizer: String (name of optimizer) or optimizer instance. See</span>

<span class="s2">          `tf.keras.optimizers`.</span>

<span class="s2">        loss: String (name of objective function), objective function or</span>

<span class="s2">          `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective</span>

<span class="s2">          function is any callable with the signature `loss = fn(y_true,</span>

<span class="s2">          y_pred)`, where y_true = ground truth values with shape =</span>

<span class="s2">          `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse</span>

<span class="s2">          categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.</span>

<span class="s2">          y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It</span>

<span class="s2">          returns a weighted loss float tensor. If a custom `Loss` instance is</span>

<span class="s2">          used and reduction is set to NONE, return value has the shape</span>

<span class="s2">          [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;</span>

<span class="s2">          otherwise, it is a scalar. If the model has multiple outputs, you can</span>

<span class="s2">          use a different loss on each output by passing a dictionary or a list</span>

<span class="s2">          of losses. The loss value that will be minimized by the model will</span>

<span class="s2">          then be the sum of all individual losses.</span>

<span class="s2">        metrics: List of metrics to be evaluated by the model during training</span>

<span class="s2">          and testing. Each of this can be a string (name of a built-in</span>

<span class="s2">          function), function or a `tf.keras.metrics.Metric` instance. See</span>

<span class="s2">          `tf.keras.metrics`. Typically you will use `metrics=[&#39;accuracy&#39;]`. A</span>

<span class="s2">          function is any callable with the signature `result = fn(y_true,</span>

<span class="s2">          y_pred)`. To specify different metrics for different outputs of a</span>

<span class="s2">          multi-output model, you could also pass a dictionary, such as</span>

<span class="s2">            `metrics={&#39;output_a&#39;: &#39;accuracy&#39;, &#39;output_b&#39;: [&#39;accuracy&#39;, &#39;mse&#39;]}`.</span>

<span class="s2">              You can also pass a list (len = len(outputs)) of lists of metrics</span>

<span class="s2">              such as `metrics=[[&#39;accuracy&#39;], [&#39;accuracy&#39;, &#39;mse&#39;]]` or</span>

<span class="s2">              `metrics=[&#39;accuracy&#39;, [&#39;accuracy&#39;, &#39;mse&#39;]]`. When you pass the</span>

<span class="s2">              strings &#39;accuracy&#39; or &#39;acc&#39;, we convert this to one of</span>

<span class="s2">              `tf.keras.metrics.BinaryAccuracy`,</span>

<span class="s2">              `tf.keras.metrics.CategoricalAccuracy`,</span>

<span class="s2">              `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss</span>

<span class="s2">              function used and the model output shape. We do a similar</span>

<span class="s2">              conversion for the strings &#39;crossentropy&#39; and &#39;ce&#39; as well.</span>

<span class="s2">        loss_weights: Optional list or dictionary specifying scalar coefficients</span>

<span class="s2">          (Python floats) to weight the loss contributions of different model</span>

<span class="s2">          outputs. The loss value that will be minimized by the model will then</span>

<span class="s2">          be the *weighted sum* of all individual losses, weighted by the</span>

<span class="s2">          `loss_weights` coefficients.</span>

<span class="s2">            If a list, it is expected to have a 1:1 mapping to the model&#39;s</span>

<span class="s2">              outputs. If a dict, it is expected to map output names (strings)</span>

<span class="s2">              to scalar coefficients.</span>

<span class="s2">        weighted_metrics: List of metrics to be evaluated and weighted by</span>

<span class="s2">          sample_weight or class_weight during training and testing.</span>

<span class="s2">        run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`&#39;s</span>

<span class="s2">          logic will not be wrapped in a `tf.function`. Recommended to leave</span>

<span class="s2">          this as `None` unless your `Model` cannot be run inside a</span>

<span class="s2">          `tf.function`.</span>

<span class="s2">        steps_per_execution: Int. Defaults to 1. The number of batches to</span>

<span class="s2">          run during each `tf.function` call. Running multiple batches</span>

<span class="s2">          inside a single `tf.function` call can greatly improve performance</span>

<span class="s2">          on TPUs or small models with a large Python overhead.</span>

<span class="s2">          At most, one full epoch will be run each</span>

<span class="s2">          execution. If a number larger than the size of the epoch is passed,</span>

<span class="s2">          the execution will be truncated to the size of the epoch.</span>

<span class="s2">          Note that if `steps_per_execution` is set to `N`,</span>

<span class="s2">          `Callback.on_batch_begin` and `Callback.on_batch_end` methods</span>

<span class="s2">          will only be called every `N` batches</span>

<span class="s2">          (i.e. before/after each `tf.function` execution).</span>

<span class="s2">        **kwargs: Arguments supported for backwards compatibility only.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: In case of invalid arguments for</span>

<span class="s2">            `optimizer`, `loss` or `metrics`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;compile&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="k">if</span> <span class="s1">&#39;experimental_steps_per_execution&#39;</span> <span class="k">in</span> <span class="n">kwargs</span><span class="o">:</span>

        <span class="n">logging</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;The argument `steps_per_execution` is no longer &#39;</span>

                     <span class="s1">&#39;experimental. Pass `steps_per_execution` instead of &#39;</span>

                     <span class="s1">&#39;`experimental_steps_per_execution`.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="k">not</span> <span class="n">steps_per_execution</span><span class="o">:</span>

          <span class="n">steps_per_execution</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;experimental_steps_per_execution&#39;</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_validate_compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_run_eagerly</span> <span class="o">=</span> <span class="n">run_eagerly</span>

      <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span> <span class="o">=</span> <span class="n">compile_utils</span><span class="p">.</span><span class="n">LossesContainer</span><span class="p">(</span>

          <span class="n">loss</span><span class="p">,</span> <span class="n">loss_weights</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">compiled_metrics</span> <span class="o">=</span> <span class="n">compile_utils</span><span class="p">.</span><span class="n">MetricsContainer</span><span class="p">(</span>

          <span class="n">metrics</span><span class="p">,</span> <span class="n">weighted_metrics</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_configure_steps_per_execution</span><span class="p">(</span><span class="n">steps_per_execution</span> <span class="k">or</span> <span class="mi">1</span><span class="p">)</span>

      <span class="c1"># Initializes attrs that are reset each time `compile` is called.</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_reset_compile_cache</span><span class="p">()</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_is_compiled</span> <span class="o">=</span> <span class="no">True</span>

      <span class="n">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="k">or</span> <span class="err">{}</span>  <span class="c1"># Backwards compat.</span>
</code></pre></div>

</details>
<h4 id="compute_loss">compute_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">ground_truths</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</code></pre></div>

<p>Apply the GIoU, L1 and SCC to each layers of the transformer decoder</p>
<p>Arguments:</p>
<ul>
<li><em>ground_truths</em>:
   see output kerod.dataset.preprocessing for the doc</li>
<li><em>y_pred</em>: A dict<ul>
<li>*scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</li>
<li><em>bbox</em>: A Tensor of shape [batch_size, num_queries, 4]</li>
</ul>
</li>
<li><em>input_shape</em>: [height, width] of the input tensor. It is the shape of the images will all the
padding included. It is used to normalize the ground_truths boxes.</li>
</ul>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_loss</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">ground_truths</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">input_shape</span><span class="p">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span><span class="w"></span>

<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nc">int</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Apply the GIoU, L1 and SCC to each layers of the transformer decoder</span>

<span class="ss">        Arguments:</span>

<span class="ss">        - *ground_truths*:</span>

<span class="ss">           see output kerod.dataset.preprocessing for the doc</span>

<span class="ss">        - *y_pred*: A dict</span>

<span class="ss">            - *scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="ss">            - *bbox*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="ss">        - *input_shape*: [height, width] of the input tensor. It is the shape of the images will all the</span>

<span class="ss">        padding included. It is used to normalize the ground_truths boxes.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">input_shape</span><span class="o">[</span><span class="n">None</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">1, 2</span><span class="o">]</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">centered_normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">convert_to_center_coordinates</span><span class="p">(</span><span class="n">normalized_boxes</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">add</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">because</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">background</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">counted</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">LABELS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">centered_normalized_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">WEIGHTS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.WEIGHTS</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">NUM_BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="err">}</span><span class="w"></span>

<span class="w">        </span><span class="n">boxes_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">logits_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.SCORES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">y_pred_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">{</span>

<span class="n">            BoxField.BOXES: boxes,</span>

<span class="n">            BoxField.SCORES: logits</span>

<span class="n">        } for boxes, logits in zip(boxes_per_lvl, logits_per_lvl)</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="n">num_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="p">),</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="k">Compute</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Giou</span><span class="p">,</span><span class="w"> </span><span class="n">L1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">SCC</span><span class="w"> </span><span class="k">at</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">layers</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">transformer</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">enumerate</span><span class="p">(</span><span class="n">y_pred_per_lvl</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">Logs</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">            </span><span class="n">compute_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">num_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_mask">compute_mask</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_mask</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Computes an output mask tensor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Tensor or list of tensors.</td>
<td>None</td>
</tr>
<tr>
<td>mask</td>
<td>None</td>
<td>Tensor or list of tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>None or a tensor (or list of tensors,</td>
</tr>
<tr>
<td>one per output tensor of the layer).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@generic_utils</span><span class="p">.</span><span class="k">default</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">compute_mask</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">mask</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="err">:</span><span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="nl">pylint</span><span class="p">:</span><span class="w"> </span><span class="n">disable</span><span class="o">=</span><span class="n">unused</span><span class="o">-</span><span class="n">argument</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Computes an output mask tensor.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        inputs: Tensor or list of tensors.</span>

<span class="ss">        mask: Tensor or list of tensors.</span>

<span class="ss">    Returns:</span>

<span class="ss">        None or a tensor (or list of tensors,</span>

<span class="ss">            one per output tensor of the layer).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">_supports_masking</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">any</span><span class="p">(</span><span class="n">m</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">name</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s1">&#39; does not support masking, &#39;</span><span class="w"></span>

<span class="w">                        </span><span class="s1">&#39;but was passed an input_mask: &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">str</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span><span class="w"></span>

<span class="w">      </span><span class="err">#</span><span class="w"> </span><span class="n">masking</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="nl">supported</span><span class="p">:</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">mask</span><span class="p">.</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">masking</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="n">supported</span><span class="p">,</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="k">default</span><span class="w"></span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="n">carry</span><span class="w"> </span><span class="k">over</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">input</span><span class="w"> </span><span class="n">mask</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">mask</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_output_shape">compute_output_shape</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_shape</span>
<span class="p">)</span>
</code></pre></div>

<p>Computes the output shape of the layer.</p>
<p>If the layer has not been built, this method will call <code>build</code> on the
layer. This assumes that the layer will later be used with inputs that
match the input shape provided here.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_shape</td>
<td>None</td>
<td>Shape tuple (tuple of integers)</td>
<td></td>
</tr>
<tr>
<td>or list of shape tuples (one per output tensor of the layer).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Shape tuples can include None for free dimensions,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>instead of an integer.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>An input shape tuple.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">compute_output_shape</span>(<span class="nb">self</span>, <span class="n">input_shape</span>):

    <span class="s">&quot;&quot;&quot;Computes the output shape of the layer.</span>

<span class="s">    If the layer has not been built, this method will call `build` on the</span>

<span class="s">    layer. This assumes that the layer will later be used with inputs that</span>

<span class="s">    match the input shape provided here.</span>

<span class="s">    Arguments:</span>

<span class="s">        input_shape: Shape tuple (tuple of integers)</span>

<span class="s">            or list of shape tuples (one per output tensor of the layer).</span>

<span class="s">            Shape tuples can include None for free dimensions,</span>

<span class="s">            instead of an integer.</span>

<span class="s">    Returns:</span>

<span class="s">        An input shape tuple.</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">context</span>.<span class="n">executing_eagerly</span>():

      <span class="c1"># In this case we build the model first in order to do shape inference.</span>

      <span class="c1"># This is acceptable because the framework only calls</span>

      <span class="c1"># `compute_output_shape` on shape values that the layer would later be</span>

      <span class="c1"># built for. It would however cause issues in case a user attempts to</span>

      <span class="c1"># use `compute_output_shape` manually with shapes that are incompatible</span>

      <span class="c1"># with the shape the Layer will be called on (these users will have to</span>

      <span class="c1"># implement `compute_output_shape` themselves).</span>

      <span class="nb">self</span>.<span class="n">_maybe_build</span>(<span class="n">input_shape</span>)

      <span class="k">with</span> <span class="n">func_graph</span>.<span class="n">FuncGraph</span>(<span class="n">str</span>(<span class="nb">self</span>.<span class="nb">name</span>) + <span class="s">&#39;_scratch_graph&#39;</span>).<span class="n">as_default</span>():

        <span class="n">input_shape</span> = <span class="n">tf_utils</span>.<span class="n">convert_shapes</span>(<span class="n">input_shape</span>, <span class="n">to_tuples</span>=<span class="nb">False</span>)

        <span class="n">def</span> <span class="n">_make_placeholder_like</span>(<span class="nb">shape</span>):

          <span class="n">ph</span> = <span class="n">backend</span>.<span class="nb">placeholder</span>(<span class="nb">shape</span>=<span class="nb">shape</span>, <span class="n">dtype</span>=<span class="nb">self</span>.<span class="n">dtype</span>)

          <span class="n">ph</span>.<span class="n">_keras_mask</span> = <span class="n">None</span>

          <span class="k">return</span> <span class="n">ph</span>

        <span class="n">inputs</span> = <span class="n">nest</span>.<span class="n">map_structure</span>(<span class="n">_make_placeholder_like</span>, <span class="n">input_shape</span>)

        <span class="n">try:</span>

          <span class="n">outputs</span> = <span class="nb">self</span>(<span class="n">inputs</span>, <span class="n">training</span>=<span class="nb">False</span>)

        <span class="n">except</span> <span class="n">TypeError</span> <span class="n">as</span> <span class="n">e:</span>

          <span class="n">six</span>.<span class="n">raise_from</span>(

              <span class="n">NotImplementedError</span>(

                  <span class="s">&#39;We could not automatically infer the static shape of the &#39;</span>

                  <span class="s">&#39;layer\&#39;s output. Please implement the &#39;</span>

                  <span class="s">&#39;`compute_output_shape` method on your layer (%s).&#39;</span> %

                  <span class="nb">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>), <span class="nb">e</span>)

      <span class="k">return</span> <span class="n">nest</span>.<span class="n">map_structure</span>(<span class="n">lambda</span> <span class="n">t:</span> <span class="nb">t</span>.<span class="nb">shape</span>, <span class="n">outputs</span>)

    <span class="n">raise</span> <span class="n">NotImplementedError</span>(

        <span class="s">&#39;Please run in eager mode or implement the `compute_output_shape` &#39;</span>

        <span class="s">&#39;method on your layer (%s).&#39;</span> % <span class="nb">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>)
</code></pre></div>

</details>
<h4 id="compute_output_signature">compute_output_signature</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_output_signature</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_signature</span>
<span class="p">)</span>
</code></pre></div>

<p>Compute the output tensor signature of the layer based on the inputs.</p>
<p>Unlike a TensorShape object, a TensorSpec object contains both shape
and dtype information for a tensor. This method allows layers to provide
output dtype information if it is different from the input dtype.
For any layer that doesn't implement this function,
the framework will fall back to use <code>compute_output_shape</code>, and will
assume that the output dtype matches the input dtype.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_signature</td>
<td>None</td>
<td>Single TensorSpec or nested structure of TensorSpec</td>
<td></td>
</tr>
<tr>
<td>objects, describing a candidate input for the layer.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Single TensorSpec or nested structure of TensorSpec objects, describing</td>
</tr>
<tr>
<td>how the layer would transform the provided input.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>TypeError</td>
<td>If input_signature contains a non-TensorSpec object.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.for_subclass_implementers</span>

  <span class="n">def</span> <span class="n">compute_output_signature</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_signature</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Compute the output tensor signature of the layer based on the inputs.</span>

<span class="s2">    Unlike a TensorShape object, a TensorSpec object contains both shape</span>

<span class="s2">    and dtype information for a tensor. This method allows layers to provide</span>

<span class="s2">    output dtype information if it is different from the input dtype.</span>

<span class="s2">    For any layer that doesn&#39;t implement this function,</span>

<span class="s2">    the framework will fall back to use `compute_output_shape`, and will</span>

<span class="s2">    assume that the output dtype matches the input dtype.</span>

<span class="s2">    Args:</span>

<span class="s2">      input_signature: Single TensorSpec or nested structure of TensorSpec</span>

<span class="s2">        objects, describing a candidate input for the layer.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Single TensorSpec or nested structure of TensorSpec objects, describing</span>

<span class="s2">        how the layer would transform the provided input.</span>

<span class="s2">    Raises:</span>

<span class="s2">      TypeError: If input_signature contains a non-TensorSpec object.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">def</span> <span class="n">check_type_return_shape</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">:</span>

      <span class="k">if</span> <span class="k">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tensor_spec</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">)</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">TypeError</span><span class="p">(</span>

            <span class="s1">&#39;Only TensorSpec signature types are supported, &#39;</span>

            <span class="s1">&#39;but saw signature signature entry: {}.&#39;</span><span class="p">.</span><span class="k">format</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

      <span class="k">return</span> <span class="n">s</span><span class="p">.</span><span class="n">shape</span>

    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">check_type_return_shape</span><span class="p">,</span> <span class="n">input_signature</span><span class="p">)</span>

    <span class="n">output_shape</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_compute_dtype</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">input_dtypes</span> <span class="o">=</span> <span class="err">[</span><span class="n">s</span><span class="p">.</span><span class="n">dtype</span> <span class="k">for</span> <span class="n">s</span> <span class="k">in</span> <span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">input_signature</span><span class="p">)</span><span class="err">]</span>

      <span class="c1"># Default behavior when self.dtype is None, is to use the first input&#39;s</span>

      <span class="c1"># dtype.</span>

      <span class="n">dtype</span> <span class="o">=</span> <span class="n">input_dtypes</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

    <span class="k">return</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

        <span class="n">lambda</span> <span class="n">s</span><span class="o">:</span> <span class="n">tensor_spec</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">s</span><span class="p">),</span>

        <span class="n">output_shape</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="count_params">count_params</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">count_params</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Count the total number of scalars composing the weights.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>An integer count.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if the layer isn't yet built</td>
</tr>
<tr>
<td>(in which case its weights aren't yet defined).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">count_params</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Count the total number of scalars composing the weights.</span>

<span class="s2">    Returns:</span>

<span class="s2">        An integer count.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: if the layer isn&#39;t yet built</span>

<span class="s2">          (in which case its weights aren&#39;t yet defined).</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_is_graph_network&#39;</span><span class="p">,</span> <span class="no">False</span><span class="p">)</span><span class="o">:</span>

        <span class="k">with</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">maybe_init_scope</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_maybe_build</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">inputs</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;You tried to call `count_params` on &#39;</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="k">name</span> <span class="o">+</span>

                         <span class="s1">&#39;, but the layer isn</span><span class="se">\&#39;</span><span class="s1">t built. &#39;</span>

                         <span class="s1">&#39;You can build it manually via: `&#39;</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="k">name</span> <span class="o">+</span>

                         <span class="s1">&#39;.build(batch_input_shape)`.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">layer_utils</span><span class="p">.</span><span class="n">count_params</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="evaluate">evaluate</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Computation is done in batches (see the <code>batch_size</code> arg.)</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:</td>
<td></td>
</tr>
<tr>
<td>- A Numpy array (or array-like), or a list of arrays</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A TensorFlow tensor, or a list of tensors</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A dict mapping input names to the corresponding array/tensors,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>if the model has named inputs.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A <code>tf.data</code> dataset. Should return a tuple</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of either <code>(inputs, targets)</code> or</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>(inputs, targets, sample_weights)</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>or <code>(inputs, targets, sample_weights)</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>A more detailed description of unpacking behavior for iterator types</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(Dataset, generator, Sequence) is given in the `Unpacking behavior</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>for iterator-like inputs<code>section of</code>Model.fit`.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy</td>
<td></td>
</tr>
<tr>
<td>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(you cannot have Numpy inputs and tensor targets, or inversely). If</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>x</code> is a dataset, generator or <code>keras.utils.Sequence</code> instance, <code>y</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>should not be specified (since targets will be obtained from the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>iterator/dataset).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Integer or <code>None</code>. Number of samples per batch of</td>
<td></td>
</tr>
<tr>
<td>computation. If unspecified, <code>batch_size</code> will default to 32. Do not</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>specify the <code>batch_size</code> if your data is in the form of a dataset,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>generators, or <code>keras.utils.Sequence</code> instances (since they generate</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>batches).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>verbose</td>
<td>None</td>
<td>0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional Numpy array of weights for the test samples,</td>
<td></td>
</tr>
<tr>
<td>used for weighting the loss function. You can either pass a flat (1D)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Numpy array with the same length as the input samples</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(1:1 mapping between weights and samples), or in the case of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>temporal data, you can pass a 2D array with shape `(samples,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sequence_length)`, to apply a different weight to every timestep</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of every sample. This argument is not supported when <code>x</code> is a</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>dataset, instead pass sample weights as the third element of <code>x</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>steps</td>
<td>None</td>
<td>Integer or <code>None</code>. Total number of steps (batches of samples)</td>
<td></td>
</tr>
<tr>
<td>before declaring the evaluation round finished. Ignored with the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>default value of <code>None</code>. If x is a <code>tf.data</code> dataset and <code>steps</code> is</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>None, 'evaluate' will run until the dataset is exhausted. This</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>argument is not supported with array inputs.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>callbacks</td>
<td>None</td>
<td>List of <code>keras.callbacks.Callback</code> instances. List of</td>
<td></td>
</tr>
<tr>
<td>callbacks to apply during evaluation. See</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>max_queue_size</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code></td>
<td></td>
</tr>
<tr>
<td>input only. Maximum size for the generator queue. If unspecified,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>max_queue_size</code> will default to 10.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>workers</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input</td>
<td></td>
</tr>
<tr>
<td>only. Maximum number of processes to spin up when using process-based</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>threading. If unspecified, <code>workers</code> will default to 1. If 0, will</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>execute the generator on the main thread.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>None</td>
<td>Boolean. Used for generator or</td>
<td></td>
</tr>
<tr>
<td><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>threading. If unspecified, <code>use_multiprocessing</code> will default to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>False</code>. Note that because this implementation relies on</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>multiprocessing, you should not pass non-picklable arguments to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>generator as they can't be passed easily to children processes.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,</td>
<td></td>
</tr>
<tr>
<td>with each key being the name of the metric. If <code>False</code>, they are</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returned as a list.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>See the discussion of <code>Unpacking behavior for iterator-like inputs</code> for
<code>Model.fit</code>. | None |</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)</td>
</tr>
<tr>
<td>or list of scalars (if the model has multiple outputs</td>
<td></td>
</tr>
<tr>
<td>and/or metrics). The attribute <code>model.metrics_names</code> will give you</td>
<td></td>
</tr>
<tr>
<td>the display labels for the scalar outputs.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.evaluate</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>in case of invalid arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

               <span class="n">x</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

               <span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

               <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

               <span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

               <span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the loss value &amp; metrics values for the model in test mode.</span>

<span class="s2">    Computation is done in batches (see the `batch_size` arg.)</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">            if the model has named inputs.</span>

<span class="s2">          - A `tf.data` dataset. Should return a tuple</span>

<span class="s2">            of either `(inputs, targets)` or</span>

<span class="s2">            `(inputs, targets, sample_weights)`.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="s2">            or `(inputs, targets, sample_weights)`.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely). If</span>

<span class="s2">          `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`</span>

<span class="s2">          should not be specified (since targets will be obtained from the</span>

<span class="s2">          iterator/dataset).</span>

<span class="s2">        batch_size: Integer or `None`. Number of samples per batch of</span>

<span class="s2">          computation. If unspecified, `batch_size` will default to 32. Do not</span>

<span class="s2">          specify the `batch_size` if your data is in the form of a dataset,</span>

<span class="s2">          generators, or `keras.utils.Sequence` instances (since they generate</span>

<span class="s2">          batches).</span>

<span class="s2">        verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</span>

<span class="s2">        sample_weight: Optional Numpy array of weights for the test samples,</span>

<span class="s2">          used for weighting the loss function. You can either pass a flat (1D)</span>

<span class="s2">          Numpy array with the same length as the input samples</span>

<span class="s2">            (1:1 mapping between weights and samples), or in the case of</span>

<span class="s2">              temporal data, you can pass a 2D array with shape `(samples,</span>

<span class="s2">              sequence_length)`, to apply a different weight to every timestep</span>

<span class="s2">              of every sample. This argument is not supported when `x` is a</span>

<span class="s2">              dataset, instead pass sample weights as the third element of `x`.</span>

<span class="s2">        steps: Integer or `None`. Total number of steps (batches of samples)</span>

<span class="s2">          before declaring the evaluation round finished. Ignored with the</span>

<span class="s2">          default value of `None`. If x is a `tf.data` dataset and `steps` is</span>

<span class="s2">          None, &#39;evaluate&#39; will run until the dataset is exhausted. This</span>

<span class="s2">          argument is not supported with array inputs.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances. List of</span>

<span class="s2">          callbacks to apply during evaluation. See</span>

<span class="s2">          [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">          input only. Maximum size for the generator queue. If unspecified,</span>

<span class="s2">          `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">          only. Maximum number of processes to spin up when using process-based</span>

<span class="s2">          threading. If unspecified, `workers` will default to 1. If 0, will</span>

<span class="s2">          execute the generator on the main thread.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">          `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">          threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">          `False`. Note that because this implementation relies on</span>

<span class="s2">          multiprocessing, you should not pass non-picklable arguments to the</span>

<span class="s2">          generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.evaluate` is wrapped in `tf.function`.</span>

<span class="s2">        ValueError: in case of invalid arguments.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

    <span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;evaluate&#39;</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="c1"># Use cached evaluation data only when it&#39;s called in `Model.fit`</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_fit_frame&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span>

          <span class="k">and</span> <span class="n">tf_inspect</span><span class="p">.</span><span class="n">currentframe</span><span class="p">().</span><span class="n">f_back</span> <span class="k">is</span> <span class="n">self</span><span class="p">.</span><span class="n">_fit_frame</span>

          <span class="k">and</span> <span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">)</span><span class="o">:</span>

        <span class="n">data_handler</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_eval_data_handler</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

        <span class="n">data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">DataHandler</span><span class="p">(</span>

            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>

            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>

            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

            <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

            <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

            <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

            <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

            <span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

      <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

      <span class="k">if</span> <span class="k">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span>

            <span class="n">callbacks</span><span class="p">,</span>

            <span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="err">{}</span>

      <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_begin</span><span class="p">()</span>

      <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">iterator</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span>  <span class="c1"># Single epoch.</span>

        <span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span>

          <span class="k">for</span> <span class="n">step</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span>

            <span class="k">with</span> <span class="n">trace</span><span class="p">.</span><span class="n">Trace</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span>

              <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

              <span class="n">tmp_logs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

              <span class="k">if</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span>

                <span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span>

              <span class="k">logs</span> <span class="o">=</span> <span class="n">tmp_logs</span>  <span class="c1"># No error, now safe to assign to logs.</span>

              <span class="n">end_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">+</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span>

              <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span> <span class="k">logs</span><span class="p">)</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="k">logs</span><span class="o">=</span><span class="k">logs</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">return_dict</span><span class="o">:</span>

        <span class="k">return</span> <span class="k">logs</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">results</span> <span class="o">=</span> <span class="err">[]</span>

        <span class="k">for</span> <span class="k">name</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="o">:</span>

          <span class="k">if</span> <span class="k">name</span> <span class="k">in</span> <span class="k">logs</span><span class="o">:</span>

            <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="k">logs</span><span class="err">[</span><span class="k">name</span><span class="err">]</span><span class="p">)</span>

        <span class="k">for</span> <span class="k">key</span> <span class="k">in</span> <span class="n">sorted</span><span class="p">(</span><span class="k">logs</span><span class="p">.</span><span class="k">keys</span><span class="p">())</span><span class="o">:</span>

          <span class="k">if</span> <span class="k">key</span> <span class="k">not</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="o">:</span>

            <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="k">logs</span><span class="err">[</span><span class="k">key</span><span class="err">]</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

          <span class="k">return</span> <span class="n">results</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

        <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

</details>
<h4 id="evaluate_generator">evaluate_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Evaluates the model on a data generator.</p>
<p>DEPRECATED:
  <code>Model.evaluate</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">evaluate_generator</span><span class="p">(</span><span class="k">self</span><span class="p">,</span>

                         <span class="n">generator</span><span class="p">,</span>

                         <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                         <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                         <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

                         <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                         <span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

                         <span class="k">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Evaluates the model on a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.evaluate` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`Model.evaluate_generator` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `Model.evaluate`, which supports generators.&#39;</span><span class="p">)</span>

    <span class="k">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate_generator&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="k">self</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span>

        <span class="n">generator</span><span class="p">,</span>

        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

        <span class="k">verbose</span><span class="o">=</span><span class="k">verbose</span><span class="p">,</span>

        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="fit">fit</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<p>Arguments:
    x: Input data. It could be:
      - A Numpy array (or array-like), or a list of arrays
        (in case the model has multiple inputs).
      - A TensorFlow tensor, or a list of tensors
        (in case the model has multiple inputs).
      - A dict mapping input names to the corresponding array/tensors,
        if the model has named inputs.
      - A <code>tf.data</code> dataset. Should return a tuple
        of either <code>(inputs, targets)</code> or
        <code>(inputs, targets, sample_weights)</code>.
      - A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code>
        or <code>(inputs, targets, sample_weights)</code>.
      A more detailed description of unpacking behavior for iterator types
      (Dataset, generator, Sequence) is given below.
    y: Target data. Like the input data <code>x</code>,
      it could be either Numpy array(s) or TensorFlow tensor(s).
      It should be consistent with <code>x</code> (you cannot have Numpy inputs and
      tensor targets, or inversely). If <code>x</code> is a dataset, generator,
      or <code>keras.utils.Sequence</code> instance, <code>y</code> should
      not be specified (since targets will be obtained from <code>x</code>).
    batch_size: Integer or <code>None</code>.
        Number of samples per gradient update.
        If unspecified, <code>batch_size</code> will default to 32.
        Do not specify the <code>batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    epochs: Integer. Number of epochs to train the model.
        An epoch is an iteration over the entire <code>x</code> and <code>y</code>
        data provided.
        Note that in conjunction with <code>initial_epoch</code>,
        <code>epochs</code> is to be understood as "final epoch".
        The model is not trained for a number of iterations
        given by <code>epochs</code>, but merely until the epoch
        of index <code>epochs</code> is reached.
    verbose: 0, 1, or 2. Verbosity mode.
        0 = silent, 1 = progress bar, 2 = one line per epoch.
        Note that the progress bar is not particularly useful when
        logged to a file, so verbose=2 is recommended when not running
        interactively (eg, in a production environment).
    callbacks: List of <code>keras.callbacks.Callback</code> instances.
        List of callbacks to apply during training.
        See <code>tf.keras.callbacks</code>. Note <code>tf.keras.callbacks.ProgbarLogger</code>
        and <code>tf.keras.callbacks.History</code> callbacks are created automatically
        and need not be passed into <code>model.fit</code>.
        <code>tf.keras.callbacks.ProgbarLogger</code> is created or not based on
        <code>verbose</code> argument to <code>model.fit</code>.
    validation_split: Float between 0 and 1.
        Fraction of the training data to be used as validation data.
        The model will set apart this fraction of the training data,
        will not train on it, and will evaluate
        the loss and any model metrics
        on this data at the end of each epoch.
        The validation data is selected from the last samples
        in the <code>x</code> and <code>y</code> data provided, before shuffling. This argument is
        not supported when <code>x</code> is a dataset, generator or
       <code>keras.utils.Sequence</code> instance.
    validation_data: Data on which to evaluate
        the loss and any model metrics at the end of each epoch.
        The model will not be trained on this data. Thus, note the fact
        that the validation loss of data provided using <code>validation_split</code>
        or <code>validation_data</code> is not affected by regularization layers like
        noise and dropout.
        <code>validation_data</code> will override <code>validation_split</code>.
        <code>validation_data</code> could be:
          - tuple <code>(x_val, y_val)</code> of Numpy arrays or tensors
          - tuple <code>(x_val, y_val, val_sample_weights)</code> of Numpy arrays
          - dataset
        For the first two cases, <code>batch_size</code> must be provided.
        For the last case, <code>validation_steps</code> could be provided.
        Note that <code>validation_data</code> does not support all the data types that
        are supported in <code>x</code>, eg, dict, generator or <code>keras.utils.Sequence</code>.
    shuffle: Boolean (whether to shuffle the training data
        before each epoch) or str (for 'batch'). This argument is ignored
        when <code>x</code> is a generator. 'batch' is a special option for dealing
        with the limitations of HDF5 data; it shuffles in batch-sized
        chunks. Has no effect when <code>steps_per_epoch</code> is not <code>None</code>.
    class_weight: Optional dictionary mapping class indices (integers)
        to a weight (float) value, used for weighting the loss function
        (during training only).
        This can be useful to tell the model to
        "pay more attention" to samples from
        an under-represented class.
    sample_weight: Optional Numpy array of weights for
        the training samples, used for weighting the loss function
        (during training only). You can either pass a flat (1D)
        Numpy array with the same length as the input samples
        (1:1 mapping between weights and samples),
        or in the case of temporal data,
        you can pass a 2D array with shape
        <code>(samples, sequence_length)</code>,
        to apply a different weight to every timestep of every sample. This
        argument is not supported when <code>x</code> is a dataset, generator, or
       <code>keras.utils.Sequence</code> instance, instead provide the sample_weights
        as the third element of <code>x</code>.
    initial_epoch: Integer.
        Epoch at which to start training
        (useful for resuming a previous training run).
    steps_per_epoch: Integer or <code>None</code>.
        Total number of steps (batches of samples)
        before declaring one epoch finished and starting the
        next epoch. When training with input tensors such as
        TensorFlow data tensors, the default <code>None</code> is equal to
        the number of samples in your dataset divided by
        the batch size, or 1 if that cannot be determined. If x is a
        <code>tf.data</code> dataset, and 'steps_per_epoch'
        is None, the epoch will run until the input dataset is exhausted.
        When passing an infinitely repeating dataset, you must specify the
        <code>steps_per_epoch</code> argument. This argument is not supported with
        array inputs.
    validation_steps: Only relevant if <code>validation_data</code> is provided and
        is a <code>tf.data</code> dataset. Total number of steps (batches of
        samples) to draw before stopping when performing validation
        at the end of every epoch. If 'validation_steps' is None, validation
        will run until the <code>validation_data</code> dataset is exhausted. In the
        case of an infinitely repeated dataset, it will run into an
        infinite loop. If 'validation_steps' is specified and only part of
        the dataset will be consumed, the evaluation will start from the
        beginning of the dataset at each epoch. This ensures that the same
        validation samples are used every time.
    validation_batch_size: Integer or <code>None</code>.
        Number of samples per validation batch.
        If unspecified, will default to <code>batch_size</code>.
        Do not specify the <code>validation_batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    validation_freq: Only relevant if validation data is provided. Integer
        or <code>collections_abc.Container</code> instance (e.g. list, tuple, etc.).
        If an integer, specifies how many training epochs to run before a
        new validation run is performed, e.g. <code>validation_freq=2</code> runs
        validation every 2 epochs. If a Container, specifies the epochs on
        which to run validation, e.g. <code>validation_freq=[1, 2, 10]</code> runs
        validation at the end of the 1st, 2nd, and 10th epochs.
    max_queue_size: Integer. Used for generator or <code>keras.utils.Sequence</code>
        input only. Maximum size for the generator queue.
        If unspecified, <code>max_queue_size</code> will default to 10.
    workers: Integer. Used for generator or <code>keras.utils.Sequence</code> input
        only. Maximum number of processes to spin up
        when using process-based threading. If unspecified, <code>workers</code>
        will default to 1. If 0, will execute the generator on the main
        thread.
    use_multiprocessing: Boolean. Used for generator or
        <code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based
        threading. If unspecified, <code>use_multiprocessing</code> will default to
        <code>False</code>. Note that because this implementation relies on
        multiprocessing, you should not pass non-picklable arguments to
        the generator as they can't be passed easily to children processes.</p>
<p>Unpacking behavior for iterator-like inputs:
    A common pattern is to pass a tf.data.Dataset, generator, or
  tf.keras.utils.Sequence to the <code>x</code> argument of fit, which will in fact
  yield not only features (x) but optionally targets (y) and sample weights.
  Keras requires that the output of such iterator-likes be unambiguous. The
  iterator should return a tuple of length 1, 2, or 3, where the optional
  second and third elements will be used for y and sample_weight
  respectively. Any other type provided will be wrapped in a length one
  tuple, effectively treating everything as 'x'. When yielding dicts, they
  should still adhere to the top-level tuple structure.
  e.g. <code>({"x0": x0, "x1": x1}, y)</code>. Keras will not attempt to separate
  features, targets, and weights from the keys of a single dict.
    A notable unsupported data type is the namedtuple. The reason is that
  it behaves like both an ordered datatype (tuple) and a mapping
  datatype (dict). So given a namedtuple of the form:
      <code>namedtuple("example_tuple", ["y", "x"])</code>
  it is ambiguous whether to reverse the order of the elements when
  interpreting the value. Even worse is a tuple of the form:
      <code>namedtuple("other_tuple", ["x", "y", "z"])</code>
  where it is unclear if the tuple was intended to be unpacked into x, y,
  and sample_weight or passed through as a single element to <code>x</code>. As a
  result the data processing code will simply raise a ValueError if it
  encounters a namedtuple. (Along with instructions to remedy the issue.)</p>
<p>Returns:
    A <code>History</code> object. Its <code>History.history</code> attribute is
    a record of training loss values and metrics values
    at successive epochs, as well as validation loss values
    and validation metrics values (if applicable).</p>
<p>Raises:
    RuntimeError: 1. If the model was never compiled or,
    2. If <code>model.fit</code> is  wrapped in <code>tf.function</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span> <span class="n">In</span> <span class="k">case</span> <span class="n">of</span> <span class="n">mismatch</span> <span class="n">between</span> <span class="n">the</span> <span class="n">provided</span> <span class="n">input</span> <span class="n">data</span>
    <span class="n">and</span> <span class="n">what</span> <span class="n">the</span> <span class="n">model</span> <span class="n">expects</span> <span class="n">or</span> <span class="n">when</span> <span class="n">the</span> <span class="n">input</span> <span class="n">data</span> <span class="k">is</span> <span class="n">empty</span><span class="o">.</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

          <span class="n">x</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">y</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">callbacks</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>

          <span class="n">validation_data</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">shuffle</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

          <span class="n">class_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">sample_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

          <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_steps</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

          <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">False</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Trains the model for a fixed number of epochs (iterations on a dataset).</span>

<span class="sd">    Arguments:</span>

<span class="sd">        x: Input data. It could be:</span>

<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="sd">            if the model has named inputs.</span>

<span class="sd">          - A `tf.data` dataset. Should return a tuple</span>

<span class="sd">            of either `(inputs, targets)` or</span>

<span class="sd">            `(inputs, targets, sample_weights)`.</span>

<span class="sd">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="sd">            or `(inputs, targets, sample_weights)`.</span>

<span class="sd">          A more detailed description of unpacking behavior for iterator types</span>

<span class="sd">          (Dataset, generator, Sequence) is given below.</span>

<span class="sd">        y: Target data. Like the input data `x`,</span>

<span class="sd">          it could be either Numpy array(s) or TensorFlow tensor(s).</span>

<span class="sd">          It should be consistent with `x` (you cannot have Numpy inputs and</span>

<span class="sd">          tensor targets, or inversely). If `x` is a dataset, generator,</span>

<span class="sd">          or `keras.utils.Sequence` instance, `y` should</span>

<span class="sd">          not be specified (since targets will be obtained from `x`).</span>

<span class="sd">        batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per gradient update.</span>

<span class="sd">            If unspecified, `batch_size` will default to 32.</span>

<span class="sd">            Do not specify the `batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        epochs: Integer. Number of epochs to train the model.</span>

<span class="sd">            An epoch is an iteration over the entire `x` and `y`</span>

<span class="sd">            data provided.</span>

<span class="sd">            Note that in conjunction with `initial_epoch`,</span>

<span class="sd">            `epochs` is to be understood as &quot;final epoch&quot;.</span>

<span class="sd">            The model is not trained for a number of iterations</span>

<span class="sd">            given by `epochs`, but merely until the epoch</span>

<span class="sd">            of index `epochs` is reached.</span>

<span class="sd">        verbose: 0, 1, or 2. Verbosity mode.</span>

<span class="sd">            0 = silent, 1 = progress bar, 2 = one line per epoch.</span>

<span class="sd">            Note that the progress bar is not particularly useful when</span>

<span class="sd">            logged to a file, so verbose=2 is recommended when not running</span>

<span class="sd">            interactively (eg, in a production environment).</span>

<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="sd">            List of callbacks to apply during training.</span>

<span class="sd">            See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`</span>

<span class="sd">            and `tf.keras.callbacks.History` callbacks are created automatically</span>

<span class="sd">            and need not be passed into `model.fit`.</span>

<span class="sd">            `tf.keras.callbacks.ProgbarLogger` is created or not based on</span>

<span class="sd">            `verbose` argument to `model.fit`.</span>

<span class="sd">        validation_split: Float between 0 and 1.</span>

<span class="sd">            Fraction of the training data to be used as validation data.</span>

<span class="sd">            The model will set apart this fraction of the training data,</span>

<span class="sd">            will not train on it, and will evaluate</span>

<span class="sd">            the loss and any model metrics</span>

<span class="sd">            on this data at the end of each epoch.</span>

<span class="sd">            The validation data is selected from the last samples</span>

<span class="sd">            in the `x` and `y` data provided, before shuffling. This argument is</span>

<span class="sd">            not supported when `x` is a dataset, generator or</span>

<span class="sd">           `keras.utils.Sequence` instance.</span>

<span class="sd">        validation_data: Data on which to evaluate</span>

<span class="sd">            the loss and any model metrics at the end of each epoch.</span>

<span class="sd">            The model will not be trained on this data. Thus, note the fact</span>

<span class="sd">            that the validation loss of data provided using `validation_split`</span>

<span class="sd">            or `validation_data` is not affected by regularization layers like</span>

<span class="sd">            noise and dropout.</span>

<span class="sd">            `validation_data` will override `validation_split`.</span>

<span class="sd">            `validation_data` could be:</span>

<span class="sd">              - tuple `(x_val, y_val)` of Numpy arrays or tensors</span>

<span class="sd">              - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays</span>

<span class="sd">              - dataset</span>

<span class="sd">            For the first two cases, `batch_size` must be provided.</span>

<span class="sd">            For the last case, `validation_steps` could be provided.</span>

<span class="sd">            Note that `validation_data` does not support all the data types that</span>

<span class="sd">            are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.</span>

<span class="sd">        shuffle: Boolean (whether to shuffle the training data</span>

<span class="sd">            before each epoch) or str (for &#39;batch&#39;). This argument is ignored</span>

<span class="sd">            when `x` is a generator. &#39;batch&#39; is a special option for dealing</span>

<span class="sd">            with the limitations of HDF5 data; it shuffles in batch-sized</span>

<span class="sd">            chunks. Has no effect when `steps_per_epoch` is not `None`.</span>

<span class="sd">        class_weight: Optional dictionary mapping class indices (integers)</span>

<span class="sd">            to a weight (float) value, used for weighting the loss function</span>

<span class="sd">            (during training only).</span>

<span class="sd">            This can be useful to tell the model to</span>

<span class="sd">            &quot;pay more attention&quot; to samples from</span>

<span class="sd">            an under-represented class.</span>

<span class="sd">        sample_weight: Optional Numpy array of weights for</span>

<span class="sd">            the training samples, used for weighting the loss function</span>

<span class="sd">            (during training only). You can either pass a flat (1D)</span>

<span class="sd">            Numpy array with the same length as the input samples</span>

<span class="sd">            (1:1 mapping between weights and samples),</span>

<span class="sd">            or in the case of temporal data,</span>

<span class="sd">            you can pass a 2D array with shape</span>

<span class="sd">            `(samples, sequence_length)`,</span>

<span class="sd">            to apply a different weight to every timestep of every sample. This</span>

<span class="sd">            argument is not supported when `x` is a dataset, generator, or</span>

<span class="sd">           `keras.utils.Sequence` instance, instead provide the sample_weights</span>

<span class="sd">            as the third element of `x`.</span>

<span class="sd">        initial_epoch: Integer.</span>

<span class="sd">            Epoch at which to start training</span>

<span class="sd">            (useful for resuming a previous training run).</span>

<span class="sd">        steps_per_epoch: Integer or `None`.</span>

<span class="sd">            Total number of steps (batches of samples)</span>

<span class="sd">            before declaring one epoch finished and starting the</span>

<span class="sd">            next epoch. When training with input tensors such as</span>

<span class="sd">            TensorFlow data tensors, the default `None` is equal to</span>

<span class="sd">            the number of samples in your dataset divided by</span>

<span class="sd">            the batch size, or 1 if that cannot be determined. If x is a</span>

<span class="sd">            `tf.data` dataset, and &#39;steps_per_epoch&#39;</span>

<span class="sd">            is None, the epoch will run until the input dataset is exhausted.</span>

<span class="sd">            When passing an infinitely repeating dataset, you must specify the</span>

<span class="sd">            `steps_per_epoch` argument. This argument is not supported with</span>

<span class="sd">            array inputs.</span>

<span class="sd">        validation_steps: Only relevant if `validation_data` is provided and</span>

<span class="sd">            is a `tf.data` dataset. Total number of steps (batches of</span>

<span class="sd">            samples) to draw before stopping when performing validation</span>

<span class="sd">            at the end of every epoch. If &#39;validation_steps&#39; is None, validation</span>

<span class="sd">            will run until the `validation_data` dataset is exhausted. In the</span>

<span class="sd">            case of an infinitely repeated dataset, it will run into an</span>

<span class="sd">            infinite loop. If &#39;validation_steps&#39; is specified and only part of</span>

<span class="sd">            the dataset will be consumed, the evaluation will start from the</span>

<span class="sd">            beginning of the dataset at each epoch. This ensures that the same</span>

<span class="sd">            validation samples are used every time.</span>

<span class="sd">        validation_batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per validation batch.</span>

<span class="sd">            If unspecified, will default to `batch_size`.</span>

<span class="sd">            Do not specify the `validation_batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        validation_freq: Only relevant if validation data is provided. Integer</span>

<span class="sd">            or `collections_abc.Container` instance (e.g. list, tuple, etc.).</span>

<span class="sd">            If an integer, specifies how many training epochs to run before a</span>

<span class="sd">            new validation run is performed, e.g. `validation_freq=2` runs</span>

<span class="sd">            validation every 2 epochs. If a Container, specifies the epochs on</span>

<span class="sd">            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs</span>

<span class="sd">            validation at the end of the 1st, 2nd, and 10th epochs.</span>

<span class="sd">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="sd">            input only. Maximum size for the generator queue.</span>

<span class="sd">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="sd">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="sd">            only. Maximum number of processes to spin up</span>

<span class="sd">            when using process-based threading. If unspecified, `workers`</span>

<span class="sd">            will default to 1. If 0, will execute the generator on the main</span>

<span class="sd">            thread.</span>

<span class="sd">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="sd">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="sd">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="sd">            `False`. Note that because this implementation relies on</span>

<span class="sd">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="sd">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="sd">    Unpacking behavior for iterator-like inputs:</span>

<span class="sd">        A common pattern is to pass a tf.data.Dataset, generator, or</span>

<span class="sd">      tf.keras.utils.Sequence to the `x` argument of fit, which will in fact</span>

<span class="sd">      yield not only features (x) but optionally targets (y) and sample weights.</span>

<span class="sd">      Keras requires that the output of such iterator-likes be unambiguous. The</span>

<span class="sd">      iterator should return a tuple of length 1, 2, or 3, where the optional</span>

<span class="sd">      second and third elements will be used for y and sample_weight</span>

<span class="sd">      respectively. Any other type provided will be wrapped in a length one</span>

<span class="sd">      tuple, effectively treating everything as &#39;x&#39;. When yielding dicts, they</span>

<span class="sd">      should still adhere to the top-level tuple structure.</span>

<span class="sd">      e.g. `({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)`. Keras will not attempt to separate</span>

<span class="sd">      features, targets, and weights from the keys of a single dict.</span>

<span class="sd">        A notable unsupported data type is the namedtuple. The reason is that</span>

<span class="sd">      it behaves like both an ordered datatype (tuple) and a mapping</span>

<span class="sd">      datatype (dict). So given a namedtuple of the form:</span>

<span class="sd">          `namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])`</span>

<span class="sd">      it is ambiguous whether to reverse the order of the elements when</span>

<span class="sd">      interpreting the value. Even worse is a tuple of the form:</span>

<span class="sd">          `namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])`</span>

<span class="sd">      where it is unclear if the tuple was intended to be unpacked into x, y,</span>

<span class="sd">      and sample_weight or passed through as a single element to `x`. As a</span>

<span class="sd">      result the data processing code will simply raise a ValueError if it</span>

<span class="sd">      encounters a namedtuple. (Along with instructions to remedy the issue.)</span>

<span class="sd">    Returns:</span>

<span class="sd">        A `History` object. Its `History.history` attribute is</span>

<span class="sd">        a record of training loss values and metrics values</span>

<span class="sd">        at successive epochs, as well as validation loss values</span>

<span class="sd">        and validation metrics values (if applicable).</span>

<span class="sd">    Raises:</span>

<span class="sd">        RuntimeError: 1. If the model was never compiled or,</span>

<span class="sd">        2. If `model.fit` is  wrapped in `tf.function`.</span>

<span class="sd">        ValueError: In case of mismatch between the provided input data</span>

<span class="sd">            and what the model expects or when the input data is empty.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">base_layer</span><span class="o">.</span><span class="n">keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span>

    <span class="c1"># Legacy graph support is contained in `training_v1.Model`.</span>

    <span class="n">version_utils</span><span class="o">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">validation_split</span><span class="p">:</span>

      <span class="c1"># Create the validation data using the training data. Only supported for</span>

      <span class="c1"># `Tensor` and `NumPy` input.</span>

      <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">),</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span>

          <span class="n">data_adapter</span><span class="o">.</span><span class="n">train_validation_split</span><span class="p">(</span>

              <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">),</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">validation_data</span><span class="p">:</span>

      <span class="n">val_x</span><span class="p">,</span> <span class="n">val_y</span><span class="p">,</span> <span class="n">val_sample_weight</span> <span class="o">=</span> <span class="p">(</span>

          <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">validation_data</span><span class="p">))</span>

    <span class="n">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span> \

         <span class="n">training_utils</span><span class="o">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

      <span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

      <span class="n">data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">DataHandler</span><span class="p">(</span>

          <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

          <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>

          <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>

          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

          <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>

          <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>

          <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

          <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>

          <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>

          <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

          <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

          <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

          <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

          <span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

      <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">):</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">(</span>

            <span class="n">callbacks</span><span class="p">,</span>

            <span class="n">add_history</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="n">False</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_train_function</span><span class="p">()</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_train_counter</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span>

      <span class="n">training_logs</span> <span class="o">=</span> <span class="n">None</span>

      <span class="c1"># Handle fault-tolerance for multi-worker.</span>

      <span class="c1"># TODO(omalleyt): Fix the ordering issues that mean this has to</span>

      <span class="c1"># happen after `callbacks.on_train_begin`.</span>

      <span class="n">data_handler</span><span class="o">.</span><span class="n">_initial_epoch</span> <span class="o">=</span> <span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>

          <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_load_initial_epoch_from_ckpt</span><span class="p">(</span><span class="n">initial_epoch</span><span class="p">))</span>

      <span class="n">logs</span> <span class="o">=</span> <span class="n">None</span>

      <span class="k">for</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">iterator</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

        <span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

        <span class="n">with</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span>

          <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span>

            <span class="n">with</span> <span class="n">trace</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span>

                <span class="s1">&#39;train&#39;</span><span class="p">,</span>

                <span class="n">epoch_num</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>

                <span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span>

                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

                <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>

              <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

              <span class="n">tmp_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

              <span class="k">if</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span>

                <span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span>

              <span class="n">logs</span> <span class="o">=</span> <span class="n">tmp_logs</span>  <span class="c1"># No error, now safe to assign to logs.</span>

              <span class="n">end_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">+</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">step_increment</span>

              <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

                <span class="k">break</span>

        <span class="k">if</span> <span class="n">logs</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

          <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Expect x to be a non-empty array or dataset.&#39;</span><span class="p">)</span>

        <span class="n">epoch_logs</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

        <span class="c1"># Run validation.</span>

        <span class="k">if</span> <span class="n">validation_data</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_eval</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">validation_freq</span><span class="p">):</span>

          <span class="c1"># Create data_handler for evaluation and cache it.</span>

          <span class="k">if</span> <span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span> <span class="n">None</span><span class="p">)</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_frame</span> <span class="o">=</span> <span class="n">tf_inspect</span><span class="o">.</span><span class="n">currentframe</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">DataHandler</span><span class="p">(</span>

                <span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>

                <span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>

                <span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>

                <span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span> <span class="ow">or</span> <span class="n">batch_size</span><span class="p">,</span>

                <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

                <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

                <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

                <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

                <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

                <span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

          <span class="n">val_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>

              <span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>

              <span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>

              <span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>

              <span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span> <span class="ow">or</span> <span class="n">batch_size</span><span class="p">,</span>

              <span class="n">steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

              <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

              <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

              <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

              <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

              <span class="n">return_dict</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>

          <span class="n">val_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;val_&#39;</span> <span class="o">+</span> <span class="n">name</span><span class="p">:</span> <span class="n">val</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

          <span class="n">epoch_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_logs</span><span class="p">)</span>

        <span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">epoch_logs</span><span class="p">)</span>

        <span class="n">training_logs</span> <span class="o">=</span> <span class="n">epoch_logs</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

          <span class="k">break</span>

      <span class="c1"># If eval data_hanlder exists, delete it after all epochs are done.</span>

      <span class="k">if</span> <span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span> <span class="n">None</span><span class="p">)</span> <span class="k">is</span> <span class="ow">not</span> <span class="n">None</span><span class="p">:</span>

        <span class="n">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span>

        <span class="n">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_frame</span>

      <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="o">=</span><span class="n">training_logs</span><span class="p">)</span>

      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>

</details>
<h4 id="fit_generator">fit_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Fits the model on data yielded batch-by-batch by a Python generator.</p>
<p>DEPRECATED:
  <code>Model.fit</code> now supports generators, so there is no longer any need to use
  this endpoint.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">fit_generator</span><span class="p">(</span><span class="k">self</span><span class="p">,</span>

                    <span class="n">generator</span><span class="p">,</span>

                    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="k">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">validation_data</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">validation_steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

                    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

                    <span class="n">shuffle</span><span class="o">=</span><span class="k">True</span><span class="p">,</span>

                    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Fits the model on data yielded batch-by-batch by a Python generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.fit` now supports generators, so there is no longer any need to use</span>

<span class="ss">      this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`Model.fit_generator` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `Model.fit`, which supports generators.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="k">self</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>

        <span class="n">generator</span><span class="p">,</span>

        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>

        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

        <span class="k">verbose</span><span class="o">=</span><span class="k">verbose</span><span class="p">,</span>

        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

        <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span>

        <span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

        <span class="n">validation_freq</span><span class="o">=</span><span class="n">validation_freq</span><span class="p">,</span>

        <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>

        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>

        <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_config">get_config</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <code>Network</code> (one layer of abstraction above).</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Python dictionary.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">get_config</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="n">raise</span> <span class="n">NotImplementedError</span>
</code></pre></div>

</details>
<h4 id="get_input_at">get_input_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor (or list of tensors if the layer has multiple inputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the input tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A tensor (or list of tensors if the layer has multiple inputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;input_tensors&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;input&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_input_mask_at">get_input_mask_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_mask_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input mask tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A mask tensor</td>
</tr>
<tr>
<td>(or list of tensors if the layer has multiple inputs).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_mask_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the input mask tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A mask tensor</span>

<span class="ss">        (or list of tensors if the layer has multiple inputs).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_input_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="o">[</span><span class="n">getattr(x, &#39;_keras_mask&#39;, None) for x in inputs</span><span class="o">]</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_keras_mask&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_input_shape_at">get_input_shape_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_shape_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input shape(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A shape tuple</td>
</tr>
<tr>
<td>(or list of shape tuples if the layer has multiple inputs).</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_shape_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the input shape(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A shape tuple</span>

<span class="ss">        (or list of shape tuples if the layer has multiple inputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;input_shapes&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;input shape&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_layer">get_layer</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_layer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence.
Indices are based on order of horizontal graph traversal (bottom-up).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>None</td>
<td>String, name of layer.</td>
<td>None</td>
</tr>
<tr>
<td>index</td>
<td>None</td>
<td>Integer, index of layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>In case of invalid layer name or index.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">get_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="k">index</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Retrieves a layer based on either its name (unique) or index.</span>

<span class="s2">    If `name` and `index` are both provided, `index` will take precedence.</span>

<span class="s2">    Indices are based on order of horizontal graph traversal (bottom-up).</span>

<span class="s2">    Arguments:</span>

<span class="s2">        name: String, name of layer.</span>

<span class="s2">        index: Integer, index of layer.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A layer instance.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: In case of invalid layer name or index.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="c1"># TODO(fchollet): We could build a dictionary based on layer names</span>

    <span class="c1"># since they are constant, but we have not done that yet.</span>

    <span class="k">if</span> <span class="k">index</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span> <span class="k">and</span> <span class="k">name</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide only a layer name or a layer index.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="k">index</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="k">index</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Was asked to retrieve layer at index &#39;</span> <span class="o">+</span> <span class="n">str</span><span class="p">(</span><span class="k">index</span><span class="p">)</span> <span class="o">+</span>

                         <span class="s1">&#39; but model only has &#39;</span> <span class="o">+</span> <span class="n">str</span><span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">))</span> <span class="o">+</span>

                         <span class="s1">&#39; layers.&#39;</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="err">[</span><span class="k">index</span><span class="err">]</span>

    <span class="k">if</span> <span class="k">name</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">for</span> <span class="n">layer</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="o">:</span>

        <span class="k">if</span> <span class="n">layer</span><span class="p">.</span><span class="k">name</span> <span class="o">==</span> <span class="k">name</span><span class="o">:</span>

          <span class="k">return</span> <span class="n">layer</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;No such layer: &#39;</span> <span class="o">+</span> <span class="k">name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>

    <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide either a layer name or layer index.&#39;</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_losses_for">get_losses_for</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_losses_for</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Retrieves losses relevant to a specific set of inputs.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Input tensor or list/tuple of input tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List of loss tensors of the layer that depend on <code>inputs</code>.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_generate_docs</span>

  <span class="n">def</span> <span class="n">get_losses_for</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use!</span>

<span class="s2">    Retrieves losses relevant to a specific set of inputs.</span>

<span class="s2">    Arguments:</span>

<span class="s2">      inputs: Input tensor or list/tuple of input tensors.</span>

<span class="s2">    Returns:</span>

<span class="s2">      List of loss tensors of the layer that depend on `inputs`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.get_losses_for` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `layer.losses` instead.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">losses</span>
</code></pre></div>

</details>
<h4 id="get_output_at">get_output_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor (or list of tensors if the layer has multiple outputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the output tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A tensor (or list of tensors if the layer has multiple outputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;output_tensors&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;output&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_output_mask_at">get_output_mask_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_mask_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output mask tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A mask tensor</td>
</tr>
<tr>
<td>(or list of tensors if the layer has multiple outputs).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_mask_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the output mask tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A mask tensor</span>

<span class="ss">        (or list of tensors if the layer has multiple outputs).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_output_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="k">output</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="o">[</span><span class="n">getattr(x, &#39;_keras_mask&#39;, None) for x in output</span><span class="o">]</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="k">output</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_keras_mask&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_output_shape_at">get_output_shape_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_shape_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output shape(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A shape tuple</td>
</tr>
<tr>
<td>(or list of shape tuples if the layer has multiple outputs).</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_shape_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the output shape(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A shape tuple</span>

<span class="ss">        (or list of shape tuples if the layer has multiple outputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;output_shapes&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;output shape&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_updates_for">get_updates_for</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_updates_for</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Retrieves updates relevant to a specific set of inputs.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Input tensor or list/tuple of input tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List of update ops of the layer that depend on <code>inputs</code>.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_generate_docs</span>

  <span class="n">def</span> <span class="n">get_updates_for</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use!</span>

<span class="s2">    Retrieves updates relevant to a specific set of inputs.</span>

<span class="s2">    Arguments:</span>

<span class="s2">      inputs: Input tensor or list/tuple of input tensors.</span>

<span class="s2">    Returns:</span>

<span class="s2">      List of update ops of the layer that depend on `inputs`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.get_updates_for` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `layer.updates` method instead.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">updates</span>
</code></pre></div>

</details>
<h4 id="get_weights">get_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the weights of the model.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A flat list of Numpy arrays.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">get_weights</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Retrieves the weights of the model.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A flat list of Numpy arrays.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="k">with</span> <span class="k">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="k">scope</span><span class="p">():</span>

      <span class="k">return</span> <span class="n">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="k">self</span><span class="p">).</span><span class="n">get_weights</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="load_weights">load_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">skip_mismatch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p>
<p>If <code>by_name</code> is False weights are loaded based on the network's
topology. This means the architecture should be the same as when the weights
were saved.  Note that layers that don't have weights are not taken into
account in the topological ordering, so adding or removing layers is fine as
long as they don't have weights.</p>
<p>If <code>by_name</code> is True, weights are loaded into layers only if they share the
same name. This is useful for fine-tuning or transfer-learning models where
some of the layers have changed.</p>
<p>Only topological loading (<code>by_name=False</code>) is supported when loading weights
from the TensorFlow format. Note that topological loading differs slightly
between TensorFlow and HDF5 formats for user-defined classes inheriting from
<code>tf.keras.Model</code>: HDF5 loads based on a flattened list of weights, while the
TensorFlow format loads based on the object-local names of attributes to
which layers are assigned in the <code>Model</code>'s constructor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String, path to the weights file to load. For weight files in</td>
<td></td>
</tr>
<tr>
<td>TensorFlow format, this is the file prefix (the same as was passed</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>to <code>save_weights</code>).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>by_name</td>
<td>None</td>
<td>Boolean, whether to load weights by name or by topological</td>
<td></td>
</tr>
<tr>
<td>order. Only topological loading is supported for weight files in</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>TensorFlow format.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>skip_mismatch</td>
<td>None</td>
<td>Boolean, whether to skip loading of layers where there is</td>
<td></td>
</tr>
<tr>
<td>a mismatch in the number of weights, or a mismatch in the shape of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the weight (only valid when <code>by_name=True</code>).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies</td>
<td></td>
</tr>
<tr>
<td>options for loading weights.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>When loading a weight file in TensorFlow format, returns the same status</td>
</tr>
<tr>
<td>object as <code>tf.train.Checkpoint.restore</code>. When graph building, restore</td>
<td></td>
</tr>
<tr>
<td>ops are run automatically as soon as the network is built (on first call</td>
<td></td>
</tr>
<tr>
<td>for user-defined classes inheriting from <code>Model</code>, immediately if it is</td>
<td></td>
</tr>
<tr>
<td>already built).</td>
<td></td>
</tr>
</tbody>
</table>
<p>When loading weights in HDF5 format, returns <code>None</code>. |</p>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If h5py is not available and the weight file is in HDF5</td>
</tr>
<tr>
<td>format.</td>
<td></td>
</tr>
<tr>
<td>ValueError</td>
<td>If <code>skip_mismatch</code> is set to <code>True</code> when <code>by_name</code> is</td>
</tr>
<tr>
<td><code>False</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

                   <span class="n">filepath</span><span class="p">,</span>

                   <span class="n">by_name</span><span class="o">=</span><span class="n">False</span><span class="p">,</span>

                   <span class="n">skip_mismatch</span><span class="o">=</span><span class="n">False</span><span class="p">,</span>

                   <span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</span>

<span class="sd">    If `by_name` is False weights are loaded based on the network&#39;s</span>

<span class="sd">    topology. This means the architecture should be the same as when the weights</span>

<span class="sd">    were saved.  Note that layers that don&#39;t have weights are not taken into</span>

<span class="sd">    account in the topological ordering, so adding or removing layers is fine as</span>

<span class="sd">    long as they don&#39;t have weights.</span>

<span class="sd">    If `by_name` is True, weights are loaded into layers only if they share the</span>

<span class="sd">    same name. This is useful for fine-tuning or transfer-learning models where</span>

<span class="sd">    some of the layers have changed.</span>

<span class="sd">    Only topological loading (`by_name=False`) is supported when loading weights</span>

<span class="sd">    from the TensorFlow format. Note that topological loading differs slightly</span>

<span class="sd">    between TensorFlow and HDF5 formats for user-defined classes inheriting from</span>

<span class="sd">    `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the</span>

<span class="sd">    TensorFlow format loads based on the object-local names of attributes to</span>

<span class="sd">    which layers are assigned in the `Model`&#39;s constructor.</span>

<span class="sd">    Arguments:</span>

<span class="sd">        filepath: String, path to the weights file to load. For weight files in</span>

<span class="sd">            TensorFlow format, this is the file prefix (the same as was passed</span>

<span class="sd">            to `save_weights`).</span>

<span class="sd">        by_name: Boolean, whether to load weights by name or by topological</span>

<span class="sd">            order. Only topological loading is supported for weight files in</span>

<span class="sd">            TensorFlow format.</span>

<span class="sd">        skip_mismatch: Boolean, whether to skip loading of layers where there is</span>

<span class="sd">            a mismatch in the number of weights, or a mismatch in the shape of</span>

<span class="sd">            the weight (only valid when `by_name=True`).</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for loading weights.</span>

<span class="sd">    Returns:</span>

<span class="sd">        When loading a weight file in TensorFlow format, returns the same status</span>

<span class="sd">        object as `tf.train.Checkpoint.restore`. When graph building, restore</span>

<span class="sd">        ops are run automatically as soon as the network is built (on first call</span>

<span class="sd">        for user-defined classes inheriting from `Model`, immediately if it is</span>

<span class="sd">        already built).</span>

<span class="sd">        When loading weights in HDF5 format, returns `None`.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If h5py is not available and the weight file is in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">        ValueError: If `skip_mismatch` is set to `True` when `by_name` is</span>

<span class="sd">          `False`.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">dist_utils</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">):</span>

      <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span>

          <span class="p">(</span><span class="ow">not</span> <span class="n">_is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">))):</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Load weights is not yet supported with TPUStrategy &#39;</span>

                         <span class="s1">&#39;with steps_per_run greater than 1.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">skip_mismatch</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">by_name</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="s1">&#39;When calling model.load_weights, skip_mismatch can only be set to &#39;</span>

          <span class="s1">&#39;True when by_name is True.&#39;</span><span class="p">)</span>

    <span class="n">filepath</span> <span class="o">=</span> <span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">_is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>

      <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="n">try</span><span class="p">:</span>

        <span class="n">py_checkpoint_reader</span><span class="o">.</span><span class="n">NewCheckpointReader</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;tf&#39;</span>

      <span class="n">except</span> <span class="n">errors_impl</span><span class="o">.</span><span class="n">DataLossError</span><span class="p">:</span>

        <span class="c1"># The checkpoint is not readable in TensorFlow format. Try HDF5.</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span><span class="p">:</span>

      <span class="n">status</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">by_name</span><span class="p">:</span>

        <span class="n">raise</span> <span class="n">NotImplementedError</span><span class="p">(</span>

            <span class="s1">&#39;Weights may only be loaded based on topology into Models when &#39;</span>

            <span class="s1">&#39;loading TensorFlow-formatted weights (got by_name=True to &#39;</span>

            <span class="s1">&#39;load_weights).&#39;</span><span class="p">)</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>

        <span class="n">session</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

        <span class="c1"># Restore existing variables (if any) immediately, and set up a</span>

        <span class="c1"># streaming restore for any variables created in the future.</span>

        <span class="n">trackable_utils</span><span class="o">.</span><span class="n">streaming_restore</span><span class="p">(</span><span class="n">status</span><span class="o">=</span><span class="n">status</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">)</span>

      <span class="n">status</span><span class="o">.</span><span class="n">assert_nontrivial_match</span><span class="p">()</span>

      <span class="k">return</span> <span class="n">status</span>

    <span class="k">if</span> <span class="n">h5py</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ImportError</span><span class="p">(</span>

          <span class="s1">&#39;`load_weights` requires h5py when loading weights from HDF5.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="s1">&#39;Unable to load weights saved in HDF5 format into a subclassed &#39;</span>

          <span class="s1">&#39;Model which has not created its variables yet. Call the Model &#39;</span>

          <span class="s1">&#39;first, then load the weights.&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span>

    <span class="n">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>

      <span class="k">if</span> <span class="s1">&#39;layer_names&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span> <span class="ow">and</span> <span class="s1">&#39;model_weights&#39;</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>

        <span class="n">f</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;model_weights&#39;</span><span class="p">]</span>

      <span class="k">if</span> <span class="n">by_name</span><span class="p">:</span>

        <span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group_by_name</span><span class="p">(</span>

            <span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="n">skip_mismatch</span><span class="o">=</span><span class="n">skip_mismatch</span><span class="p">)</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="make_predict_function">make_predict_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_predict_function</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of inference.</p>
<p>This method can be overridden to support custom inference logic.
This method is called by <code>Model.predict</code> and <code>Model.predict_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.predict_step</code>.</p>
<p>This function is cached the first time <code>Model.predict</code> or
<code>Model.predict_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a</td>
</tr>
<tr>
<td><code>tf.data.Iterator</code>, and return the outputs of the <code>Model</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">make_predict_function</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of inference.</span>

<span class="s2">    This method can be overridden to support custom inference logic.</span>

<span class="s2">    This method is called by `Model.predict` and `Model.predict_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.predict_step`.</span>

<span class="s2">    This function is cached the first time `Model.predict` or</span>

<span class="s2">    `Model.predict_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return the outputs of the `Model`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span>

    <span class="n">def</span> <span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

      <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

      <span class="n">def</span> <span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span>

        <span class="k">with</span> <span class="n">ops</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

          <span class="n">model</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

        <span class="k">return</span> <span class="n">outputs</span>

      <span class="k">data</span> <span class="o">=</span> <span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">reduce_per_replica</span><span class="p">(</span>

          <span class="n">outputs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;concat&#39;</span><span class="p">)</span>

      <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span> <span class="k">is</span> <span class="k">None</span> <span class="k">or</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with one step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="n">math_ops</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">:</span>

          <span class="n">directives</span><span class="p">.</span><span class="k">set</span><span class="n">_loop_options</span><span class="p">(</span>

              <span class="n">shape_invariants</span><span class="o">=</span><span class="err">[</span><span class="p">(</span>

                  <span class="n">t</span><span class="p">,</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">get_tensor_spec</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span>

                                <span class="k">for</span> <span class="n">t</span> <span class="k">in</span> <span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="err">]</span><span class="p">)</span>

          <span class="n">step_outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

          <span class="n">outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="o">:</span> <span class="nf">concat</span><span class="p">(</span><span class="err">[</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="err">]</span><span class="p">),</span> <span class="n">outputs</span><span class="p">,</span>

                                       <span class="n">step_outputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

      <span class="n">predict_function</span> <span class="o">=</span> <span class="n">def_function</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

          <span class="n">predict_function</span><span class="p">,</span> <span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="n">predict_function</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span>
</code></pre></div>

</details>
<h4 id="make_test_function">make_test_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_test_function</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of evaluation.</p>
<p>This method can be overridden to support custom evaluation logic.
This method is called by <code>Model.evaluate</code> and <code>Model.test_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.test_step</code>.</p>
<p>This function is cached the first time <code>Model.evaluate</code> or
<code>Model.test_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a</td>
</tr>
<tr>
<td><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will</td>
<td></td>
</tr>
<tr>
<td>be passed to <code>tf.keras.Callbacks.on_test_batch_end</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">make_test_function</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of evaluation.</span>

<span class="s2">    This method can be overridden to support custom evaluation logic.</span>

<span class="s2">    This method is called by `Model.evaluate` and `Model.test_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.test_step`.</span>

<span class="s2">    This function is cached the first time `Model.evaluate` or</span>

<span class="s2">    `Model.test_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_test_batch_end`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span>

    <span class="n">def</span> <span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

      <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

      <span class="n">def</span> <span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">test_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span>

        <span class="k">with</span> <span class="n">ops</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

          <span class="n">model</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

        <span class="k">return</span> <span class="n">outputs</span>

      <span class="k">data</span> <span class="o">=</span> <span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">reduce_per_replica</span><span class="p">(</span>

          <span class="n">outputs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>

      <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with one step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="n">math_ops</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span>

          <span class="n">outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

      <span class="n">test_function</span> <span class="o">=</span> <span class="n">def_function</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

          <span class="n">test_function</span><span class="p">,</span> <span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="o">=</span> <span class="n">test_function</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span>
</code></pre></div>

</details>
<h4 id="make_train_function">make_train_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_train_function</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of training.</p>
<p>This method can be overridden to support custom training logic.
This method is called by <code>Model.fit</code> and <code>Model.train_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual training
logic to <code>Model.train_step</code>.</p>
<p>This function is cached the first time <code>Model.fit</code> or
<code>Model.train_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a</td>
</tr>
<tr>
<td><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will</td>
<td></td>
</tr>
<tr>
<td>be passed to <code>tf.keras.Callbacks.on_train_batch_end</code>, such as</td>
<td></td>
</tr>
<tr>
<td><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">make_train_function</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of training.</span>

<span class="s2">    This method can be overridden to support custom training logic.</span>

<span class="s2">    This method is called by `Model.fit` and `Model.train_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual training</span>

<span class="s2">    logic to `Model.train_step`.</span>

<span class="s2">    This function is cached the first time `Model.fit` or</span>

<span class="s2">    `Model.train_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_train_batch_end`, such as</span>

<span class="s2">      `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span>

    <span class="n">def</span> <span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

      <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single training step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

      <span class="n">def</span> <span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">train_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="c1"># Ensure counter is updated only if `train_step` succeeds.</span>

        <span class="k">with</span> <span class="n">ops</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

          <span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

        <span class="k">return</span> <span class="n">outputs</span>

      <span class="k">data</span> <span class="o">=</span> <span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">reduce_per_replica</span><span class="p">(</span>

          <span class="n">outputs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>

      <span class="n">write_scalar_summaries</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

      <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with one step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="n">math_ops</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span>

          <span class="n">outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

      <span class="n">train_function</span> <span class="o">=</span> <span class="n">def_function</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

          <span class="n">train_function</span><span class="p">,</span> <span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="n">train_function</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span>
</code></pre></div>

</details>
<h4 id="predict">predict</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches. This method is designed for performance in
large scale inputs. For small amount of inputs that fit in one batch,
directly using <code>__call__</code> is recommended for faster execution, e.g.,
<code>model(x)</code>, or <code>model(x, training=False)</code> if you have layers such as
<code>tf.keras.layers.BatchNormalization</code> that behaves differently during
inference. Also, note the fact that test loss is not affected by
regularization layers like noise and dropout.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input samples. It could be:</td>
<td></td>
</tr>
<tr>
<td>- A Numpy array (or array-like), or a list of arrays</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A TensorFlow tensor, or a list of tensors</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A <code>tf.data</code> dataset.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A generator or <code>keras.utils.Sequence</code> instance.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>A more detailed description of unpacking behavior for iterator types</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(Dataset, generator, Sequence) is given in the `Unpacking behavior</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>for iterator-like inputs<code>section of</code>Model.fit`.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Integer or <code>None</code>.</td>
<td></td>
</tr>
<tr>
<td>Number of samples per batch.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>If unspecified, <code>batch_size</code> will default to 32.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Do not specify the <code>batch_size</code> if your data is in the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>form of dataset, generators, or <code>keras.utils.Sequence</code> instances</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(since they generate batches).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>verbose</td>
<td>None</td>
<td>Verbosity mode, 0 or 1.</td>
<td>None</td>
</tr>
<tr>
<td>steps</td>
<td>None</td>
<td>Total number of steps (batches of samples)</td>
<td></td>
</tr>
<tr>
<td>before declaring the prediction round finished.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Ignored with the default value of <code>None</code>. If x is a <code>tf.data</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>dataset and <code>steps</code> is None, <code>predict</code> will</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>run until the input dataset is exhausted.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>callbacks</td>
<td>None</td>
<td>List of <code>keras.callbacks.Callback</code> instances.</td>
<td></td>
</tr>
<tr>
<td>List of callbacks to apply during prediction.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>See <a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>max_queue_size</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code></td>
<td></td>
</tr>
<tr>
<td>input only. Maximum size for the generator queue.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>If unspecified, <code>max_queue_size</code> will default to 10.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>workers</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input</td>
<td></td>
</tr>
<tr>
<td>only. Maximum number of processes to spin up when using</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>process-based threading. If unspecified, <code>workers</code> will default</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>to 1. If 0, will execute the generator on the main thread.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>None</td>
<td>Boolean. Used for generator or</td>
<td></td>
</tr>
<tr>
<td><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>threading. If unspecified, <code>use_multiprocessing</code> will default to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>False</code>. Note that because this implementation relies on</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>multiprocessing, you should not pass non-picklable arguments to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the generator as they can't be passed easily to children processes.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>See the discussion of <code>Unpacking behavior for iterator-like inputs</code> for
<code>Model.fit</code>. Note that Model.predict uses the same interpretation rules as
<code>Model.fit</code> and <code>Model.evaluate</code>, so inputs must be unambiguous for all
three methods. | None |</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between the provided</td>
</tr>
<tr>
<td>input data and the model's expectations,</td>
<td></td>
</tr>
<tr>
<td>or in case a stateful model receives a number of samples</td>
<td></td>
</tr>
<tr>
<td>that is not a multiple of the batch size.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

              <span class="n">x</span><span class="p">,</span>

              <span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

              <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

              <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

              <span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Generates output predictions for the input samples.</span>

<span class="s2">    Computation is done in batches. This method is designed for performance in</span>

<span class="s2">    large scale inputs. For small amount of inputs that fit in one batch,</span>

<span class="s2">    directly using `__call__` is recommended for faster execution, e.g.,</span>

<span class="s2">    `model(x)`, or `model(x, training=False)` if you have layers such as</span>

<span class="s2">    `tf.keras.layers.BatchNormalization` that behaves differently during</span>

<span class="s2">    inference. Also, note the fact that test loss is not affected by</span>

<span class="s2">    regularization layers like noise and dropout.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input samples. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A `tf.data` dataset.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` instance.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        batch_size: Integer or `None`.</span>

<span class="s2">            Number of samples per batch.</span>

<span class="s2">            If unspecified, `batch_size` will default to 32.</span>

<span class="s2">            Do not specify the `batch_size` if your data is in the</span>

<span class="s2">            form of dataset, generators, or `keras.utils.Sequence` instances</span>

<span class="s2">            (since they generate batches).</span>

<span class="s2">        verbose: Verbosity mode, 0 or 1.</span>

<span class="s2">        steps: Total number of steps (batches of samples)</span>

<span class="s2">            before declaring the prediction round finished.</span>

<span class="s2">            Ignored with the default value of `None`. If x is a `tf.data`</span>

<span class="s2">            dataset and `steps` is None, `predict` will</span>

<span class="s2">            run until the input dataset is exhausted.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="s2">            List of callbacks to apply during prediction.</span>

<span class="s2">            See [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">            input only. Maximum size for the generator queue.</span>

<span class="s2">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">            only. Maximum number of processes to spin up when using</span>

<span class="s2">            process-based threading. If unspecified, `workers` will default</span>

<span class="s2">            to 1. If 0, will execute the generator on the main thread.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">            `False`. Note that because this implementation relies on</span>

<span class="s2">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="s2">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`. Note that Model.predict uses the same interpretation rules as</span>

<span class="s2">    `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all</span>

<span class="s2">    three methods.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Numpy array(s) of predictions.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.predict` is wrapped in `tf.function`.</span>

<span class="s2">        ValueError: In case of mismatch between the provided</span>

<span class="s2">            input data and the model&#39;s expectations,</span>

<span class="s2">            or in case a stateful model receives a number of samples</span>

<span class="s2">            that is not a multiple of the batch size.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

    <span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="k">None</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

      <span class="n">dataset_types</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="p">.</span><span class="n">DatasetV1</span><span class="p">,</span> <span class="n">dataset_ops</span><span class="p">.</span><span class="n">DatasetV2</span><span class="p">)</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span> <span class="k">or</span> <span class="n">_is_tpu_multi_host</span><span class="p">(</span>

          <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">))</span> <span class="k">and</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dataset_types</span><span class="p">)</span><span class="o">:</span>

        <span class="n">try</span><span class="o">:</span>

          <span class="k">options</span> <span class="o">=</span> <span class="n">dataset_ops</span><span class="p">.</span><span class="k">Options</span><span class="p">()</span>

          <span class="n">data_option</span> <span class="o">=</span> <span class="n">AutoShardPolicy</span><span class="p">.</span><span class="k">DATA</span>

          <span class="k">options</span><span class="p">.</span><span class="n">experimental_distribute</span><span class="p">.</span><span class="n">auto_shard_policy</span> <span class="o">=</span> <span class="n">data_option</span>

          <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">with_options</span><span class="p">(</span><span class="k">options</span><span class="p">)</span>

        <span class="k">except</span> <span class="n">ValueError</span><span class="o">:</span>

          <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Using Model.predict with &#39;</span>

                        <span class="s1">&#39;MultiWorkerDistributionStrategy or TPUStrategy and &#39;</span>

                        <span class="s1">&#39;AutoShardPolicy.FILE might lead to out-of-order result&#39;</span>

                        <span class="s1">&#39;. Consider setting it to AutoShardPolicy.DATA.&#39;</span><span class="p">)</span>

      <span class="n">data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">DataHandler</span><span class="p">(</span>

          <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

          <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

          <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

          <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

          <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

          <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

          <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

          <span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

      <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

      <span class="k">if</span> <span class="k">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span>

            <span class="n">callbacks</span><span class="p">,</span>

            <span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_begin</span><span class="p">()</span>

      <span class="n">batch_outputs</span> <span class="o">=</span> <span class="k">None</span>

      <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">iterator</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span>  <span class="c1"># Single epoch.</span>

        <span class="k">with</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span>

          <span class="k">for</span> <span class="n">step</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span>

            <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

            <span class="n">tmp_batch_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span>

              <span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span>

            <span class="n">batch_outputs</span> <span class="o">=</span> <span class="n">tmp_batch_outputs</span>  <span class="c1"># No error, now safe to assign.</span>

            <span class="k">if</span> <span class="n">outputs</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

              <span class="n">outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span> <span class="n">batch_output</span><span class="o">:</span> <span class="err">[</span><span class="n">batch_output</span><span class="err">]</span><span class="p">,</span>

                                           <span class="n">batch_outputs</span><span class="p">)</span>

            <span class="k">else</span><span class="o">:</span>

              <span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>

                  <span class="n">batch_outputs</span><span class="p">,</span>

                  <span class="n">lambda</span> <span class="n">output</span><span class="p">,</span> <span class="n">batch_output</span><span class="o">:</span> <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_output</span><span class="p">),</span>

                  <span class="n">outputs</span><span class="p">,</span> <span class="n">batch_outputs</span><span class="p">)</span>

            <span class="n">end_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">+</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span>

            <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span> <span class="err">{</span><span class="s1">&#39;outputs&#39;</span><span class="o">:</span> <span class="n">batch_outputs</span><span class="err">}</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">batch_outputs</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Expect x to be a non-empty array or dataset.&#39;</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_end</span><span class="p">()</span>

    <span class="n">all_outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span><span class="n">batch_outputs</span><span class="p">,</span> <span class="n">concat</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_generator">predict_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates predictions for the input samples from a data generator.</p>
<p>DEPRECATED:
  <code>Model.predict</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">predict_generator</span><span class="p">(</span><span class="k">self</span><span class="p">,</span>

                        <span class="n">generator</span><span class="p">,</span>

                        <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                        <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                        <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

                        <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

                        <span class="k">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Generates predictions for the input samples from a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.predict` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`Model.predict_generator` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `Model.predict`, which supports generators.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="k">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span>

        <span class="n">generator</span><span class="p">,</span>

        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

        <span class="k">verbose</span><span class="o">=</span><span class="k">verbose</span><span class="p">,</span>

        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_on_batch">predict_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns predictions for a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be: - A Numpy array (or array-like), or a list</td>
<td></td>
</tr>
<tr>
<td>of arrays (in case the model has multiple inputs). - A TensorFlow</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>tensor, or a list of tensors (in case the model has multiple inputs).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict_on_batch</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between given number of inputs and</td>
</tr>
<tr>
<td>expectations of the model.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">predict_on_batch</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Returns predictions for a single batch of samples.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        x: Input data. It could be: - A Numpy array (or array-like), or a list</span>

<span class="ss">          of arrays (in case the model has multiple inputs). - A TensorFlow</span>

<span class="ss">          tensor, or a list of tensors (in case the model has multiple inputs).</span>

<span class="ss">    Returns:</span>

<span class="ss">        Numpy array(s) of predictions.</span>

<span class="ss">    Raises:</span>

<span class="ss">        RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.</span>

<span class="ss">        ValueError: In case of mismatch between given number of inputs and</span>

<span class="ss">          expectations of the model.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="k">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict_on_batch&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;predict_on_batch&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="k">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="k">scope</span><span class="p">():</span>

      <span class="n">iterator</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

      <span class="k">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_step">predict_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference and returns the boxes, scores and labels associated.</p>
<p>Background is discarded the max and argmax operation are performed.
It means that if background was predicted the second maximum score would
be outputed.</p>
<p>Example: background + 3 classes
[0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</p>
<p>"To optimize for AP, we override the prediction of these slots
with the second highest scoring class, using the corresponding confidence"
Part 4. Experiments of Object Detection with Transformers</p>
<p>Returns:</p>
<ul>
<li><em>boxes</em>: A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]
containing the boxes with the coordinates between 0 and 1.</li>
<li><em>scores</em>: A Tensor of shape [batch_size, self.num_queries] containing
the score of the boxes.</li>
<li><em>classes</em>: A Tensor of shape [batch_size, self.num_queries]
containing the class of the boxes [0, num_classes).</li>
</ul>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">predict_step</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="k">data</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Perform an inference and returns the boxes, scores and labels associated.</span>

<span class="ss">        Background is discarded the max and argmax operation are performed.</span>

<span class="ss">        It means that if background was predicted the second maximum score would</span>

<span class="ss">        be outputed.</span>

<span class="ss">        Example: background + 3 classes</span>

<span class="ss">        [0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</span>

<span class="ss">        &quot;</span><span class="k">To</span> <span class="n">optimize</span> <span class="k">for</span> <span class="n">AP</span><span class="p">,</span> <span class="n">we</span> <span class="n">override</span> <span class="n">the</span> <span class="n">prediction</span> <span class="k">of</span> <span class="n">these</span> <span class="n">slots</span>

        <span class="k">with</span> <span class="n">the</span> <span class="k">second</span> <span class="n">highest</span> <span class="n">scoring</span> <span class="k">class</span><span class="p">,</span> <span class="k">using</span> <span class="n">the</span> <span class="k">corresponding</span> <span class="n">confidence</span><span class="ss">&quot;</span>

<span class="ss">        Part 4. Experiments of Object Detection with Transformers</span>

<span class="ss">        Returns:</span>

<span class="ss">        - *boxes*: A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]</span>

<span class="ss">        containing the boxes with the coordinates between 0 and 1.</span>

<span class="ss">        - *scores*: A Tensor of shape [batch_size, self.num_queries] containing</span>

<span class="ss">        the score of the boxes.</span>

<span class="ss">        - *classes*: A Tensor of shape [batch_size, self.num_queries]</span>

<span class="ss">        containing the class of the boxes [0, num_classes).</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="k">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="k">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="k">False</span><span class="p">)</span>

        <span class="n">boxes_without_padding</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">detr_postprocessing</span><span class="p">(</span>

            <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="p">.</span><span class="n">BOXES</span><span class="p">],</span>

            <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="p">.</span><span class="n">SCORES</span><span class="p">],</span>

            <span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES_INFO</span><span class="p">],</span>

            <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span>

        <span class="p">)</span>

        <span class="k">return</span> <span class="n">boxes_without_padding</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span>
</code></pre></div>

</details>
<h4 id="reset_metrics">reset_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_metrics</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Resets the state of all the metrics in the model.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>inputs = tf.keras.layers.Input(shape=(3,))
outputs = tf.keras.layers.Dense(2)(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
model.compile(optimizer="Adam", loss="mse", metrics=["mae"])</p>
<p>x = np.random.random((2, 3))
y = np.random.randint(0, 2, (2, 2))
_ = model.fit(x, y, verbose=0)
assert all(float(m.result()) for m in model.metrics)</p>
<p>model.reset_metrics()
assert all(float(m.result()) == 0 for m in model.metrics)</p>
</blockquote>
</blockquote>
</blockquote>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">reset_metrics</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Resets the state of all the metrics in the model.</span>

<span class="ss">    Examples:</span>

<span class="ss">    &gt;&gt;&gt; inputs = tf.keras.layers.Input(shape=(3,))</span>

<span class="ss">    &gt;&gt;&gt; outputs = tf.keras.layers.Dense(2)(inputs)</span>

<span class="ss">    &gt;&gt;&gt; model = tf.keras.models.Model(inputs=inputs, outputs=outputs)</span>

<span class="ss">    &gt;&gt;&gt; model.compile(optimizer=&quot;</span><span class="n">Adam</span><span class="ss">&quot;, loss=&quot;</span><span class="n">mse</span><span class="ss">&quot;, metrics=[&quot;</span><span class="n">mae</span><span class="ss">&quot;])</span>

<span class="ss">    &gt;&gt;&gt; x = np.random.random((2, 3))</span>

<span class="ss">    &gt;&gt;&gt; y = np.random.randint(0, 2, (2, 2))</span>

<span class="ss">    &gt;&gt;&gt; _ = model.fit(x, y, verbose=0)</span>

<span class="ss">    &gt;&gt;&gt; assert all(float(m.result()) for m in model.metrics)</span>

<span class="ss">    &gt;&gt;&gt; model.reset_metrics()</span>

<span class="ss">    &gt;&gt;&gt; assert all(float(m.result()) == 0 for m in model.metrics)</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="k">for</span> <span class="n">m</span> <span class="k">in</span> <span class="k">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">:</span>

      <span class="n">m</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="reset_states">reset_states</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_states</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">reset_states</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="k">for</span> <span class="n">layer</span> <span class="k">in</span> <span class="k">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;reset_states&#39;</span><span class="p">)</span> <span class="k">and</span> <span class="n">getattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;stateful&#39;</span><span class="p">,</span> <span class="k">False</span><span class="p">):</span>

        <span class="n">layer</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="save">save</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">signatures</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">save_traces</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p>
<p>Please see <code>tf.keras.models.save_model</code> or the
<a href="https://keras.io/guides/serialization_and_saving/">Serialization and Saving guide</a>
for details.</p>
<p>Arguments:
    filepath: String, PathLike, path to SavedModel or H5 file to save the
        model.
    overwrite: Whether to silently overwrite any existing file at the
        target location, or provide the user with a manual prompt.
    include_optimizer: If True, save optimizer's state together.
    save_format: Either <code>'tf'</code> or <code>'h5'</code>, indicating whether to save the
        model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,
        and 'h5' in TF 1.X.
    signatures: Signatures to save with the SavedModel. Applicable to the
        'tf' format only. Please see the <code>signatures</code> argument in
        <code>tf.saved_model.save</code> for details.
    options: (only applies to SavedModel format)
        <code>tf.saved_model.SaveOptions</code> object that specifies options for
        saving to SavedModel.
    save_traces: (only applies to SavedModel format) When enabled, the
        SavedModel will store the function traces for each layer. This
        can be disabled, so that only the configs of each layer are stored.
        Defaults to <code>True</code>. Disabling this will decrease serialization time
        and reduce file size, but it requires that all custom layers/models
        implement a <code>get_config()</code> method.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>  <span class="c1"># creates a HDF5 file &#39;my_model.h5&#39;</span>
<span class="k">del</span> <span class="n">model</span>  <span class="c1"># deletes the existing model</span>

<span class="c1"># returns a compiled model</span>
<span class="c1"># identical to the previous one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">save</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

           <span class="n">filepath</span><span class="p">,</span>

           <span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

           <span class="n">include_optimizer</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

           <span class="n">save_format</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

           <span class="n">signatures</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

           <span class="k">options</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

           <span class="n">save_traces</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span>

    <span class="c1"># pylint: disable=line-too-long</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Saves the model to Tensorflow SavedModel or a single HDF5 file.</span>

<span class="s2">    Please see `tf.keras.models.save_model` or the</span>

<span class="s2">    [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)</span>

<span class="s2">    for details.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        filepath: String, PathLike, path to SavedModel or H5 file to save the</span>

<span class="s2">            model.</span>

<span class="s2">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="s2">            target location, or provide the user with a manual prompt.</span>

<span class="s2">        include_optimizer: If True, save optimizer&#39;s state together.</span>

<span class="s2">        save_format: Either `&#39;tf&#39;` or `&#39;h5&#39;`, indicating whether to save the</span>

<span class="s2">            model to Tensorflow SavedModel or HDF5. Defaults to &#39;tf&#39; in TF 2.X,</span>

<span class="s2">            and &#39;h5&#39; in TF 1.X.</span>

<span class="s2">        signatures: Signatures to save with the SavedModel. Applicable to the</span>

<span class="s2">            &#39;tf&#39; format only. Please see the `signatures` argument in</span>

<span class="s2">            `tf.saved_model.save` for details.</span>

<span class="s2">        options: (only applies to SavedModel format)</span>

<span class="s2">            `tf.saved_model.SaveOptions` object that specifies options for</span>

<span class="s2">            saving to SavedModel.</span>

<span class="s2">        save_traces: (only applies to SavedModel format) When enabled, the</span>

<span class="s2">            SavedModel will store the function traces for each layer. This</span>

<span class="s2">            can be disabled, so that only the configs of each layer are stored.</span>

<span class="s2">            Defaults to `True`. Disabling this will decrease serialization time</span>

<span class="s2">            and reduce file size, but it requires that all custom layers/models</span>

<span class="s2">            implement a `get_config()` method.</span>

<span class="s2">    Example:</span>

<span class="s2">    ```python</span>

<span class="s2">    from keras.models import load_model</span>

<span class="s2">    model.save(&#39;my_model.h5&#39;)  # creates a HDF5 file &#39;my_model.h5&#39;</span>

<span class="s2">    del model  # deletes the existing model</span>

<span class="s2">    # returns a compiled model</span>

<span class="s2">    # identical to the previous one</span>

<span class="s2">    model = load_model(&#39;my_model.h5&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="c1"># pylint: enable=line-too-long</span>

    <span class="n">save</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="p">,</span> <span class="n">save_format</span><span class="p">,</span>

                    <span class="n">signatures</span><span class="p">,</span> <span class="k">options</span><span class="p">,</span> <span class="n">save_traces</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="save_weights">save_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves all layer weights.</p>
<p>Either saves in HDF5 or in TensorFlow format based on the <code>save_format</code>
argument.</p>
<p>When saving in HDF5 format, the weight file has:
  - <code>layer_names</code> (attribute), a list of strings
      (ordered names of model layers).
  - For every layer, a <code>group</code> named <code>layer.name</code>
      - For every such layer group, a group attribute <code>weight_names</code>,
          a list of strings
          (ordered names of weights tensor of the layer).
      - For every weight in the layer, a dataset
          storing the weight value, named after the weight tensor.</p>
<p>When saving in TensorFlow format, all objects referenced by the network are
saved in the same format as <code>tf.train.Checkpoint</code>, including any <code>Layer</code>
instances or <code>Optimizer</code> instances assigned to object attributes. For
networks constructed from inputs and outputs using <code>tf.keras.Model(inputs,
outputs)</code>, <code>Layer</code> instances used by the network are tracked/saved
automatically. For user-defined classes which inherit from <code>tf.keras.Model</code>,
<code>Layer</code> instances must be assigned to object attributes, typically in the
constructor. See the documentation of <code>tf.train.Checkpoint</code> and
<code>tf.keras.Model</code> for details.</p>
<p>While the formats are the same, do not mix <code>save_weights</code> and
<code>tf.train.Checkpoint</code>. Checkpoints saved by <code>Model.save_weights</code> should be
loaded using <code>Model.load_weights</code>. Checkpoints saved using
<code>tf.train.Checkpoint.save</code> should be restored using the corresponding
<code>tf.train.Checkpoint.restore</code>. Prefer <code>tf.train.Checkpoint</code> over
<code>save_weights</code> for training checkpoints.</p>
<p>The TensorFlow format matches objects and variables by starting at a root
object, <code>self</code> for <code>save_weights</code>, and greedily matching attribute
names. For <code>Model.save</code> this is the <code>Model</code>, and for <code>Checkpoint.save</code> this
is the <code>Checkpoint</code> even if the <code>Checkpoint</code> has a model attached. This
means saving a <code>tf.keras.Model</code> using <code>save_weights</code> and loading into a
<code>tf.train.Checkpoint</code> with a <code>Model</code> attached (or vice versa) will not match
the <code>Model</code>'s variables. See the <a href="https://www.tensorflow.org/guide/checkpoint">guide to training
checkpoints</a> for details
on the TensorFlow format.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String or PathLike, path to the file to save the weights to.</td>
<td></td>
</tr>
<tr>
<td>When saving in TensorFlow format, this is the prefix used for</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>checkpoint files (multiple files are generated). Note that the '.h5'</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>suffix causes weights to be saved in HDF5 format.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>overwrite</td>
<td>None</td>
<td>Whether to silently overwrite any existing file at the</td>
<td></td>
</tr>
<tr>
<td>target location, or provide the user with a manual prompt.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>save_format</td>
<td>None</td>
<td>Either 'tf' or 'h5'. A <code>filepath</code> ending in '.h5' or</td>
<td></td>
</tr>
<tr>
<td>'.keras' will default to HDF5 if <code>save_format</code> is <code>None</code>. Otherwise</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>None</code> defaults to 'tf'.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies</td>
<td></td>
</tr>
<tr>
<td>options for saving weights.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If h5py is not available when attempting to save in HDF5</td>
</tr>
<tr>
<td>format.</td>
<td></td>
</tr>
<tr>
<td>ValueError</td>
<td>For invalid/unknown format arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

                   <span class="n">filepath</span><span class="p">,</span>

                   <span class="n">overwrite</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

                   <span class="n">save_format</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

                   <span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Saves all layer weights.</span>

<span class="sd">    Either saves in HDF5 or in TensorFlow format based on the `save_format`</span>

<span class="sd">    argument.</span>

<span class="sd">    When saving in HDF5 format, the weight file has:</span>

<span class="sd">      - `layer_names` (attribute), a list of strings</span>

<span class="sd">          (ordered names of model layers).</span>

<span class="sd">      - For every layer, a `group` named `layer.name`</span>

<span class="sd">          - For every such layer group, a group attribute `weight_names`,</span>

<span class="sd">              a list of strings</span>

<span class="sd">              (ordered names of weights tensor of the layer).</span>

<span class="sd">          - For every weight in the layer, a dataset</span>

<span class="sd">              storing the weight value, named after the weight tensor.</span>

<span class="sd">    When saving in TensorFlow format, all objects referenced by the network are</span>

<span class="sd">    saved in the same format as `tf.train.Checkpoint`, including any `Layer`</span>

<span class="sd">    instances or `Optimizer` instances assigned to object attributes. For</span>

<span class="sd">    networks constructed from inputs and outputs using `tf.keras.Model(inputs,</span>

<span class="sd">    outputs)`, `Layer` instances used by the network are tracked/saved</span>

<span class="sd">    automatically. For user-defined classes which inherit from `tf.keras.Model`,</span>

<span class="sd">    `Layer` instances must be assigned to object attributes, typically in the</span>

<span class="sd">    constructor. See the documentation of `tf.train.Checkpoint` and</span>

<span class="sd">    `tf.keras.Model` for details.</span>

<span class="sd">    While the formats are the same, do not mix `save_weights` and</span>

<span class="sd">    `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be</span>

<span class="sd">    loaded using `Model.load_weights`. Checkpoints saved using</span>

<span class="sd">    `tf.train.Checkpoint.save` should be restored using the corresponding</span>

<span class="sd">    `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over</span>

<span class="sd">    `save_weights` for training checkpoints.</span>

<span class="sd">    The TensorFlow format matches objects and variables by starting at a root</span>

<span class="sd">    object, `self` for `save_weights`, and greedily matching attribute</span>

<span class="sd">    names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this</span>

<span class="sd">    is the `Checkpoint` even if the `Checkpoint` has a model attached. This</span>

<span class="sd">    means saving a `tf.keras.Model` using `save_weights` and loading into a</span>

<span class="sd">    `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match</span>

<span class="sd">    the `Model`&#39;s variables. See the [guide to training</span>

<span class="sd">    checkpoints](https://www.tensorflow.org/guide/checkpoint) for details</span>

<span class="sd">    on the TensorFlow format.</span>

<span class="sd">    Arguments:</span>

<span class="sd">        filepath: String or PathLike, path to the file to save the weights to.</span>

<span class="sd">            When saving in TensorFlow format, this is the prefix used for</span>

<span class="sd">            checkpoint files (multiple files are generated). Note that the &#39;.h5&#39;</span>

<span class="sd">            suffix causes weights to be saved in HDF5 format.</span>

<span class="sd">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="sd">            target location, or provide the user with a manual prompt.</span>

<span class="sd">        save_format: Either &#39;tf&#39; or &#39;h5&#39;. A `filepath` ending in &#39;.h5&#39; or</span>

<span class="sd">            &#39;.keras&#39; will default to HDF5 if `save_format` is `None`. Otherwise</span>

<span class="sd">            `None` defaults to &#39;tf&#39;.</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for saving weights.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If h5py is not available when attempting to save in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">        ValueError: For invalid/unknown format arguments.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span>

    <span class="n">filepath</span> <span class="o">=</span> <span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

    <span class="n">filepath_is_h5</span> <span class="o">=</span> <span class="n">_is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">filepath_is_h5</span><span class="p">:</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;tf&#39;</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="n">user_format</span> <span class="o">=</span> <span class="n">save_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

      <span class="k">if</span> <span class="n">user_format</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;tensorflow&#39;</span><span class="p">,</span> <span class="s1">&#39;tf&#39;</span><span class="p">):</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;tf&#39;</span>

      <span class="k">elif</span> <span class="n">user_format</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;hdf5&#39;</span><span class="p">,</span> <span class="s1">&#39;h5&#39;</span><span class="p">,</span> <span class="s1">&#39;keras&#39;</span><span class="p">):</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

            <span class="s1">&#39;Unknown format &quot;</span><span class="si">%s</span><span class="s1">&quot;. Was expecting one of {&quot;tf&quot;, &quot;h5&quot;}.&#39;</span> <span class="o">%</span> <span class="p">(</span>

                <span class="n">save_format</span><span class="p">,))</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span> <span class="ow">and</span> <span class="n">filepath_is_h5</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="p">(</span><span class="s1">&#39;save_weights got save_format=&quot;tf&quot;/&quot;tensorflow&quot;, but the &#39;</span>

           <span class="s1">&#39;filepath (&quot;</span><span class="si">%s</span><span class="s1">&quot;) looks like an HDF5 file. Omit the &quot;.h5&quot;/&quot;.keras&quot; &#39;</span>

           <span class="s1">&#39;when saving in TensorFlow format.&#39;</span><span class="p">)</span>

          <span class="o">%</span> <span class="n">filepath</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;h5&#39;</span> <span class="ow">and</span> <span class="n">h5py</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ImportError</span><span class="p">(</span>

          <span class="s1">&#39;`save_weights` requires h5py when saving in hdf5.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span><span class="p">:</span>

      <span class="n">check_filepath</span> <span class="o">=</span> <span class="n">filepath</span> <span class="o">+</span> <span class="s1">&#39;.index&#39;</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="n">check_filepath</span> <span class="o">=</span> <span class="n">filepath</span>

    <span class="c1"># If file exists and should not be overwritten:</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">overwrite</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">):</span>

      <span class="n">proceed</span> <span class="o">=</span> <span class="n">ask_to_proceed_with_overwrite</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">)</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">proceed</span><span class="p">:</span>

        <span class="k">return</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;h5&#39;</span><span class="p">:</span>

      <span class="n">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>

        <span class="n">hdf5_format</span><span class="o">.</span><span class="n">save_weights_to_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>

        <span class="n">session</span> <span class="o">=</span> <span class="n">None</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">session</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="n">None</span><span class="p">)</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">optimizer</span>

          <span class="ow">and</span> <span class="ow">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">trackable</span><span class="o">.</span><span class="n">Trackable</span><span class="p">)):</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>

            <span class="p">(</span><span class="s1">&#39;This model was compiled with a Keras optimizer (</span><span class="si">%s</span><span class="s1">) but is being &#39;</span>

             <span class="s1">&#39;saved in TensorFlow format with `save_weights`. The model</span><span class="se">\&#39;</span><span class="s1">s &#39;</span>

             <span class="s1">&#39;weights will be saved, but unlike with TensorFlow optimizers in &#39;</span>

             <span class="s1">&#39;the TensorFlow format the optimizer</span><span class="se">\&#39;</span><span class="s1">s state will not be &#39;</span>

             <span class="s1">&#39;saved.</span><span class="se">\n\n</span><span class="s1">Consider using a TensorFlow optimizer from `tf.train`.&#39;</span><span class="p">)</span>

            <span class="o">%</span> <span class="p">(</span><span class="n">optimizer</span><span class="p">,))</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>

      <span class="c1"># Record this checkpoint so it&#39;s visible from tf.train.latest_checkpoint.</span>

      <span class="n">checkpoint_management</span><span class="o">.</span><span class="n">update_checkpoint_state_internal</span><span class="p">(</span>

          <span class="n">save_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">filepath</span><span class="p">),</span>

          <span class="n">model_checkpoint_path</span><span class="o">=</span><span class="n">filepath</span><span class="p">,</span>

          <span class="n">save_relative_paths</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

          <span class="n">all_model_checkpoint_paths</span><span class="o">=</span><span class="p">[</span><span class="n">filepath</span><span class="p">])</span>
</code></pre></div>

</details>
<h4 id="set_weights">set_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">weights</span>
<span class="p">)</span>
</code></pre></div>

<p>Sets the weights of the layer, from Numpy arrays.</p>
<p>The weights of a layer represent the state of the layer. This function
sets the weight values from numpy arrays. The weight values should be
passed in the order they are created by the layer. Note that the layer's
weights must be instantiated before calling this function by calling
the layer.</p>
<p>For example, a Dense layer returns a list of two values-- per-output
weights and the bias value. These can be used to set the weights of another
Dense layer:</p>
<blockquote>
<blockquote>
<blockquote>
<p>a = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(1.))
a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))
a.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]
b = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(2.))
b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))
b.get_weights()
[array([[2.],
       [2.],
       [2.]], dtype=float32), array([0.], dtype=float32)]
b.set_weights(a.get_weights())
b.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>weights</td>
<td>None</td>
<td>a list of Numpy arrays. The number</td>
<td></td>
</tr>
<tr>
<td>of arrays and their shape must match</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>number of the dimensions of the weights</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of the layer (i.e. it should match the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>output of <code>get_weights</code>).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>If the provided weights list does not match the</td>
</tr>
<tr>
<td>layer's specifications.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Sets the weights of the layer, from Numpy arrays.</span>

<span class="sd">    The weights of a layer represent the state of the layer. This function</span>

<span class="sd">    sets the weight values from numpy arrays. The weight values should be</span>

<span class="sd">    passed in the order they are created by the layer. Note that the layer&#39;s</span>

<span class="sd">    weights must be instantiated before calling this function by calling</span>

<span class="sd">    the layer.</span>

<span class="sd">    For example, a Dense layer returns a list of two values-- per-output</span>

<span class="sd">    weights and the bias value. These can be used to set the weights of another</span>

<span class="sd">    Dense layer:</span>

<span class="sd">    &gt;&gt;&gt; a = tf.keras.layers.Dense(1,</span>

<span class="sd">    ...   kernel_initializer=tf.constant_initializer(1.))</span>

<span class="sd">    &gt;&gt;&gt; a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))</span>

<span class="sd">    &gt;&gt;&gt; a.get_weights()</span>

<span class="sd">    [array([[1.],</span>

<span class="sd">           [1.],</span>

<span class="sd">           [1.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    &gt;&gt;&gt; b = tf.keras.layers.Dense(1,</span>

<span class="sd">    ...   kernel_initializer=tf.constant_initializer(2.))</span>

<span class="sd">    &gt;&gt;&gt; b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))</span>

<span class="sd">    &gt;&gt;&gt; b.get_weights()</span>

<span class="sd">    [array([[2.],</span>

<span class="sd">           [2.],</span>

<span class="sd">           [2.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    &gt;&gt;&gt; b.set_weights(a.get_weights())</span>

<span class="sd">    &gt;&gt;&gt; b.get_weights()</span>

<span class="sd">    [array([[1.],</span>

<span class="sd">           [1.],</span>

<span class="sd">           [1.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    Arguments:</span>

<span class="sd">        weights: a list of Numpy arrays. The number</span>

<span class="sd">            of arrays and their shape must match</span>

<span class="sd">            number of the dimensions of the weights</span>

<span class="sd">            of the layer (i.e. it should match the</span>

<span class="sd">            output of `get_weights`).</span>

<span class="sd">    Raises:</span>

<span class="sd">        ValueError: If the provided weights list does not match the</span>

<span class="sd">            layer&#39;s specifications.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>

    <span class="n">expected_num_weights</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">TrackableWeightHandler</span><span class="p">):</span>

        <span class="n">expected_num_weights</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">num_tensors</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">expected_num_weights</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">expected_num_weights</span> <span class="o">!=</span> <span class="n">len</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="s1">&#39;You called `set_weights(weights)` on layer &quot;</span><span class="si">%s</span><span class="s1">&quot; &#39;</span>

          <span class="s1">&#39;with a weight list of length </span><span class="si">%s</span><span class="s1">, but the layer was &#39;</span>

          <span class="s1">&#39;expecting </span><span class="si">%s</span><span class="s1"> weights. Provided weights: </span><span class="si">%s</span><span class="s1">...&#39;</span> <span class="o">%</span>

          <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">len</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">expected_num_weights</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">weights</span><span class="p">)[:</span><span class="mi">50</span><span class="p">]))</span>

    <span class="n">weight_index</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">weight_value_tuples</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">TrackableWeightHandler</span><span class="p">):</span>

        <span class="n">num_tensors</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">num_tensors</span>

        <span class="n">tensors</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="p">:</span><span class="n">weight_index</span> <span class="o">+</span> <span class="n">num_tensors</span><span class="p">]</span>

        <span class="n">param</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>

        <span class="n">weight_index</span> <span class="o">+=</span> <span class="n">num_tensors</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">weight</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="p">]</span>

        <span class="n">ref_shape</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">ref_shape</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>

          <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

              <span class="s1">&#39;Layer weight shape </span><span class="si">%s</span><span class="s1"> not compatible with provided weight &#39;</span>

              <span class="s1">&#39;shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ref_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

        <span class="n">weight_value_tuples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">param</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>

        <span class="n">weight_index</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">backend</span><span class="o">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">weight_value_tuples</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="summary">summary</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">line_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">print_fn</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Prints a string summary of the network.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>line_length</td>
<td>None</td>
<td>Total length of printed lines</td>
<td></td>
</tr>
<tr>
<td>(e.g. set this to adapt the display to different</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>terminal window sizes).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>positions</td>
<td>None</td>
<td>Relative or absolute positions of log elements</td>
<td></td>
</tr>
<tr>
<td>in each line. If not provided,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>defaults to <code>[.33, .55, .67, 1.]</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>print_fn</td>
<td>None</td>
<td>Print function to use. Defaults to <code>print</code>.</td>
<td></td>
</tr>
<tr>
<td>It will be called on each line of the summary.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>You can set it to a custom function</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>in order to capture the string summary.</td>
<td><code>print</code></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if <code>summary()</code> is called before the model is built.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">line_length</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="n">positions</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="n">print_fn</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Prints a string summary of the network.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        line_length: Total length of printed lines</span>

<span class="s2">            (e.g. set this to adapt the display to different</span>

<span class="s2">            terminal window sizes).</span>

<span class="s2">        positions: Relative or absolute positions of log elements</span>

<span class="s2">            in each line. If not provided,</span>

<span class="s2">            defaults to `[.33, .55, .67, 1.]`.</span>

<span class="s2">        print_fn: Print function to use. Defaults to `print`.</span>

<span class="s2">            It will be called on each line of the summary.</span>

<span class="s2">            You can set it to a custom function</span>

<span class="s2">            in order to capture the string summary.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: if `summary()` is called before the model is built.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;This model has not yet been built. &#39;</span>

                       <span class="s1">&#39;Build the model first by calling `build()` or calling &#39;</span>

                       <span class="s1">&#39;`fit()` with some data, or specify &#39;</span>

                       <span class="s1">&#39;an `input_shape` argument in the first layer(s) for &#39;</span>

                       <span class="s1">&#39;automatic build.&#39;</span><span class="p">)</span>

    <span class="n">layer_utils</span><span class="p">.</span><span class="n">print_summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                              <span class="n">line_length</span><span class="o">=</span><span class="n">line_length</span><span class="p">,</span>

                              <span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span>

                              <span class="n">print_fn</span><span class="o">=</span><span class="n">print_fn</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="test_on_batch">test_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Test the model on a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be: - A Numpy array (or array-like), or a list</td>
<td></td>
</tr>
<tr>
<td>of arrays (in case the model has multiple inputs). - A TensorFlow</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>tensor, or a list of tensors (in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A dict mapping input names to the corresponding array/tensors, if</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the model has named inputs.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy</td>
<td></td>
</tr>
<tr>
<td>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional array of the same length as x, containing</td>
<td></td>
</tr>
<tr>
<td>weights to apply to the model's loss for each sample. In the case of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>temporal data, you can pass a 2D array with shape (samples,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sequence_length), to apply a different weight to every timestep of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>every sample.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>reset_metrics</td>
<td>None</td>
<td>If <code>True</code>, the metrics returned will be only for this</td>
<td></td>
</tr>
<tr>
<td>batch. If <code>False</code>, the metrics will be statefully accumulated across</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>batches.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,</td>
<td></td>
</tr>
<tr>
<td>with each key being the name of the metric. If <code>False</code>, they are</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returned as a list.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)</td>
</tr>
<tr>
<td>or list of scalars (if the model has multiple outputs</td>
<td></td>
</tr>
<tr>
<td>and/or metrics). The attribute <code>model.metrics_names</code> will give you</td>
<td></td>
</tr>
<tr>
<td>the display labels for the scalar outputs.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.test_on_batch</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of invalid user-provided arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">test_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                    <span class="n">x</span><span class="p">,</span>

                    <span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

                    <span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Test the model on a single batch of samples.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input data. It could be: - A Numpy array (or array-like), or a list</span>

<span class="s2">          of arrays (in case the model has multiple inputs). - A TensorFlow</span>

<span class="s2">          tensor, or a list of tensors (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors, if</span>

<span class="s2">          the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.</span>

<span class="s2">        ValueError: In case of invalid user-provided arguments.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="n">iterator</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>

                                                    <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">reset_metrics</span><span class="o">:</span>

      <span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

    <span class="k">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_dict</span><span class="o">:</span>

      <span class="k">return</span> <span class="k">logs</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">results</span> <span class="o">=</span> <span class="err">[</span><span class="k">logs</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="k">name</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">for</span> <span class="k">name</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="err">]</span>

      <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

        <span class="k">return</span> <span class="n">results</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

      <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

</details>
<h4 id="test_step">test_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="p">#</span> <span class="n">To</span> <span class="n">compute</span> <span class="n">the</span> <span class="n">loss</span> <span class="n">we</span> <span class="n">need</span> <span class="n">to</span> <span class="n">get</span> <span class="n">the</span> <span class="n">results</span> <span class="n">of</span> <span class="n">each</span> <span class="n">decoder</span> <span class="n">layer</span>

        <span class="p">#</span> <span class="n">Setting</span> <span class="n">training</span> <span class="n">to</span> <span class="n">True</span> <span class="n">will</span> <span class="n">provide</span> <span class="n">it</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>

        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mh">1</span><span class="o">:</span><span class="mh">3</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">compute_dtype</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">None</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">loss_metric</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="p">.</span><span class="nl">name:</span> <span class="n">m</span><span class="p">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="n">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">}</span>
</code></pre></div>

</details>
<h4 id="to_json">to_json</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a JSON string containing the network configuration.</p>
<p>To load a network from a JSON save file, use
<code>keras.models.model_from_json(json_string, custom_objects={})</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments</td>
<td></td>
</tr>
<tr>
<td>to be passed to <code>json.dumps()</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A JSON string.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Returns a JSON string containing the network configuration.</span>

<span class="sd">    To load a network from a JSON save file, use</span>

<span class="sd">    `keras.models.model_from_json(json_string, custom_objects={})`.</span>

<span class="sd">    Arguments:</span>

<span class="sd">        **kwargs: Additional keyword arguments</span>

<span class="sd">            to be passed to `json.dumps()`.</span>

<span class="sd">    Returns:</span>

<span class="sd">        A JSON string.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_updated_config</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>

        <span class="n">model_config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">json_utils</span><span class="o">.</span><span class="n">get_json_type</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="to_yaml">to_yaml</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_yaml</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a yaml string containing the network configuration.</p>
<p>To load a network from a yaml save file, use
<code>keras.models.model_from_yaml(yaml_string, custom_objects={})</code>.</p>
<p><code>custom_objects</code> should be a dictionary mapping
the names of custom losses / layers / etc to the corresponding
functions / classes.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments</td>
<td></td>
</tr>
<tr>
<td>to be passed to <code>yaml.dump()</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A YAML string.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>if yaml module is not found.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">to_yaml</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns a yaml string containing the network configuration.</span>

<span class="s2">    To load a network from a yaml save file, use</span>

<span class="s2">    `keras.models.model_from_yaml(yaml_string, custom_objects={})`.</span>

<span class="s2">    `custom_objects` should be a dictionary mapping</span>

<span class="s2">    the names of custom losses / layers / etc to the corresponding</span>

<span class="s2">    functions / classes.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        **kwargs: Additional keyword arguments</span>

<span class="s2">            to be passed to `yaml.dump()`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A YAML string.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ImportError: if yaml module is not found.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">yaml</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ImportError</span><span class="p">(</span>

          <span class="s1">&#39;Requires yaml module installed (`pip install pyyaml`).&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">yaml</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_updated_config</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="train_on_batch">train_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Runs a single gradient update on a single batch of data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:</td>
<td></td>
</tr>
<tr>
<td>- A Numpy array (or array-like), or a list of arrays</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A TensorFlow tensor, or a list of tensors</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A dict mapping input names to the corresponding array/tensors,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>if the model has named inputs.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy</td>
<td></td>
</tr>
<tr>
<td>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional array of the same length as x, containing</td>
<td></td>
</tr>
<tr>
<td>weights to apply to the model's loss for each sample. In the case of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>temporal data, you can pass a 2D array with shape (samples,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sequence_length), to apply a different weight to every timestep of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>every sample.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>class_weight</td>
<td>None</td>
<td>Optional dictionary mapping class indices (integers) to a</td>
<td></td>
</tr>
<tr>
<td>weight (float) to apply to the model's loss for the samples from this</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>class during training. This can be useful to tell the model to "pay</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>more attention" to samples from an under-represented class.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>reset_metrics</td>
<td>None</td>
<td>If <code>True</code>, the metrics returned will be only for this</td>
<td></td>
</tr>
<tr>
<td>batch. If <code>False</code>, the metrics will be statefully accumulated across</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>batches.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,</td>
<td></td>
</tr>
<tr>
<td>with each key being the name of the metric. If <code>False</code>, they are</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returned as a list.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar training loss</td>
</tr>
<tr>
<td>(if the model has a single output and no metrics)</td>
<td></td>
</tr>
<tr>
<td>or list of scalars (if the model has multiple outputs</td>
<td></td>
</tr>
<tr>
<td>and/or metrics). The attribute <code>model.metrics_names</code> will give you</td>
<td></td>
</tr>
<tr>
<td>the display labels for the scalar outputs.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.train_on_batch</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of invalid user-provided arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">train_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                     <span class="n">x</span><span class="p">,</span>

                     <span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                     <span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                     <span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                     <span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

                     <span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single gradient update on a single batch of data.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">              if the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        class_weight: Optional dictionary mapping class indices (integers) to a</span>

<span class="s2">          weight (float) to apply to the model&#39;s loss for the samples from this</span>

<span class="s2">          class during training. This can be useful to tell the model to &quot;</span><span class="n">pay</span>

          <span class="n">more</span> <span class="n">attention</span><span class="s2">&quot; to samples from an under-represented class.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar training loss</span>

<span class="s2">        (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">      RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.</span>

<span class="s2">      ValueError: In case of invalid user-provided arguments.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">(),</span> <span class="err">\</span>

         <span class="n">training_utils</span><span class="p">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

      <span class="n">iterator</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>

                                                    <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span>

                                                    <span class="n">class_weight</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_train_function</span><span class="p">()</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">reset_metrics</span><span class="o">:</span>

      <span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

    <span class="k">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_dict</span><span class="o">:</span>

      <span class="k">return</span> <span class="k">logs</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">results</span> <span class="o">=</span> <span class="err">[</span><span class="k">logs</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="k">name</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">for</span> <span class="k">name</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="err">]</span>

      <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

        <span class="k">return</span> <span class="n">results</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

      <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

</details>
<h4 id="train_step">train_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>

            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>

            <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">None</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span> <span class="n">tape</span><span class="o">=</span><span class="n">tape</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span>
</code></pre></div>

</details>
<h3 id="detrresnet50">DeTrResnet50</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">DeTrResnet50</span><span class="p">(</span>
    <span class="n">num_classes</span><span class="p">,</span>
    <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<h4 id="attributes_1">Attributes</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>num_classes</td>
<td>None</td>
<td>The number of classes of your dataset</td>
<td></td>
</tr>
<tr>
<td>(<strong>do not include the background class</strong> it is handle for you)</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>backbone</td>
<td>None</td>
<td>A vision model like ResNet50.</td>
<td>None</td>
</tr>
<tr>
<td>num_queries</td>
<td>None</td>
<td>number of object queries, ie detection slot.</td>
<td></td>
</tr>
<tr>
<td>This is the maximal number of objects</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>DETR can detect in a single image. For COCO, we recommend 100 queries.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Call arguments: | None |
| inputs | None | Tuple
1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]
2. image_informations: A 1D tensor of float32 and shape [(height, width),].
    It contains the shape of the image without any padding.
3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None]
    composed of 0 and 1 which allows to know where a padding has been applied. | None |
| training | None | Is automatically set to <code>True</code> in train mode
Call returns: | None |
| logits | None | A Tensor of shape [batch_size, h, num_classes + 1] class logits | None |
| boxes | None | A Tensor of shape [batch_size, h, 4]
where h is num_queries * transformer_decoder.transformer_num_layers if
training is true and num_queries otherwise. | None |</p>
<h4 id="ancestors-in-mro_1">Ancestors (in MRO)</h4>
<ul>
<li>kerod.model.detr.DeTr</li>
<li>tensorflow.python.keras.engine.training.Model</li>
<li>tensorflow.python.keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>tensorflow.python.keras.utils.version_utils.LayerVersionSelector</li>
<li>tensorflow.python.keras.utils.version_utils.ModelVersionSelector</li>
</ul>
<h4 id="static-methods_1">Static methods</h4>
<h4 id="from_config_1">from_config</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span>
    <span class="n">config</span><span class="p">,</span>
    <span class="n">custom_objects</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a layer from its config.</p>
<p>This method is the reverse of <code>get_config</code>,
capable of instantiating the same layer from the config
dictionary. It does not handle layer connectivity
(handled by Network), nor weights (handled by <code>set_weights</code>).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>config</td>
<td>None</td>
<td>A Python dictionary, typically the</td>
<td></td>
</tr>
<tr>
<td>output of get_config.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nd">@classmethod</span>

  <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

    <span class="c1"># Since only FunctionalModel produces config, the model can only</span>

    <span class="c1"># be constructed for FunctionalModel</span>

    <span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="kn">import</span> <span class="n">functional</span>  <span class="c1"># pylint: disable=g-import-not-at-top</span>

    <span class="k">return</span> <span class="n">functional</span><span class="o">.</span><span class="n">Functional</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span>

        <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">custom_objects</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="with_name_scope_1">with_name_scope</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">with_name_scope</span><span class="p">(</span>
    <span class="n">method</span>
<span class="p">)</span>
</code></pre></div>

<p>Decorator to automatically enter the module name scope.</p>
<blockquote>
<blockquote>
<blockquote>
<p>class MyModule(tf.Module):
...   @tf.Module.with_name_scope
...   def <strong>call</strong>(self, x):
...     if not hasattr(self, 'w'):
...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))
...     return tf.matmul(x, self.w)</p>
</blockquote>
</blockquote>
</blockquote>
<p>Using the above module would produce <code>tf.Variable</code>s and <code>tf.Tensor</code>s whose
names included the module name:</p>
<blockquote>
<blockquote>
<blockquote>
<p>mod = MyModule()
mod(tf.ones([1, 2]))
<tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>
mod.w
<tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,
numpy=..., dtype=float32)></p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>method</td>
<td>None</td>
<td>The method to wrap.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The original method wrapped such that it enters the module's name scope.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@classmethod</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">with_name_scope</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span><span class="w"> </span><span class="k">method</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Decorator to automatically enter the module name scope.</span>

<span class="ss">    &gt;&gt;&gt; class MyModule(tf.Module):</span>

<span class="ss">    ...   @tf.Module.with_name_scope</span>

<span class="ss">    ...   def __call__(self, x):</span>

<span class="ss">    ...     if not hasattr(self, &#39;w&#39;):</span>

<span class="ss">    ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))</span>

<span class="ss">    ...     return tf.matmul(x, self.w)</span>

<span class="ss">    Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose</span>

<span class="ss">    names included the module name:</span>

<span class="ss">    &gt;&gt;&gt; mod = MyModule()</span>

<span class="ss">    &gt;&gt;&gt; mod(tf.ones([1, 2]))</span>

<span class="ss">    &lt;tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)&gt;</span>

<span class="ss">    &gt;&gt;&gt; mod.w</span>

<span class="ss">    &lt;tf.Variable &#39;my_module/Variable:0&#39; shape=(2, 3) dtype=float32,</span>

<span class="ss">    numpy=..., dtype=float32)&gt;</span>

<span class="ss">    Args:</span>

<span class="ss">      method: The method to wrap.</span>

<span class="ss">    Returns:</span>

<span class="ss">      The original method wrapped such that it enters the module&#39;s name scope.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">method_with_name_scope</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">name_scope</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">method</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tf_decorator</span><span class="p">.</span><span class="n">make_decorator</span><span class="p">(</span><span class="k">method</span><span class="p">,</span><span class="w"> </span><span class="n">method_with_name_scope</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="instance-variables_1">Instance variables</h4>
<div class="codehilite"><pre><span></span><code><span class="n">activity_regularizer</span>
</code></pre></div>

<p>Optional regularizer function for the output of this layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">compute_dtype</span>
</code></pre></div>

<p>The dtype of the layer's computations.</p>
<p>This is equivalent to <code>Layer.dtype_policy.compute_dtype</code>. Unless
mixed precision is used, this is the same as <code>Layer.dtype</code>, the dtype of
the weights.</p>
<p>Layers automatically cast their inputs to the compute dtype, which causes
computations and the output to be in the compute dtype as well. This is done
by the base Layer class in <code>Layer.__call__</code>, so you do not have to insert
these casts if implementing your own layer.</p>
<p>Layers often perform certain internal computations in higher precision when
<code>compute_dtype</code> is float16 or bfloat16 for numeric stability. The output
will still typically be float16 or bfloat16 in such cases.</p>
<div class="codehilite"><pre><span></span><code><span class="n">distribute_strategy</span>
</code></pre></div>

<p>The <code>tf.distribute.Strategy</code> this model was created under.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dtype</span>
</code></pre></div>

<p>The dtype of the layer weights.</p>
<p>This is equivalent to <code>Layer.dtype_policy.variable_dtype</code>. Unless
mixed precision is used, this is the same as <code>Layer.compute_dtype</code>, the
dtype of the layer's computations.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dtype_policy</span>
</code></pre></div>

<p>The dtype policy associated with this layer.</p>
<p>This is an instance of a <code>tf.keras.mixed_precision.Policy</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dynamic</span>
</code></pre></div>

<p>Whether the layer is dynamic (eager-only); set in the constructor.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inbound_nodes</span>
</code></pre></div>

<p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>
<div class="codehilite"><pre><span></span><code><span class="nb">input</span>
</code></pre></div>

<p>Retrieves the input tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_mask</span>
</code></pre></div>

<p>Retrieves the input mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>
<p>Returns:
    Input mask tensor (potentially None) or list of input
    mask tensors.</p>
<p>Raises:
    AttributeError: if the layer is connected to
    more than one incoming layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_shape</span>
</code></pre></div>

<p>Retrieves the input shape(s) of a layer.</p>
<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer, or if all inputs
have the same shape.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_spec</span>
</code></pre></div>

<p><code>InputSpec</code> instance(s) describing the input format for this layer.</p>
<p>When you create a layer subclass, you can set <code>self.input_spec</code> to enable
the layer to run input compatibility checks when it is called.
Consider a <code>Conv2D</code> layer: it can only be called on a single input tensor
of rank 4. As such, you can set, in <code>__init__()</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputSpec</span><span class="p">(</span><span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div>

<p>Now, if you try to call the layer on an input that isn't rank 4
(for instance, an input of shape <code>(2,)</code>, it will raise a nicely-formatted
error:</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span> <span class="n">Input</span> <span class="mi">0</span> <span class="n">of</span> <span class="n">layer</span> <span class="n">conv2d</span> <span class="k">is</span> <span class="n">incompatible</span> <span class="k">with</span> <span class="n">the</span> <span class="n">layer</span><span class="o">:</span>
<span class="n">expected</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="o">,</span> <span class="n">found</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="o">.</span> <span class="n">Full</span> <span class="n">shape</span> <span class="n">received</span><span class="o">:</span> <span class="o">[</span><span class="mi">2</span><span class="o">]</span>
</code></pre></div>

<p>Input checks that can be specified via <code>input_spec</code> include:
- Structure (e.g. a single input, a list of 2 inputs, etc)
- Shape
- Rank (ndim)
- Dtype</p>
<p>For more information, see <code>tf.keras.layers.InputSpec</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">layers</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">losses</span>
</code></pre></div>

<p>List of losses added using the <code>add_loss()</code> API.</p>
<p>Variable regularization tensors are created when this property is accessed,
so it is eager safe: accessing <code>losses</code> under a <code>tf.GradientTape</code> will
propagate gradients back to the corresponding variables.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>class MyLayer(tf.keras.layers.Layer):
...   def call(self, inputs):
...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))
...     return inputs
l = MyLayer()
l(np.ones((10, 1)))
l.losses
[1.0]</p>
<p>inputs = tf.keras.Input(shape=(10,))
x = tf.keras.layers.Dense(10)(inputs)
outputs = tf.keras.layers.Dense(1)(x)
model = tf.keras.Model(inputs, outputs)</p>
<h1 id="activity-regularization_1">Activity regularization.</h1>
<p>len(model.losses)
0
model.add_loss(tf.abs(tf.reduce_mean(x)))
len(model.losses)
1</p>
<p>inputs = tf.keras.Input(shape=(10,))
d = tf.keras.layers.Dense(10, kernel_initializer='ones')
x = d(inputs)
outputs = tf.keras.layers.Dense(1)(x)
model = tf.keras.Model(inputs, outputs)</p>
<h1 id="weight-regularization_1">Weight regularization.</h1>
<p>model.add_loss(lambda: tf.reduce_mean(d.kernel))
model.losses
[<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]</p>
</blockquote>
</blockquote>
</blockquote>
<p>Returns:
  A list of tensors.</p>
<div class="codehilite"><pre><span></span><code><span class="n">metrics</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">metrics_names</span>
</code></pre></div>

<p>Returns the model's display labels for all outputs.</p>
<p>Note: <code>metrics_names</code> are available only after a <code>keras.Model</code> has been
trained/evaluated on actual data.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>inputs = tf.keras.layers.Input(shape=(3,))
outputs = tf.keras.layers.Dense(2)(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
model.compile(optimizer="Adam", loss="mse", metrics=["mae"])
model.metrics_names
[]</p>
<p>x = np.random.random((2, 3))
y = np.random.randint(0, 2, (2, 2))
model.fit(x, y)
model.metrics_names
['loss', 'mae']</p>
<p>inputs = tf.keras.layers.Input(shape=(3,))
d = tf.keras.layers.Dense(2, name='out')
output_1 = d(inputs)
output_2 = d(inputs)
model = tf.keras.models.Model(
...    inputs=inputs, outputs=[output_1, output_2])
model.compile(optimizer="Adam", loss="mse", metrics=["mae", "acc"])
model.fit(x, (y, y))
model.metrics_names
['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',
'out_1_acc']</p>
</blockquote>
</blockquote>
</blockquote>
<div class="codehilite"><pre><span></span><code><span class="n">name</span>
</code></pre></div>

<p>Name of the layer (string), set in the constructor.</p>
<div class="codehilite"><pre><span></span><code><span class="n">name_scope</span>
</code></pre></div>

<p>Returns a <code>tf.name_scope</code> instance for this class.</p>
<div class="codehilite"><pre><span></span><code><span class="n">non_trainable_variables</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">non_trainable_weights</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">outbound_nodes</span>
</code></pre></div>

<p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output</span>
</code></pre></div>

<p>Retrieves the output tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one output,
i.e. if it is connected to one incoming layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output_mask</span>
</code></pre></div>

<p>Retrieves the output mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>
<p>Returns:
    Output mask tensor (potentially None) or list of output
    mask tensors.</p>
<p>Raises:
    AttributeError: if the layer is connected to
    more than one incoming layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output_shape</span>
</code></pre></div>

<p>Retrieves the output shape(s) of a layer.</p>
<p>Only applicable if the layer has one output,
or if all outputs have the same shape.</p>
<div class="codehilite"><pre><span></span><code><span class="n">run_eagerly</span>
</code></pre></div>

<p>Settable attribute indicating whether the model should run eagerly.</p>
<p>Running eagerly means that your model will be run step by step,
like Python code. Your model might run slower, but it should become easier
for you to debug it by stepping into individual layer calls.</p>
<p>By default, we will attempt to compile your model to a static graph to
deliver the best execution performance.</p>
<div class="codehilite"><pre><span></span><code><span class="n">state_updates</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Returns the <code>updates</code> from all layers that are stateful.</p>
<p>This is useful for separating training updates and
state updates, e.g. when we need to update a layer's internal state
during prediction.</p>
<div class="codehilite"><pre><span></span><code><span class="n">stateful</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">submodules</span>
</code></pre></div>

<p>Sequence of all sub-modules.</p>
<p>Submodules are modules which are properties of this module, or found as
properties of modules which are properties of this module (and so on).</p>
<blockquote>
<blockquote>
<blockquote>
<p>a = tf.Module()
b = tf.Module()
c = tf.Module()
a.b = b
b.c = c
list(a.submodules) == [b, c]
True
list(b.submodules) == [c]
True
list(c.submodules) == []
True</p>
</blockquote>
</blockquote>
</blockquote>
<div class="codehilite"><pre><span></span><code><span class="n">supports_masking</span>
</code></pre></div>

<p>Whether this layer supports computing a mask using <code>compute_mask</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">trainable</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">trainable_variables</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">trainable_weights</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">updates</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">variable_dtype</span>
</code></pre></div>

<p>Alias of <code>Layer.dtype</code>, the dtype of the weights.</p>
<div class="codehilite"><pre><span></span><code><span class="n">variables</span>
</code></pre></div>

<p>Returns the list of all layer variables/weights.</p>
<p>Alias of <code>self.weights</code>.</p>
<p>Note: This will not track the weights of nested <code>tf.Modules</code> that are not
themselves Keras layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">weights</span>
</code></pre></div>

<p>Returns the list of all layer variables/weights.</p>
<p>Note: This will not track the weights of nested <code>tf.Modules</code> that are not
themselves Keras layers.</p>
<h4 id="methods_1">Methods</h4>
<h4 id="add_loss_1">add_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">losses</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Add loss tensor(s), potentially dependent on layer inputs.</p>
<p>Some losses (for instance, activity regularization losses) may be dependent
on the inputs passed when calling a layer. Hence, when reusing the same
layer on different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.losses</code> may
be dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>
<p>This method can be used inside a subclassed layer or model's <code>call</code>
function, in which case <code>losses</code> should be a Tensor or list of Tensors.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">inputs</span>
</code></pre></div>

<p>This method can also be called directly on a Functional Model during
construction. In this case, any loss Tensors passed to this Model must
be symbolic and be able to be traced back to the model's <code>Input</code>s. These
losses become part of the model's topology and are tracked in <code>get_config</code>.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="c1"># Activity regularization.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</code></pre></div>

<p>If this is not the case for your loss (if, for example, your loss references
a <code>Variable</code> of one of the model's layers), you can wrap your loss in a
zero-argument lambda. These losses are not tracked as part of the model's
topology since they can't be serialized.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">d</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="c1"># Weight regularization.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">kernel</span><span class="p">))</span>
</code></pre></div>

<p>Arguments:
  losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses
    may also be zero-argument callables which create a loss tensor.
  **kwargs: Additional keyword arguments for backward compatibility.
    Accepted values:
      inputs - Deprecated, will be automatically inferred.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">add_loss</span>(<span class="nb">self</span>, <span class="n">losses</span>, **<span class="n">kwargs</span>):

    <span class="s">&quot;&quot;&quot;Add loss tensor(s), potentially dependent on layer inputs.</span>

<span class="s">    Some losses (for instance, activity regularization losses) may be dependent</span>

<span class="s">    on the inputs passed when calling a layer. Hence, when reusing the same</span>

<span class="s">    layer on different inputs `a` and `b`, some entries in `layer.losses` may</span>

<span class="s">    be dependent on `a` and some on `b`. This method automatically keeps track</span>

<span class="s">    of dependencies.</span>

<span class="s">    This method can be used inside a subclassed layer or model&#39;s `call`</span>

<span class="s">    function, in which case `losses` should be a Tensor or list of Tensors.</span>

<span class="s">    Example:</span>

<span class="s">    ```python</span>

<span class="s">    class MyLayer(tf.keras.layers.Layer):</span>

<span class="s">      def call(self, inputs):</span>

<span class="s">        self.add_loss(tf.abs(tf.reduce_mean(inputs)))</span>

<span class="s">        return inputs</span>

<span class="s">    ```</span>

<span class="s">    This method can also be called directly on a Functional Model during</span>

<span class="s">    construction. In this case, any loss Tensors passed to this Model must</span>

<span class="s">    be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>

<span class="s">    losses become part of the model&#39;s topology and are tracked in `get_config`.</span>

<span class="s">    Example:</span>

<span class="s">    ```python</span>

<span class="s">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s">    x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s">    # Activity regularization.</span>

<span class="s">    model.add_loss(tf.abs(tf.reduce_mean(x)))</span>

<span class="s">    ```</span>

<span class="s">    If this is not the case for your loss (if, for example, your loss references</span>

<span class="s">    a `Variable` of one of the model&#39;s layers), you can wrap your loss in a</span>

<span class="s">    zero-argument lambda. These losses are not tracked as part of the model&#39;s</span>

<span class="s">    topology since they can&#39;t be serialized.</span>

<span class="s">    Example:</span>

<span class="s">    ```python</span>

<span class="s">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s">    d = tf.keras.layers.Dense(10)</span>

<span class="s">    x = d(inputs)</span>

<span class="s">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s">    # Weight regularization.</span>

<span class="s">    model.add_loss(lambda: tf.reduce_mean(d.kernel))</span>

<span class="s">    ```</span>

<span class="s">    Arguments:</span>

<span class="s">      losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses</span>

<span class="s">        may also be zero-argument callables which create a loss tensor.</span>

<span class="s">      **kwargs: Additional keyword arguments for backward compatibility.</span>

<span class="s">        Accepted values:</span>

<span class="s">          inputs - Deprecated, will be automatically inferred.</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="n">kwargs</span>.<span class="nb">pop</span>(<span class="s">&#39;inputs&#39;</span>, <span class="n">None</span>)

    <span class="k">if</span> <span class="n">kwargs:</span>

      <span class="n">raise</span> <span class="n">TypeError</span>(<span class="s">&#39;Unknown keyword arguments: %s&#39;</span> % (<span class="n">kwargs</span>.<span class="nb">keys</span>(),))

    <span class="n">def</span> <span class="n">_tag_callable</span>(<span class="n">loss</span>):

      <span class="s">&quot;&quot;&quot;Tags callable loss tensor as `_unconditional_loss`.&quot;&quot;&quot;</span>

      <span class="k">if</span> <span class="n">callable</span>(<span class="n">loss</span>):

        <span class="c1"># We run the loss without autocasting, as regularizers are often</span>

        <span class="c1"># numerically unstable in float16.</span>

        <span class="k">with</span> <span class="n">autocast_variable</span>.<span class="n">enable_auto_cast_variables</span>(<span class="n">None</span>):

          <span class="n">loss</span> = <span class="n">loss</span>()

      <span class="k">if</span> <span class="n">loss</span> <span class="k">is</span> <span class="n">None:</span>

        <span class="k">return</span> <span class="n">None</span>  <span class="c1"># Will be filtered out when computing the .losses property</span>

      <span class="k">if</span> <span class="nb">not</span> <span class="n">tensor_util</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>):

        <span class="n">loss</span> = <span class="n">ops</span>.<span class="n">convert_to_tensor_v2_with_dispatch</span>(

            <span class="n">loss</span>, <span class="n">dtype</span>=<span class="n">backend</span>.<span class="n">floatx</span>())

      <span class="n">loss</span>.<span class="n">_unconditional_loss</span> = <span class="nb">True</span>  <span class="c1"># pylint: disable=protected-access</span>

      <span class="k">return</span> <span class="n">loss</span>

    <span class="n">losses</span> = <span class="n">nest</span>.<span class="n">flatten</span>(<span class="n">losses</span>)

    <span class="n">callable_losses</span> = []

    <span class="n">eager_losses</span> = []

    <span class="n">symbolic_losses</span> = []

    <span class="k">for</span> <span class="n">loss</span> <span class="nb">in</span> <span class="n">losses:</span>

      <span class="k">if</span> <span class="n">callable</span>(<span class="n">loss</span>):

        <span class="n">callable_losses</span>.<span class="nb">append</span>(<span class="n">functools</span>.<span class="n">partial</span>(<span class="n">_tag_callable</span>, <span class="n">loss</span>))

        <span class="n">continue</span>

      <span class="k">if</span> <span class="n">loss</span> <span class="k">is</span> <span class="n">None:</span>

        <span class="n">continue</span>

      <span class="k">if</span> <span class="nb">not</span> <span class="n">tensor_util</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>) <span class="o">and</span> <span class="nb">not</span> <span class="n">isinstance</span>(

          <span class="n">loss</span>, <span class="n">keras_tensor</span>.<span class="n">KerasTensor</span>):

        <span class="n">loss</span> = <span class="n">ops</span>.<span class="n">convert_to_tensor_v2_with_dispatch</span>(

            <span class="n">loss</span>, <span class="n">dtype</span>=<span class="n">backend</span>.<span class="n">floatx</span>())

      <span class="c1"># TF Functions should take the eager path.</span>

      <span class="k">if</span> ((<span class="n">tf_utils</span>.<span class="n">is_symbolic_tensor</span>(<span class="n">loss</span>) <span class="o">or</span>

           <span class="n">isinstance</span>(<span class="n">loss</span>, <span class="n">keras_tensor</span>.<span class="n">KerasTensor</span>)) <span class="o">and</span>

          <span class="nb">not</span> <span class="n">base_layer_utils</span>.<span class="n">is_in_tf_function</span>()):

        <span class="n">symbolic_losses</span>.<span class="nb">append</span>(<span class="n">loss</span>)

      <span class="n">elif</span> <span class="n">tensor_util</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>):

        <span class="n">eager_losses</span>.<span class="nb">append</span>(<span class="n">loss</span>)

    <span class="nb">self</span>.<span class="n">_callable_losses</span>.<span class="n">extend</span>(<span class="n">callable_losses</span>)

    <span class="n">in_call_context</span> = <span class="n">base_layer_utils</span>.<span class="n">call_context</span>().<span class="n">in_call</span>

    <span class="k">if</span> <span class="n">eager_losses</span> <span class="o">and</span> <span class="nb">not</span> <span class="n">in_call_context:</span>

      <span class="n">raise</span> <span class="n">ValueError</span>(

          <span class="s">&#39;Expected a symbolic Tensors or a callable for the loss value. &#39;</span>

          <span class="s">&#39;Please wrap your loss computation in a zero argument `lambda`.&#39;</span>)

    <span class="nb">self</span>.<span class="n">_eager_losses</span>.<span class="n">extend</span>(<span class="n">eager_losses</span>)

    <span class="k">if</span> <span class="n">in_call_context</span> <span class="o">and</span> <span class="nb">not</span> <span class="n">keras_tensor</span>.<span class="n">keras_tensors_enabled</span>():

      <span class="k">for</span> <span class="n">symbolic_loss</span> <span class="nb">in</span> <span class="n">symbolic_losses:</span>

        <span class="nb">self</span>.<span class="n">_losses</span>.<span class="nb">append</span>(<span class="n">symbolic_loss</span>)

    <span class="n">else:</span>

      <span class="k">for</span> <span class="n">symbolic_loss</span> <span class="nb">in</span> <span class="n">symbolic_losses:</span>

        <span class="k">if</span> <span class="n">getattr</span>(<span class="nb">self</span>, <span class="s">&#39;_is_graph_network&#39;</span>, <span class="nb">False</span>):

          <span class="nb">self</span>.<span class="n">_graph_network_add_loss</span>(<span class="n">symbolic_loss</span>)

        <span class="n">else:</span>

          <span class="c1"># Possible a loss was added in a Layer&#39;s `build`.</span>

          <span class="nb">self</span>.<span class="n">_losses</span>.<span class="nb">append</span>(<span class="n">symbolic_loss</span>)
</code></pre></div>

</details>
<h4 id="add_metric_1">add_metric</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_metric</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">value</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Adds metric tensor to the layer.</p>
<p>This method can be used inside the <code>call()</code> method of a subclassed layer
or model.</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyMetricLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyMetricLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_metric_layer&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_2&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span>
</code></pre></div>

<p>This method can also be called directly on a Functional Model during
construction. In this case, any tensor passed to this Model must
be symbolic and be able to be traced back to the model's <code>Input</code>s. These
metrics become part of the model's topology and are tracked when you
save the model via <code>save()</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

<p>Note: Calling <code>add_metric()</code> with the result of a metric object on a
Functional Model, as shown in the example below, is not supported. This is
because we cannot trace the metric result tensor back to the model's inputs.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">()(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>None</td>
<td>Metric tensor.</td>
<td>None</td>
</tr>
<tr>
<td>name</td>
<td>None</td>
<td>String metric name.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments for backward compatibility.</td>
<td></td>
</tr>
<tr>
<td>Accepted values:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>aggregation</code> - When the <code>value</code> tensor provided is not the result of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>calling a <code>keras.Metric</code> instance, it will be aggregated by default</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>using a <code>keras.Metric.Mean</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">add_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="k">value</span><span class="p">,</span> <span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Adds metric tensor to the layer.</span>

<span class="s2">    This method can be used inside the `call()` method of a subclassed layer</span>

<span class="s2">    or model.</span>

<span class="s2">    ```python</span>

<span class="s2">    class MyMetricLayer(tf.keras.layers.Layer):</span>

<span class="s2">      def __init__(self):</span>

<span class="s2">        super(MyMetricLayer, self).__init__(name=&#39;my_metric_layer&#39;)</span>

<span class="s2">        self.mean = tf.keras.metrics.Mean(name=&#39;metric_1&#39;)</span>

<span class="s2">      def call(self, inputs):</span>

<span class="s2">        self.add_metric(self.mean(x))</span>

<span class="s2">        self.add_metric(tf.reduce_sum(x), name=&#39;metric_2&#39;)</span>

<span class="s2">        return inputs</span>

<span class="s2">    ```</span>

<span class="s2">    This method can also be called directly on a Functional Model during</span>

<span class="s2">    construction. In this case, any tensor passed to this Model must</span>

<span class="s2">    be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>

<span class="s2">    metrics become part of the model&#39;s topology and are tracked when you</span>

<span class="s2">    save the model via `save()`.</span>

<span class="s2">    ```python</span>

<span class="s2">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s2">    x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s2">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s2">    model.add_metric(math_ops.reduce_sum(x), name=&#39;metric_1&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    Note: Calling `add_metric()` with the result of a metric object on a</span>

<span class="s2">    Functional Model, as shown in the example below, is not supported. This is</span>

<span class="s2">    because we cannot trace the metric result tensor back to the model&#39;s inputs.</span>

<span class="s2">    ```python</span>

<span class="s2">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s2">    x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s2">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s2">    model.add_metric(tf.keras.metrics.Mean()(x), name=&#39;metric_1&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    Args:</span>

<span class="s2">      value: Metric tensor.</span>

<span class="s2">      name: String metric name.</span>

<span class="s2">      **kwargs: Additional keyword arguments for backward compatibility.</span>

<span class="s2">        Accepted values:</span>

<span class="s2">        `aggregation` - When the `value` tensor provided is not the result of</span>

<span class="s2">        calling a `keras.Metric` instance, it will be aggregated by default</span>

<span class="s2">        using a `keras.Metric.Mean`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">kwargs_keys</span> <span class="o">=</span> <span class="k">list</span><span class="p">(</span><span class="n">kwargs</span><span class="p">.</span><span class="k">keys</span><span class="p">())</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">or</span>

        <span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">and</span> <span class="n">kwargs_keys</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span> <span class="o">!=</span> <span class="s1">&#39;aggregation&#39;</span><span class="p">))</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">TypeError</span><span class="p">(</span><span class="s1">&#39;Unknown keyword arguments: &#39;</span><span class="p">,</span> <span class="n">str</span><span class="p">(</span><span class="n">kwargs</span><span class="p">.</span><span class="k">keys</span><span class="p">()))</span>

    <span class="n">from_metric_obj</span> <span class="o">=</span> <span class="n">hasattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="s1">&#39;_metric_obj&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">keras_tensor</span><span class="p">.</span><span class="n">keras_tensors_enabled</span><span class="p">()</span><span class="o">:</span>

      <span class="n">is_symbolic</span> <span class="o">=</span> <span class="n">isinstance</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="n">keras_tensor</span><span class="p">.</span><span class="n">KerasTensor</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">is_symbolic</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">is_symbolic_tensor</span><span class="p">(</span><span class="k">value</span><span class="p">)</span>

    <span class="n">in_call_context</span> <span class="o">=</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">call_context</span><span class="p">().</span><span class="n">in_call</span>

    <span class="k">if</span> <span class="k">name</span> <span class="k">is</span> <span class="k">None</span> <span class="k">and</span> <span class="k">not</span> <span class="n">from_metric_obj</span><span class="o">:</span>

      <span class="c1"># Eg. `self.add_metric(math_ops.reduce_sum(x))`</span>

      <span class="c1"># In eager mode, we use metric name to lookup a metric. Without a name,</span>

      <span class="c1"># a new Mean metric wrapper will be created on every model/layer call.</span>

      <span class="c1"># So, we raise an error when no name is provided.</span>

      <span class="c1"># We will do the same for symbolic mode for consistency although a name</span>

      <span class="c1"># will be generated if no name is provided.</span>

      <span class="c1"># We will not raise this error in the foll use case for the sake of</span>

      <span class="c1"># consistency as name in provided in the metric constructor.</span>

      <span class="c1"># mean = metrics.Mean(name=&#39;my_metric&#39;)</span>

      <span class="c1"># model.add_metric(mean(outputs))</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Please provide a name for your metric like &#39;</span>

                       <span class="s1">&#39;`self.add_metric(tf.reduce_sum(inputs), &#39;</span>

                       <span class="s1">&#39;name=</span><span class="se">\&#39;</span><span class="s1">mean_activation</span><span class="se">\&#39;</span><span class="s1">)`&#39;</span><span class="p">)</span>

    <span class="n">elif</span> <span class="n">from_metric_obj</span><span class="o">:</span>

      <span class="k">name</span> <span class="o">=</span> <span class="k">value</span><span class="p">.</span><span class="n">_metric_obj</span><span class="p">.</span><span class="k">name</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">in_call_context</span> <span class="k">and</span> <span class="k">not</span> <span class="n">is_symbolic</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Expected a symbolic Tensor for the metric value, &#39;</span>

                       <span class="s1">&#39;received: &#39;</span> <span class="o">+</span> <span class="n">str</span><span class="p">(</span><span class="k">value</span><span class="p">))</span>

    <span class="c1"># If a metric was added in a Layer&#39;s `call` or `build`.</span>

    <span class="k">if</span> <span class="n">in_call_context</span> <span class="k">or</span> <span class="k">not</span> <span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_is_graph_network&#39;</span><span class="p">,</span> <span class="no">False</span><span class="p">)</span><span class="o">:</span>

      <span class="c1"># TF Function path should take the eager path.</span>

      <span class="c1"># If the given metric is available in `metrics` list we just update state</span>

      <span class="c1"># on it, otherwise we create a new metric instance and</span>

      <span class="c1"># add it to the `metrics` list.</span>

      <span class="n">metric_obj</span> <span class="o">=</span> <span class="n">getattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="s1">&#39;_metric_obj&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>

      <span class="c1"># Tensors that come from a Metric object already updated the Metric state.</span>

      <span class="n">should_update_state</span> <span class="o">=</span> <span class="k">not</span> <span class="n">metric_obj</span>

      <span class="k">name</span> <span class="o">=</span> <span class="n">metric_obj</span><span class="p">.</span><span class="k">name</span> <span class="k">if</span> <span class="n">metric_obj</span> <span class="k">else</span> <span class="k">name</span>

      <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">_metrics_lock</span><span class="o">:</span>

        <span class="k">match</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_get_existing_metric</span><span class="p">(</span><span class="k">name</span><span class="p">)</span>

        <span class="k">if</span> <span class="k">match</span><span class="o">:</span>

          <span class="n">metric_obj</span> <span class="o">=</span> <span class="k">match</span>

        <span class="n">elif</span> <span class="n">metric_obj</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

        <span class="k">else</span><span class="o">:</span>

          <span class="c1"># Build the metric object with the value&#39;s dtype if it defines one</span>

          <span class="n">metric_obj</span> <span class="o">=</span> <span class="n">metrics_mod</span><span class="p">.</span><span class="n">Mean</span><span class="p">(</span>

              <span class="k">name</span><span class="o">=</span><span class="k">name</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">getattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">))</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">should_update_state</span><span class="o">:</span>

        <span class="n">metric_obj</span><span class="p">(</span><span class="k">value</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">from_metric_obj</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Using the result of calling a `Metric` object &#39;</span>

                         <span class="s1">&#39;when calling `add_metric` on a Functional &#39;</span>

                         <span class="s1">&#39;Model is not supported. Please pass the &#39;</span>

                         <span class="s1">&#39;Tensor to monitor directly.&#39;</span><span class="p">)</span>

      <span class="c1"># Insert layers into the Keras Graph Network.</span>

      <span class="n">aggregation</span> <span class="o">=</span> <span class="k">None</span> <span class="k">if</span> <span class="n">from_metric_obj</span> <span class="k">else</span> <span class="s1">&#39;mean&#39;</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_graph_network_add_metric</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="n">aggregation</span><span class="p">,</span> <span class="k">name</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="add_update_1">add_update</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_update</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">updates</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Add update op(s), potentially dependent on layer inputs.</p>
<p>Weight updates (for instance, the updates of the moving mean and variance
in a BatchNormalization layer) may be dependent on the inputs passed
when calling a layer. Hence, when reusing the same layer on
different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.updates</code> may be
dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>
<p>This call is ignored when eager execution is enabled (in that case, variable
updates are run on the fly and thus do not need to be tracked for later
execution).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>updates</td>
<td>None</td>
<td>Update op, or list/tuple of update ops, or zero-arg callable</td>
<td></td>
</tr>
<tr>
<td>that returns an update op. A zero-arg callable should be passed in</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>order to disable running the updates by setting <code>trainable=False</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>on this Layer, when executing in Eager mode.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>inputs</td>
<td>None</td>
<td>Deprecated, will be automatically inferred.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_doc_inheritable</span>

  <span class="n">def</span> <span class="n">add_update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Add update op(s), potentially dependent on layer inputs.</span>

<span class="s2">    Weight updates (for instance, the updates of the moving mean and variance</span>

<span class="s2">    in a BatchNormalization layer) may be dependent on the inputs passed</span>

<span class="s2">    when calling a layer. Hence, when reusing the same layer on</span>

<span class="s2">    different inputs `a` and `b`, some entries in `layer.updates` may be</span>

<span class="s2">    dependent on `a` and some on `b`. This method automatically keeps track</span>

<span class="s2">    of dependencies.</span>

<span class="s2">    This call is ignored when eager execution is enabled (in that case, variable</span>

<span class="s2">    updates are run on the fly and thus do not need to be tracked for later</span>

<span class="s2">    execution).</span>

<span class="s2">    Arguments:</span>

<span class="s2">      updates: Update op, or list/tuple of update ops, or zero-arg callable</span>

<span class="s2">        that returns an update op. A zero-arg callable should be passed in</span>

<span class="s2">        order to disable running the updates by setting `trainable=False`</span>

<span class="s2">        on this Layer, when executing in Eager mode.</span>

<span class="s2">      inputs: Deprecated, will be automatically inferred.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">inputs</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">tf_logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span>

          <span class="s1">&#39;`add_update` `inputs` kwarg has been deprecated. You no longer need &#39;</span>

          <span class="s1">&#39;to pass a value to `inputs` as it is being automatically inferred.&#39;</span><span class="p">)</span>

    <span class="n">call_context</span> <span class="o">=</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">call_context</span><span class="p">()</span>

    <span class="c1"># No need to run updates during Functional API construction.</span>

    <span class="k">if</span> <span class="n">call_context</span><span class="p">.</span><span class="n">in_keras_graph</span><span class="o">:</span>

      <span class="k">return</span>

    <span class="c1"># Callable updates are disabled by setting `trainable=False`.</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">call_context</span><span class="p">.</span><span class="n">frozen</span><span class="o">:</span>

      <span class="k">for</span> <span class="k">update</span> <span class="k">in</span> <span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span><span class="o">:</span>

        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="k">update</span><span class="p">)</span><span class="o">:</span>

          <span class="k">update</span><span class="p">()</span>  <span class="c1"># pylint: disable=not-callable</span>
</code></pre></div>

</details>
<h4 id="add_variable_1">add_variable</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_variable</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use! Alias for <code>add_weight</code>.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_doc_inheritable</span>

  <span class="n">def</span> <span class="n">add_variable</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use! Alias for `add_weight`.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.add_variable` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `layer.add_weight` method instead.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">add_weight</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="add_weight_1">add_weight</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_weight</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">trainable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_resource</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">synchronization</span><span class="o">=&lt;</span><span class="n">VariableSynchronization</span><span class="o">.</span><span class="n">AUTO</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=&lt;</span><span class="n">VariableAggregation</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Adds a new variable to the layer.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>None</td>
<td>Variable name.</td>
<td>None</td>
</tr>
<tr>
<td>shape</td>
<td>None</td>
<td>Variable shape. Defaults to scalar if unspecified.</td>
<td>scalar if unspecified</td>
</tr>
<tr>
<td>dtype</td>
<td>None</td>
<td>The type of the variable. Defaults to <code>self.dtype</code>.</td>
<td><code>self.dtype</code></td>
</tr>
<tr>
<td>initializer</td>
<td>None</td>
<td>Initializer instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>regularizer</td>
<td>None</td>
<td>Regularizer instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>trainable</td>
<td>None</td>
<td>Boolean, whether the variable should be part of the layer's</td>
<td></td>
</tr>
<tr>
<td>"trainable_variables" (e.g. variables, biases)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>or "non_trainable_variables" (e.g. BatchNorm mean and variance).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Note that <code>trainable</code> cannot be <code>True</code> if <code>synchronization</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>is set to <code>ON_READ</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>constraint</td>
<td>None</td>
<td>Constraint instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>use_resource</td>
<td>None</td>
<td>Whether to use <code>ResourceVariable</code>.</td>
<td>None</td>
</tr>
<tr>
<td>synchronization</td>
<td>None</td>
<td>Indicates when a distributed a variable will be</td>
<td></td>
</tr>
<tr>
<td>aggregated. Accepted values are constants defined in the class</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.VariableSynchronization</code>. By default the synchronization is set to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>AUTO</code> and the current <code>DistributionStrategy</code> chooses</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>when to synchronize. If <code>synchronization</code> is set to <code>ON_READ</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>trainable</code> must not be set to <code>True</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>aggregation</td>
<td>None</td>
<td>Indicates how a distributed variable will be aggregated.</td>
<td></td>
</tr>
<tr>
<td>Accepted values are constants defined in the class</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.VariableAggregation</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments. Accepted values are <code>getter</code>,</td>
<td></td>
</tr>
<tr>
<td><code>collections</code>, <code>experimental_autocast</code> and <code>caching_device</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The variable created.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>When giving unsupported dtype and no initializer or when</td>
</tr>
<tr>
<td>trainable has been set to True with synchronization set as <code>ON_READ</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.for_subclass_implementers</span>

  <span class="n">def</span> <span class="n">add_weight</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                 <span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">shape</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">dtype</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">initializer</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">regularizer</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">trainable</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="k">constraint</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">use_resource</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">synchronization</span><span class="o">=</span><span class="n">tf_variables</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="p">.</span><span class="n">AUTO</span><span class="p">,</span>

                 <span class="n">aggregation</span><span class="o">=</span><span class="n">tf_variables</span><span class="p">.</span><span class="n">VariableAggregation</span><span class="p">.</span><span class="k">NONE</span><span class="p">,</span>

                 <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Adds a new variable to the layer.</span>

<span class="s2">    Arguments:</span>

<span class="s2">      name: Variable name.</span>

<span class="s2">      shape: Variable shape. Defaults to scalar if unspecified.</span>

<span class="s2">      dtype: The type of the variable. Defaults to `self.dtype`.</span>

<span class="s2">      initializer: Initializer instance (callable).</span>

<span class="s2">      regularizer: Regularizer instance (callable).</span>

<span class="s2">      trainable: Boolean, whether the variable should be part of the layer&#39;s</span>

<span class="s2">        &quot;</span><span class="n">trainable_variables</span><span class="s2">&quot; (e.g. variables, biases)</span>

<span class="s2">        or &quot;</span><span class="n">non_trainable_variables</span><span class="s2">&quot; (e.g. BatchNorm mean and variance).</span>

<span class="s2">        Note that `trainable` cannot be `True` if `synchronization`</span>

<span class="s2">        is set to `ON_READ`.</span>

<span class="s2">      constraint: Constraint instance (callable).</span>

<span class="s2">      use_resource: Whether to use `ResourceVariable`.</span>

<span class="s2">      synchronization: Indicates when a distributed a variable will be</span>

<span class="s2">        aggregated. Accepted values are constants defined in the class</span>

<span class="s2">        `tf.VariableSynchronization`. By default the synchronization is set to</span>

<span class="s2">        `AUTO` and the current `DistributionStrategy` chooses</span>

<span class="s2">        when to synchronize. If `synchronization` is set to `ON_READ`,</span>

<span class="s2">        `trainable` must not be set to `True`.</span>

<span class="s2">      aggregation: Indicates how a distributed variable will be aggregated.</span>

<span class="s2">        Accepted values are constants defined in the class</span>

<span class="s2">        `tf.VariableAggregation`.</span>

<span class="s2">      **kwargs: Additional keyword arguments. Accepted values are `getter`,</span>

<span class="s2">        `collections`, `experimental_autocast` and `caching_device`.</span>

<span class="s2">    Returns:</span>

<span class="s2">      The variable created.</span>

<span class="s2">    Raises:</span>

<span class="s2">      ValueError: When giving unsupported dtype and no initializer or when</span>

<span class="s2">        trainable has been set to True with synchronization set as `ON_READ`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">shape</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">shape</span> <span class="o">=</span> <span class="p">()</span>

    <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;partitioner&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>  <span class="c1"># Ignored.</span>

    <span class="c1"># Validate optional keyword arguments.</span>

    <span class="k">for</span> <span class="n">kwarg</span> <span class="k">in</span> <span class="n">kwargs</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">kwarg</span> <span class="k">not</span> <span class="k">in</span> <span class="err">[</span><span class="s1">&#39;collections&#39;</span><span class="p">,</span> <span class="s1">&#39;experimental_autocast&#39;</span><span class="p">,</span>

                       <span class="s1">&#39;caching_device&#39;</span><span class="p">,</span> <span class="s1">&#39;getter&#39;</span><span class="err">]</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">TypeError</span><span class="p">(</span><span class="s1">&#39;Unknown keyword argument:&#39;</span><span class="p">,</span> <span class="n">kwarg</span><span class="p">)</span>

    <span class="n">collections_arg</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;collections&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>

    <span class="c1"># &#39;experimental_autocast&#39; can be set to False by the caller to indicate an</span>

    <span class="c1"># AutoCastVariable should never be created.</span>

    <span class="n">autocast</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;experimental_autocast&#39;</span><span class="p">,</span> <span class="no">True</span><span class="p">)</span>

    <span class="c1"># See the docstring for tf.Variable about the details for caching_device.</span>

    <span class="n">caching_device</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;caching_device&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">dtype</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">dtype</span> <span class="k">or</span> <span class="n">backend</span><span class="p">.</span><span class="n">floatx</span><span class="p">()</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="p">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">variable_dtype</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="c1"># The policy is &quot;_infer&quot;, so we infer the policy from the variable dtype.</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_set_dtype_policy</span><span class="p">(</span><span class="n">policy</span><span class="p">.</span><span class="n">Policy</span><span class="p">(</span><span class="n">dtype</span><span class="p">.</span><span class="n">base_dtype</span><span class="p">.</span><span class="k">name</span><span class="p">))</span>

    <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>

    <span class="n">regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="n">regularizer</span><span class="p">)</span>

    <span class="k">constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="k">constraint</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">synchronization</span> <span class="o">==</span> <span class="n">tf_variables</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="p">.</span><span class="n">ON_READ</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">trainable</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

            <span class="s1">&#39;Synchronization value can be set to &#39;</span>

            <span class="s1">&#39;VariableSynchronization.ON_READ only for non-trainable variables. &#39;</span>

            <span class="s1">&#39;You have specified trainable=True and &#39;</span>

            <span class="s1">&#39;synchronization=VariableSynchronization.ON_READ.&#39;</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="c1"># Set trainable to be false when variable is to be synced on read.</span>

        <span class="n">trainable</span> <span class="o">=</span> <span class="no">False</span>

    <span class="n">elif</span> <span class="n">trainable</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">trainable</span> <span class="o">=</span> <span class="no">True</span>

    <span class="c1"># Initialize variable when no initializer provided</span>

    <span class="k">if</span> <span class="n">initializer</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="c1"># If dtype is DT_FLOAT, provide a uniform unit scaling initializer</span>

      <span class="k">if</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_floating</span><span class="o">:</span>

        <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">)</span>

      <span class="c1"># If dtype is DT_INT/DT_UINT, provide a default value `zero`</span>

      <span class="c1"># If dtype is DT_BOOL, provide a default value `FALSE`</span>

      <span class="n">elif</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_integer</span> <span class="k">or</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_unsigned</span> <span class="k">or</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_bool</span><span class="o">:</span>

        <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="s1">&#39;zeros&#39;</span><span class="p">)</span>

      <span class="c1"># NOTES:Do we need to support for handling DT_STRING and DT_COMPLEX here?</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;An initializer for variable %s of type %s is required&#39;</span>

                         <span class="s1">&#39; for layer %s&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="k">name</span><span class="p">,</span> <span class="n">dtype</span><span class="p">.</span><span class="n">base_dtype</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="k">name</span><span class="p">))</span>

    <span class="n">getter</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;getter&#39;</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">make_variable</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">autocast</span> <span class="k">and</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">compute_dtype</span> <span class="o">!=</span> <span class="n">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">variable_dtype</span>

        <span class="k">and</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_floating</span><span class="p">)</span><span class="o">:</span>

      <span class="n">old_getter</span> <span class="o">=</span> <span class="n">getter</span>

      <span class="c1"># Wrap variable constructor to return an AutoCastVariable.</span>

      <span class="n">def</span> <span class="n">getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>  <span class="c1"># pylint: disable=function-redefined</span>

        <span class="n">variable</span> <span class="o">=</span> <span class="n">old_getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">autocast_variable</span><span class="p">.</span><span class="n">create_autocast_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

      <span class="c1"># Also the caching_device does not work with the mixed precision API,</span>

      <span class="c1"># disable it if it is specified.</span>

      <span class="c1"># TODO(b/142020079): Reenable it once the bug is fixed.</span>

      <span class="k">if</span> <span class="n">caching_device</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

        <span class="n">tf_logging</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`caching_device` does not work with mixed precision &#39;</span>

                        <span class="s1">&#39;API. Ignoring user specified `caching_device`.&#39;</span><span class="p">)</span>

        <span class="n">caching_device</span> <span class="o">=</span> <span class="k">None</span>

    <span class="n">variable</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_add_variable_with_custom_getter</span><span class="p">(</span>

        <span class="k">name</span><span class="o">=</span><span class="k">name</span><span class="p">,</span>

        <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>

        <span class="c1"># TODO(allenl): a `make_variable` equivalent should be added as a</span>

        <span class="c1"># `Trackable` method.</span>

        <span class="n">getter</span><span class="o">=</span><span class="n">getter</span><span class="p">,</span>

        <span class="c1"># Manage errors in Layer rather than Trackable.</span>

        <span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

        <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>

        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>

        <span class="k">constraint</span><span class="o">=</span><span class="k">constraint</span><span class="p">,</span>

        <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>

        <span class="n">use_resource</span><span class="o">=</span><span class="n">use_resource</span><span class="p">,</span>

        <span class="n">collections</span><span class="o">=</span><span class="n">collections_arg</span><span class="p">,</span>

        <span class="n">synchronization</span><span class="o">=</span><span class="n">synchronization</span><span class="p">,</span>

        <span class="n">aggregation</span><span class="o">=</span><span class="n">aggregation</span><span class="p">,</span>

        <span class="n">caching_device</span><span class="o">=</span><span class="n">caching_device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">regularizer</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="c1"># TODO(fchollet): in the future, this should be handled at the</span>

      <span class="c1"># level of variable creation, and weight regularization losses</span>

      <span class="c1"># should be variable attributes.</span>

      <span class="n">name_in_scope</span> <span class="o">=</span> <span class="n">variable</span><span class="p">.</span><span class="k">name</span><span class="err">[</span><span class="o">:</span><span class="n">variable</span><span class="p">.</span><span class="k">name</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)</span><span class="err">]</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_handle_weight_regularization</span><span class="p">(</span><span class="n">name_in_scope</span><span class="p">,</span>

                                         <span class="n">variable</span><span class="p">,</span>

                                         <span class="n">regularizer</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">is_split_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span><span class="o">:</span>

      <span class="k">for</span> <span class="n">v</span> <span class="k">in</span> <span class="n">variable</span><span class="o">:</span>

        <span class="n">backend</span><span class="p">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">trainable</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="k">else</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_non_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">backend</span><span class="p">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">trainable</span><span class="o">:</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_non_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">variable</span>
</code></pre></div>

</details>
<h4 id="apply_1">apply</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">apply</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>This is an alias of <code>self.__call__</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Input tensor(s).</td>
<td>None</td>
</tr>
<tr>
<td>*args</td>
<td>None</td>
<td>additional positional arguments to be passed to <code>self.call</code>.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>additional keyword arguments to be passed to <code>self.call</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Output tensor(s).</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">apply</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Deprecated, do NOT use!</span>

<span class="ss">    This is an alias of `self.__call__`.</span>

<span class="ss">    Arguments:</span>

<span class="ss">      inputs: Input tensor(s).</span>

<span class="ss">      *args: additional positional arguments to be passed to `self.call`.</span>

<span class="ss">      **kwargs: additional keyword arguments to be passed to `self.call`.</span>

<span class="ss">    Returns:</span>

<span class="ss">      Output tensor(s).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.apply` is deprecated and &#39;</span><span class="w"></span>

<span class="w">                  </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">                  </span><span class="s1">&#39;Please use `layer.__call__` method instead.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">__call__</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="build_1">build</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_shape</span>
<span class="p">)</span>
</code></pre></div>

<p>Builds the model based on input shapes received.</p>
<p>This is to be used for subclassed models, which do not know at instantiation
time what their inputs look like.</p>
<p>This method only exists for users who want to call <code>model.build()</code> in a
standalone way (as a substitute for calling the model on real data to
build it). It will never be called by the framework (and thus it will
never throw unexpected errors in an unrelated workflow).</p>
<p>Args:
 input_shape: Single tuple, TensorShape, or list/dict of shapes, where
     shapes are tuples, integers, or TensorShapes.</p>
<p>Raises:
  ValueError:
    1. In case of invalid user-provided data (not of type tuple,
       list, TensorShape, or dict).
    2. If the model requires call arguments that are agnostic
       to the input shapes (positional or kwarg in call signature).
    3. If not all layers were properly built.
    4. If float type inputs are not supported within the layers.</p>
<p>In each of these cases, the user should build their model by calling it
  on real tensor data.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="s s-Atom">@generic_utils</span><span class="p">.</span><span class="s s-Atom">default</span>

  <span class="s s-Atom">def</span> <span class="nf">build</span><span class="p">(</span><span class="s s-Atom">self</span><span class="p">,</span> <span class="s s-Atom">input_shape</span><span class="p">)</span><span class="s s-Atom">:</span>

    <span class="s2">&quot;&quot;&quot;Builds the model based on input shapes received.</span>

<span class="s2">    This is to be used for subclassed models, which do not know at instantiation</span>

<span class="s2">    time what their inputs look like.</span>

<span class="s2">    This method only exists for users who want to call `model.build()` in a</span>

<span class="s2">    standalone way (as a substitute for calling the model on real data to</span>

<span class="s2">    build it). It will never be called by the framework (and thus it will</span>

<span class="s2">    never throw unexpected errors in an unrelated workflow).</span>

<span class="s2">    Args:</span>

<span class="s2">     input_shape: Single tuple, TensorShape, or list/dict of shapes, where</span>

<span class="s2">         shapes are tuples, integers, or TensorShapes.</span>

<span class="s2">    Raises:</span>

<span class="s2">      ValueError:</span>

<span class="s2">        1. In case of invalid user-provided data (not of type tuple,</span>

<span class="s2">           list, TensorShape, or dict).</span>

<span class="s2">        2. If the model requires call arguments that are agnostic</span>

<span class="s2">           to the input shapes (positional or kwarg in call signature).</span>

<span class="s2">        3. If not all layers were properly built.</span>

<span class="s2">        4. If float type inputs are not supported within the layers.</span>

<span class="s2">      In each of these cases, the user should build their model by calling it</span>

<span class="s2">      on real tensor data.</span>

<span class="s2">    &quot;&quot;&quot;</span>

    <span class="s s-Atom">if</span> <span class="s s-Atom">self</span><span class="p">.</span><span class="k">_</span><span class="s s-Atom">is_graph_network:</span>

      <span class="nf">super</span><span class="p">(</span><span class="nv">Model</span><span class="p">,</span> <span class="s s-Atom">self</span><span class="p">).</span><span class="nf">build</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>

      <span class="s s-Atom">return</span>

    <span class="s s-Atom">if</span> <span class="s s-Atom">input_shape</span> <span class="o">is</span> <span class="nv">None</span><span class="s s-Atom">:</span>

      <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;Input shape must be defined when calling build on a &#39;</span>

                       <span class="s s-Atom">&#39;model subclass network.&#39;</span><span class="p">)</span>

    <span class="s s-Atom">valid_types</span> <span class="o">=</span> <span class="p">(</span><span class="s s-Atom">tuple</span><span class="p">,</span> <span class="s s-Atom">list</span><span class="p">,</span> <span class="s s-Atom">tensor_shape</span><span class="p">.</span><span class="nv">TensorShape</span><span class="p">,</span> <span class="s s-Atom">dict</span><span class="p">)</span>

    <span class="s s-Atom">if</span> <span class="o">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">valid_types</span><span class="p">)</span><span class="s s-Atom">:</span>

      <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;Specified input shape is not one of the valid types. &#39;</span>

                       <span class="s s-Atom">&#39;Please specify a batch input shape of type tuple or &#39;</span>

                       <span class="s s-Atom">&#39;list of input shapes. User provided &#39;</span>

                       <span class="s s-Atom">&#39;input type: {}&#39;</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">type</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)))</span>

    <span class="s s-Atom">if</span> <span class="s s-Atom">input_shape</span> <span class="s s-Atom">and</span> <span class="o">not</span> <span class="s s-Atom">self</span><span class="p">.</span><span class="nn">inputs</span><span class="p">:</span>

      <span class="s s-Atom">#</span> <span class="nv">We</span> <span class="s s-Atom">create</span> <span class="s s-Atom">placeholders</span> <span class="s s-Atom">for</span> <span class="s s-Atom">the</span> <span class="err">`</span><span class="nv">None</span><span class="err">`</span><span class="s s-Atom">s</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">shape</span> <span class="s s-Atom">and</span> <span class="s s-Atom">build</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model</span>

      <span class="s s-Atom">#</span> <span class="s s-Atom">in</span> <span class="s s-Atom">a</span> <span class="nv">Graph</span><span class="p">.</span> <span class="nv">Since</span> <span class="s s-Atom">tf</span><span class="p">.</span><span class="nv">Variable</span> <span class="o">is</span> <span class="s s-Atom">compatible</span> <span class="s s-Atom">with</span> <span class="s s-Atom">both</span> <span class="s s-Atom">eager</span> <span class="s s-Atom">execution</span>

      <span class="s s-Atom">#</span> <span class="s s-Atom">and</span> <span class="s s-Atom">graph</span> <span class="s s-Atom">building</span><span class="p">,</span> <span class="s s-Atom">the</span> <span class="s s-Atom">variables</span> <span class="s s-Atom">created</span> <span class="s s-Atom">after</span> <span class="s s-Atom">building</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model</span> <span class="s s-Atom">in</span>

      <span class="s s-Atom">#</span> <span class="s s-Atom">a</span> <span class="nv">Graph</span> <span class="s s-Atom">are</span> <span class="s s-Atom">still</span> <span class="s s-Atom">valid</span> <span class="s s-Atom">when</span> <span class="s s-Atom">executing</span> <span class="s s-Atom">eagerly</span><span class="p">.</span>

      <span class="s s-Atom">if</span> <span class="s s-Atom">context</span><span class="p">.</span><span class="nf">executing_eagerly</span><span class="p">()</span><span class="s s-Atom">:</span>

        <span class="s s-Atom">graph</span> <span class="o">=</span> <span class="s s-Atom">func_graph</span><span class="p">.</span><span class="nv">FuncGraph</span><span class="p">(</span><span class="s s-Atom">&#39;build_graph&#39;</span><span class="p">)</span>

      <span class="nn">else</span><span class="p">:</span>

        <span class="s s-Atom">graph</span> <span class="o">=</span> <span class="s s-Atom">backend</span><span class="p">.</span><span class="nf">get_graph</span><span class="p">()</span>

      <span class="s s-Atom">with</span> <span class="s s-Atom">graph</span><span class="p">.</span><span class="nf">as_default</span><span class="p">()</span><span class="s s-Atom">:</span>

        <span class="nf">if</span> <span class="p">(</span><span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">list</span><span class="p">)</span> <span class="s s-Atom">and</span>

            <span class="nf">all</span><span class="p">(</span><span class="s s-Atom">d</span> <span class="o">is</span> <span class="nv">None</span> <span class="s s-Atom">or</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">d</span><span class="p">,</span> <span class="s s-Atom">int</span><span class="p">)</span> <span class="s s-Atom">for</span> <span class="s s-Atom">d</span> <span class="s s-Atom">in</span> <span class="s s-Atom">input_shape</span><span class="p">))</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">input_shape</span> <span class="o">=</span> <span class="nf">tuple</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>

        <span class="s s-Atom">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">list</span><span class="p">)</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">x</span> <span class="o">=</span> <span class="p">[</span><span class="s s-Atom">base_layer_utils</span><span class="p">.</span><span class="nf">generate_placeholders_from_shape</span><span class="p">(</span><span class="s s-Atom">shape</span><span class="p">)</span>

               <span class="s s-Atom">for</span> <span class="s s-Atom">shape</span> <span class="s s-Atom">in</span> <span class="s s-Atom">input_shape</span><span class="p">]</span>

        <span class="s s-Atom">elif</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">dict</span><span class="p">)</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">x</span> <span class="o">=</span> <span class="p">{</span>

              <span class="nn">k</span><span class="p">:</span> <span class="s s-Atom">base_layer_utils</span><span class="p">.</span><span class="nf">generate_placeholders_from_shape</span><span class="p">(</span><span class="s s-Atom">shape</span><span class="p">)</span>

              <span class="s s-Atom">for</span> <span class="s s-Atom">k</span><span class="p">,</span> <span class="s s-Atom">shape</span> <span class="s s-Atom">in</span> <span class="s s-Atom">input_shape</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span>

          <span class="p">}</span>

        <span class="nn">else</span><span class="p">:</span>

          <span class="s s-Atom">x</span> <span class="o">=</span> <span class="s s-Atom">base_layer_utils</span><span class="p">.</span><span class="nf">generate_placeholders_from_shape</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>

        <span class="s s-Atom">kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="s s-Atom">call_signature</span> <span class="o">=</span> <span class="s s-Atom">self</span><span class="p">.</span><span class="k">_</span><span class="s s-Atom">call_full_argspec</span>

        <span class="s s-Atom">call_args</span> <span class="o">=</span> <span class="s s-Atom">call_signature</span><span class="p">.</span><span class="s s-Atom">args</span>

        <span class="s s-Atom">#</span> <span class="nv">Exclude</span> <span class="err">`</span><span class="s s-Atom">self</span><span class="err">`</span><span class="p">,</span> <span class="err">`</span><span class="s s-Atom">inputs</span><span class="err">`</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">any</span> <span class="s s-Atom">argument</span> <span class="s s-Atom">with</span> <span class="s s-Atom">a</span> <span class="s s-Atom">default</span> <span class="s s-Atom">value</span><span class="p">.</span>

        <span class="s s-Atom">if</span> <span class="nf">len</span><span class="p">(</span><span class="s s-Atom">call_args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">if</span> <span class="s s-Atom">call_signature</span><span class="p">.</span><span class="nn">defaults</span><span class="p">:</span>

            <span class="s s-Atom">call_args</span> <span class="o">=</span> <span class="s s-Atom">call_args</span><span class="p">[</span><span class="mi">2</span><span class="p">:-</span><span class="nf">len</span><span class="p">(</span><span class="s s-Atom">call_signature</span><span class="p">.</span><span class="s s-Atom">defaults</span><span class="p">)]</span>

          <span class="nn">else</span><span class="p">:</span>

            <span class="s s-Atom">call_args</span> <span class="o">=</span> <span class="s s-Atom">call_args</span><span class="p">[</span><span class="mi">2</span><span class="s s-Atom">:</span><span class="p">]</span>

          <span class="s s-Atom">for</span> <span class="s s-Atom">arg</span> <span class="s s-Atom">in</span> <span class="s s-Atom">call_args:</span>

            <span class="s s-Atom">if</span> <span class="s s-Atom">arg</span> <span class="o">==</span> <span class="s s-Atom">&#39;training&#39;:</span>

              <span class="s s-Atom">#</span> <span class="nv">Case</span> <span class="s s-Atom">where</span> <span class="err">`</span><span class="s s-Atom">training</span><span class="err">`</span> <span class="o">is</span> <span class="s s-Atom">a</span> <span class="s s-Atom">positional</span> <span class="s s-Atom">arg</span> <span class="s s-Atom">with</span> <span class="s s-Atom">no</span> <span class="s s-Atom">default</span><span class="p">.</span>

              <span class="s s-Atom">kwargs</span><span class="p">[</span><span class="s s-Atom">&#39;training&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nv">False</span>

            <span class="nn">else</span><span class="p">:</span>

              <span class="s s-Atom">#</span> <span class="nv">Has</span> <span class="s s-Atom">invalid</span> <span class="s s-Atom">call</span> <span class="s s-Atom">signature</span> <span class="s s-Atom">with</span> <span class="s s-Atom">unknown</span> <span class="s s-Atom">positional</span> <span class="s s-Atom">arguments</span><span class="p">.</span>

              <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span>

                  <span class="s s-Atom">&#39;Currently, you cannot build your model if it has &#39;</span>

                  <span class="s s-Atom">&#39;positional or keyword arguments that are not &#39;</span>

                  <span class="s s-Atom">&#39;inputs to the model, but are required for its &#39;</span>

                  <span class="s s-Atom">&#39;`call` method. Instead, in order to instantiate &#39;</span>

                  <span class="s s-Atom">&#39;and build your model, `call` your model on real &#39;</span>

                  <span class="s s-Atom">&#39;tensor data with all expected call arguments.&#39;</span><span class="p">)</span>

        <span class="s s-Atom">elif</span> <span class="nf">len</span><span class="p">(</span><span class="s s-Atom">call_args</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">#</span> <span class="nv">Signature</span> <span class="s s-Atom">without</span> <span class="err">`</span><span class="s s-Atom">inputs</span><span class="err">`</span><span class="p">.</span>

          <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;You can only call `build` on a model if its `call` &#39;</span>

                           <span class="s s-Atom">&#39;method accepts an `inputs` argument.&#39;</span><span class="p">)</span>

        <span class="nn">try</span><span class="p">:</span>

          <span class="s s-Atom">self</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="s s-Atom">x</span><span class="p">,</span> <span class="s s-Atom">**kwargs</span><span class="p">)</span>

        <span class="nf">except</span> <span class="p">(</span><span class="s s-Atom">errors</span><span class="p">.</span><span class="nv">InvalidArgumentError</span><span class="p">,</span> <span class="nv">TypeError</span><span class="p">)</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;You cannot build your model by calling `build` &#39;</span>

                           <span class="s s-Atom">&#39;if your layers do not support float type inputs. &#39;</span>

                           <span class="s s-Atom">&#39;Instead, in order to instantiate and build your &#39;</span>

                           <span class="s s-Atom">&#39;model, `call` your model on real tensor data (of &#39;</span>

                           <span class="s s-Atom">&#39;the correct dtype).&#39;</span><span class="p">)</span>

    <span class="nf">super</span><span class="p">(</span><span class="nv">Model</span><span class="p">,</span> <span class="s s-Atom">self</span><span class="p">).</span><span class="nf">build</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="call_1">call</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">training</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference in training.</p>
<p>Arguments:</p>
<ul>
<li>
<p><em>inputs</em>: Tuple</p>
<ol>
<li>images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</li>
<li>image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape
of the image without any padding.</li>
<li>images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None] composed of 0 and 1 which allows to know where a padding has been applied.</li>
</ol>
</li>
<li>
<p><em>training</em>: Is automatically set to <code>True</code> in train mode</p>
</li>
</ul>
<p>Returns:</p>
<ul>
<li><em>logits</em>: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</li>
<li><em>boxes</em>: A Tensor of shape [batch_size, num_queries, 4]</li>
</ul>
<p>where h is num_queries * transformer_decoder.transformer_num_layers if
training is true and num_queries otherwise.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Perform an inference in training.</span>

<span class="s2">        Arguments:</span>

<span class="s2">        - *inputs*: Tuple</span>

<span class="s2">            1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</span>

<span class="s2">            2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape</span>

<span class="s2">            of the image without any padding.</span>

<span class="s2">            3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None] composed of 0 and 1 which allows to know where a padding has been applied.</span>

<span class="s2">        - *training*: Is automatically set to `True` in train mode</span>

<span class="s2">        Returns:</span>

<span class="s2">        - *logits*: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="s2">        - *boxes*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="s2">        where h is num_queries * transformer_decoder.transformer_num_layers if</span>

<span class="s2">        training is true and num_queries otherwise.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="n">images</span> <span class="o">=</span> <span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="err">]</span>

        <span class="n">images_padding_masks</span> <span class="o">=</span> <span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES_PMASK</span><span class="err">]</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

        <span class="c1"># The preprocessing dedicated to the backbone is done inside the model.</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="o">-</span><span class="mi">1</span><span class="err">]</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">images_padding_masks</span><span class="err">[</span><span class="p">...,</span> <span class="k">None</span><span class="err">]</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span>

                                        <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="err">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">3</span><span class="err">]</span><span class="p">,</span>

                                        <span class="n">method</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">ResizeMethod</span><span class="p">.</span><span class="n">NEAREST_NEIGHBOR</span><span class="p">)</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="kt">bool</span><span class="p">)</span>

        <span class="c1"># Positional_encoding for the backbone</span>

        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">pos_embed</span><span class="p">(</span><span class="n">features_mask</span><span class="p">)</span>

        <span class="c1"># [batch_size, num_queries, self.hidden_dim]</span>

        <span class="n">all_the_queries</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">all_the_queries</span><span class="err">[</span><span class="k">None</span><span class="err">]</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># [batch_size, num_queries, self.hidden_dim]</span>

        <span class="n">query_embed</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">query_embed</span><span class="p">(</span><span class="n">all_the_queries</span><span class="p">)</span>

        <span class="c1"># add positional_encoding to x [batch_size, h, w, self.hidden_dim]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">input_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Flatten the position embedding and the spatial tensor</span>

        <span class="c1"># to allow the preprocessing by the Transformer</span>

        <span class="c1"># [batch_size, h * w,  self.hidden_dim]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="c1"># Flatten the padding masks</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">decoder_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>

                                          <span class="n">pos_embed</span><span class="p">,</span>

                                          <span class="n">query_embed</span><span class="p">,</span>

                                          <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">features_mask</span><span class="p">,</span>

                                          <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="n">boxes</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">bbox_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">class_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span>

        <span class="k">return</span> <span class="err">{</span>

            <span class="n">BoxField</span><span class="p">.</span><span class="n">SCORES</span><span class="o">:</span> <span class="n">logits</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="p">.</span><span class="n">BOXES</span><span class="o">:</span> <span class="n">boxes</span><span class="p">,</span>

        <span class="err">}</span>
</code></pre></div>

</details>
<h4 id="compile_1">compile</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Configures the model for training.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>optimizer</td>
<td>None</td>
<td>String (name of optimizer) or optimizer instance. See</td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.optimizers</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>loss</td>
<td>None</td>
<td>String (name of objective function), objective function or</td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.losses.Loss</code> instance. See <code>tf.keras.losses</code>. An objective</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function is any callable with the signature `loss = fn(y_true,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>y_pred)`, where y_true = ground truth values with shape =</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>[batch_size, d0, .. dN]</code>, except sparse loss functions such as sparse</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>categorical crossentropy where shape = <code>[batch_size, d0, .. dN-1]</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>y_pred = predicted values with shape = <code>[batch_size, d0, .. dN]</code>. It</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returns a weighted loss float tensor. If a custom <code>Loss</code> instance is</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>used and reduction is set to NONE, return value has the shape</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>[batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>otherwise, it is a scalar. If the model has multiple outputs, you can</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>use a different loss on each output by passing a dictionary or a list</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of losses. The loss value that will be minimized by the model will</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>then be the sum of all individual losses.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>metrics</td>
<td>None</td>
<td>List of metrics to be evaluated by the model during training</td>
<td></td>
</tr>
<tr>
<td>and testing. Each of this can be a string (name of a built-in</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function), function or a <code>tf.keras.metrics.Metric</code> instance. See</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics</code>. Typically you will use <code>metrics=['accuracy']</code>. A</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function is any callable with the signature `result = fn(y_true,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>y_pred)`. To specify different metrics for different outputs of a</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>multi-output model, you could also pass a dictionary, such as</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>You can also pass a list (len = len(outputs)) of lists of metrics</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>such as <code>metrics=[['accuracy'], ['accuracy', 'mse']]</code> or</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>metrics=['accuracy', ['accuracy', 'mse']]</code>. When you pass the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>strings 'accuracy' or 'acc', we convert this to one of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics.BinaryAccuracy</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics.CategoricalAccuracy</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics.SparseCategoricalAccuracy</code> based on the loss</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function used and the model output shape. We do a similar</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>conversion for the strings 'crossentropy' and 'ce' as well.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>loss_weights</td>
<td>None</td>
<td>Optional list or dictionary specifying scalar coefficients</td>
<td></td>
</tr>
<tr>
<td>(Python floats) to weight the loss contributions of different model</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>outputs. The loss value that will be minimized by the model will then</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>be the <em>weighted sum</em> of all individual losses, weighted by the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>loss_weights</code> coefficients.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>If a list, it is expected to have a 1:1 mapping to the model's</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>outputs. If a dict, it is expected to map output names (strings)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>to scalar coefficients.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>weighted_metrics</td>
<td>None</td>
<td>List of metrics to be evaluated and weighted by</td>
<td></td>
</tr>
<tr>
<td>sample_weight or class_weight during training and testing.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>run_eagerly</td>
<td>None</td>
<td>Bool. Defaults to <code>False</code>. If <code>True</code>, this <code>Model</code>'s</td>
<td></td>
</tr>
<tr>
<td>logic will not be wrapped in a <code>tf.function</code>. Recommended to leave</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>this as <code>None</code> unless your <code>Model</code> cannot be run inside a</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.function</code>.</td>
<td><code>False</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td>steps_per_execution</td>
<td>None</td>
<td>Int. Defaults to 1. The number of batches to</td>
<td></td>
</tr>
<tr>
<td>run during each <code>tf.function</code> call. Running multiple batches</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>inside a single <code>tf.function</code> call can greatly improve performance</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>on TPUs or small models with a large Python overhead.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>At most, one full epoch will be run each</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>execution. If a number larger than the size of the epoch is passed,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the execution will be truncated to the size of the epoch.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Note that if <code>steps_per_execution</code> is set to <code>N</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>Callback.on_batch_begin</code> and <code>Callback.on_batch_end</code> methods</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>will only be called every <code>N</code> batches</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(i.e. before/after each <code>tf.function</code> execution).</td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Arguments supported for backwards compatibility only.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>In case of invalid arguments for</td>
</tr>
<tr>
<td><code>optimizer</code>, <code>loss</code> or <code>metrics</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">compile</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

              <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>

              <span class="n">loss</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">metrics</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">loss_weights</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">weighted_metrics</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">run_eagerly</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">steps_per_execution</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Configures the model for training.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        optimizer: String (name of optimizer) or optimizer instance. See</span>

<span class="s2">          `tf.keras.optimizers`.</span>

<span class="s2">        loss: String (name of objective function), objective function or</span>

<span class="s2">          `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective</span>

<span class="s2">          function is any callable with the signature `loss = fn(y_true,</span>

<span class="s2">          y_pred)`, where y_true = ground truth values with shape =</span>

<span class="s2">          `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse</span>

<span class="s2">          categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.</span>

<span class="s2">          y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It</span>

<span class="s2">          returns a weighted loss float tensor. If a custom `Loss` instance is</span>

<span class="s2">          used and reduction is set to NONE, return value has the shape</span>

<span class="s2">          [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;</span>

<span class="s2">          otherwise, it is a scalar. If the model has multiple outputs, you can</span>

<span class="s2">          use a different loss on each output by passing a dictionary or a list</span>

<span class="s2">          of losses. The loss value that will be minimized by the model will</span>

<span class="s2">          then be the sum of all individual losses.</span>

<span class="s2">        metrics: List of metrics to be evaluated by the model during training</span>

<span class="s2">          and testing. Each of this can be a string (name of a built-in</span>

<span class="s2">          function), function or a `tf.keras.metrics.Metric` instance. See</span>

<span class="s2">          `tf.keras.metrics`. Typically you will use `metrics=[&#39;accuracy&#39;]`. A</span>

<span class="s2">          function is any callable with the signature `result = fn(y_true,</span>

<span class="s2">          y_pred)`. To specify different metrics for different outputs of a</span>

<span class="s2">          multi-output model, you could also pass a dictionary, such as</span>

<span class="s2">            `metrics={&#39;output_a&#39;: &#39;accuracy&#39;, &#39;output_b&#39;: [&#39;accuracy&#39;, &#39;mse&#39;]}`.</span>

<span class="s2">              You can also pass a list (len = len(outputs)) of lists of metrics</span>

<span class="s2">              such as `metrics=[[&#39;accuracy&#39;], [&#39;accuracy&#39;, &#39;mse&#39;]]` or</span>

<span class="s2">              `metrics=[&#39;accuracy&#39;, [&#39;accuracy&#39;, &#39;mse&#39;]]`. When you pass the</span>

<span class="s2">              strings &#39;accuracy&#39; or &#39;acc&#39;, we convert this to one of</span>

<span class="s2">              `tf.keras.metrics.BinaryAccuracy`,</span>

<span class="s2">              `tf.keras.metrics.CategoricalAccuracy`,</span>

<span class="s2">              `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss</span>

<span class="s2">              function used and the model output shape. We do a similar</span>

<span class="s2">              conversion for the strings &#39;crossentropy&#39; and &#39;ce&#39; as well.</span>

<span class="s2">        loss_weights: Optional list or dictionary specifying scalar coefficients</span>

<span class="s2">          (Python floats) to weight the loss contributions of different model</span>

<span class="s2">          outputs. The loss value that will be minimized by the model will then</span>

<span class="s2">          be the *weighted sum* of all individual losses, weighted by the</span>

<span class="s2">          `loss_weights` coefficients.</span>

<span class="s2">            If a list, it is expected to have a 1:1 mapping to the model&#39;s</span>

<span class="s2">              outputs. If a dict, it is expected to map output names (strings)</span>

<span class="s2">              to scalar coefficients.</span>

<span class="s2">        weighted_metrics: List of metrics to be evaluated and weighted by</span>

<span class="s2">          sample_weight or class_weight during training and testing.</span>

<span class="s2">        run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`&#39;s</span>

<span class="s2">          logic will not be wrapped in a `tf.function`. Recommended to leave</span>

<span class="s2">          this as `None` unless your `Model` cannot be run inside a</span>

<span class="s2">          `tf.function`.</span>

<span class="s2">        steps_per_execution: Int. Defaults to 1. The number of batches to</span>

<span class="s2">          run during each `tf.function` call. Running multiple batches</span>

<span class="s2">          inside a single `tf.function` call can greatly improve performance</span>

<span class="s2">          on TPUs or small models with a large Python overhead.</span>

<span class="s2">          At most, one full epoch will be run each</span>

<span class="s2">          execution. If a number larger than the size of the epoch is passed,</span>

<span class="s2">          the execution will be truncated to the size of the epoch.</span>

<span class="s2">          Note that if `steps_per_execution` is set to `N`,</span>

<span class="s2">          `Callback.on_batch_begin` and `Callback.on_batch_end` methods</span>

<span class="s2">          will only be called every `N` batches</span>

<span class="s2">          (i.e. before/after each `tf.function` execution).</span>

<span class="s2">        **kwargs: Arguments supported for backwards compatibility only.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: In case of invalid arguments for</span>

<span class="s2">            `optimizer`, `loss` or `metrics`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;compile&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="k">if</span> <span class="s1">&#39;experimental_steps_per_execution&#39;</span> <span class="k">in</span> <span class="n">kwargs</span><span class="o">:</span>

        <span class="n">logging</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;The argument `steps_per_execution` is no longer &#39;</span>

                     <span class="s1">&#39;experimental. Pass `steps_per_execution` instead of &#39;</span>

                     <span class="s1">&#39;`experimental_steps_per_execution`.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="k">not</span> <span class="n">steps_per_execution</span><span class="o">:</span>

          <span class="n">steps_per_execution</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;experimental_steps_per_execution&#39;</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_validate_compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_run_eagerly</span> <span class="o">=</span> <span class="n">run_eagerly</span>

      <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span> <span class="o">=</span> <span class="n">compile_utils</span><span class="p">.</span><span class="n">LossesContainer</span><span class="p">(</span>

          <span class="n">loss</span><span class="p">,</span> <span class="n">loss_weights</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">compiled_metrics</span> <span class="o">=</span> <span class="n">compile_utils</span><span class="p">.</span><span class="n">MetricsContainer</span><span class="p">(</span>

          <span class="n">metrics</span><span class="p">,</span> <span class="n">weighted_metrics</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_configure_steps_per_execution</span><span class="p">(</span><span class="n">steps_per_execution</span> <span class="k">or</span> <span class="mi">1</span><span class="p">)</span>

      <span class="c1"># Initializes attrs that are reset each time `compile` is called.</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_reset_compile_cache</span><span class="p">()</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_is_compiled</span> <span class="o">=</span> <span class="no">True</span>

      <span class="n">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="k">or</span> <span class="err">{}</span>  <span class="c1"># Backwards compat.</span>
</code></pre></div>

</details>
<h4 id="compute_loss_1">compute_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">ground_truths</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</code></pre></div>

<p>Apply the GIoU, L1 and SCC to each layers of the transformer decoder</p>
<p>Arguments:</p>
<ul>
<li><em>ground_truths</em>:
   see output kerod.dataset.preprocessing for the doc</li>
<li><em>y_pred</em>: A dict<ul>
<li>*scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</li>
<li><em>bbox</em>: A Tensor of shape [batch_size, num_queries, 4]</li>
</ul>
</li>
<li><em>input_shape</em>: [height, width] of the input tensor. It is the shape of the images will all the
padding included. It is used to normalize the ground_truths boxes.</li>
</ul>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_loss</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">ground_truths</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">input_shape</span><span class="p">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span><span class="w"></span>

<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nc">int</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Apply the GIoU, L1 and SCC to each layers of the transformer decoder</span>

<span class="ss">        Arguments:</span>

<span class="ss">        - *ground_truths*:</span>

<span class="ss">           see output kerod.dataset.preprocessing for the doc</span>

<span class="ss">        - *y_pred*: A dict</span>

<span class="ss">            - *scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="ss">            - *bbox*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="ss">        - *input_shape*: [height, width] of the input tensor. It is the shape of the images will all the</span>

<span class="ss">        padding included. It is used to normalize the ground_truths boxes.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">input_shape</span><span class="o">[</span><span class="n">None</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">1, 2</span><span class="o">]</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">centered_normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">convert_to_center_coordinates</span><span class="p">(</span><span class="n">normalized_boxes</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">add</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">because</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">background</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">counted</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">LABELS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">centered_normalized_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">WEIGHTS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.WEIGHTS</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">NUM_BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="err">}</span><span class="w"></span>

<span class="w">        </span><span class="n">boxes_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">logits_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.SCORES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">y_pred_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">{</span>

<span class="n">            BoxField.BOXES: boxes,</span>

<span class="n">            BoxField.SCORES: logits</span>

<span class="n">        } for boxes, logits in zip(boxes_per_lvl, logits_per_lvl)</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="n">num_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="p">),</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="k">Compute</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Giou</span><span class="p">,</span><span class="w"> </span><span class="n">L1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">SCC</span><span class="w"> </span><span class="k">at</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">layers</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">transformer</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">enumerate</span><span class="p">(</span><span class="n">y_pred_per_lvl</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">Logs</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">            </span><span class="n">compute_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">num_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_mask_1">compute_mask</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_mask</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Computes an output mask tensor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Tensor or list of tensors.</td>
<td>None</td>
</tr>
<tr>
<td>mask</td>
<td>None</td>
<td>Tensor or list of tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>None or a tensor (or list of tensors,</td>
</tr>
<tr>
<td>one per output tensor of the layer).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@generic_utils</span><span class="p">.</span><span class="k">default</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">compute_mask</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">mask</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="err">:</span><span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="nl">pylint</span><span class="p">:</span><span class="w"> </span><span class="n">disable</span><span class="o">=</span><span class="n">unused</span><span class="o">-</span><span class="n">argument</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Computes an output mask tensor.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        inputs: Tensor or list of tensors.</span>

<span class="ss">        mask: Tensor or list of tensors.</span>

<span class="ss">    Returns:</span>

<span class="ss">        None or a tensor (or list of tensors,</span>

<span class="ss">            one per output tensor of the layer).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">_supports_masking</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">any</span><span class="p">(</span><span class="n">m</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">name</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s1">&#39; does not support masking, &#39;</span><span class="w"></span>

<span class="w">                        </span><span class="s1">&#39;but was passed an input_mask: &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">str</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span><span class="w"></span>

<span class="w">      </span><span class="err">#</span><span class="w"> </span><span class="n">masking</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="nl">supported</span><span class="p">:</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">mask</span><span class="p">.</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">masking</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="n">supported</span><span class="p">,</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="k">default</span><span class="w"></span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="n">carry</span><span class="w"> </span><span class="k">over</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">input</span><span class="w"> </span><span class="n">mask</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">mask</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_output_shape_1">compute_output_shape</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_shape</span>
<span class="p">)</span>
</code></pre></div>

<p>Computes the output shape of the layer.</p>
<p>If the layer has not been built, this method will call <code>build</code> on the
layer. This assumes that the layer will later be used with inputs that
match the input shape provided here.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_shape</td>
<td>None</td>
<td>Shape tuple (tuple of integers)</td>
<td></td>
</tr>
<tr>
<td>or list of shape tuples (one per output tensor of the layer).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Shape tuples can include None for free dimensions,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>instead of an integer.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>An input shape tuple.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">compute_output_shape</span>(<span class="nb">self</span>, <span class="n">input_shape</span>):

    <span class="s">&quot;&quot;&quot;Computes the output shape of the layer.</span>

<span class="s">    If the layer has not been built, this method will call `build` on the</span>

<span class="s">    layer. This assumes that the layer will later be used with inputs that</span>

<span class="s">    match the input shape provided here.</span>

<span class="s">    Arguments:</span>

<span class="s">        input_shape: Shape tuple (tuple of integers)</span>

<span class="s">            or list of shape tuples (one per output tensor of the layer).</span>

<span class="s">            Shape tuples can include None for free dimensions,</span>

<span class="s">            instead of an integer.</span>

<span class="s">    Returns:</span>

<span class="s">        An input shape tuple.</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">context</span>.<span class="n">executing_eagerly</span>():

      <span class="c1"># In this case we build the model first in order to do shape inference.</span>

      <span class="c1"># This is acceptable because the framework only calls</span>

      <span class="c1"># `compute_output_shape` on shape values that the layer would later be</span>

      <span class="c1"># built for. It would however cause issues in case a user attempts to</span>

      <span class="c1"># use `compute_output_shape` manually with shapes that are incompatible</span>

      <span class="c1"># with the shape the Layer will be called on (these users will have to</span>

      <span class="c1"># implement `compute_output_shape` themselves).</span>

      <span class="nb">self</span>.<span class="n">_maybe_build</span>(<span class="n">input_shape</span>)

      <span class="k">with</span> <span class="n">func_graph</span>.<span class="n">FuncGraph</span>(<span class="n">str</span>(<span class="nb">self</span>.<span class="nb">name</span>) + <span class="s">&#39;_scratch_graph&#39;</span>).<span class="n">as_default</span>():

        <span class="n">input_shape</span> = <span class="n">tf_utils</span>.<span class="n">convert_shapes</span>(<span class="n">input_shape</span>, <span class="n">to_tuples</span>=<span class="nb">False</span>)

        <span class="n">def</span> <span class="n">_make_placeholder_like</span>(<span class="nb">shape</span>):

          <span class="n">ph</span> = <span class="n">backend</span>.<span class="nb">placeholder</span>(<span class="nb">shape</span>=<span class="nb">shape</span>, <span class="n">dtype</span>=<span class="nb">self</span>.<span class="n">dtype</span>)

          <span class="n">ph</span>.<span class="n">_keras_mask</span> = <span class="n">None</span>

          <span class="k">return</span> <span class="n">ph</span>

        <span class="n">inputs</span> = <span class="n">nest</span>.<span class="n">map_structure</span>(<span class="n">_make_placeholder_like</span>, <span class="n">input_shape</span>)

        <span class="n">try:</span>

          <span class="n">outputs</span> = <span class="nb">self</span>(<span class="n">inputs</span>, <span class="n">training</span>=<span class="nb">False</span>)

        <span class="n">except</span> <span class="n">TypeError</span> <span class="n">as</span> <span class="n">e:</span>

          <span class="n">six</span>.<span class="n">raise_from</span>(

              <span class="n">NotImplementedError</span>(

                  <span class="s">&#39;We could not automatically infer the static shape of the &#39;</span>

                  <span class="s">&#39;layer\&#39;s output. Please implement the &#39;</span>

                  <span class="s">&#39;`compute_output_shape` method on your layer (%s).&#39;</span> %

                  <span class="nb">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>), <span class="nb">e</span>)

      <span class="k">return</span> <span class="n">nest</span>.<span class="n">map_structure</span>(<span class="n">lambda</span> <span class="n">t:</span> <span class="nb">t</span>.<span class="nb">shape</span>, <span class="n">outputs</span>)

    <span class="n">raise</span> <span class="n">NotImplementedError</span>(

        <span class="s">&#39;Please run in eager mode or implement the `compute_output_shape` &#39;</span>

        <span class="s">&#39;method on your layer (%s).&#39;</span> % <span class="nb">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>)
</code></pre></div>

</details>
<h4 id="compute_output_signature_1">compute_output_signature</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_output_signature</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_signature</span>
<span class="p">)</span>
</code></pre></div>

<p>Compute the output tensor signature of the layer based on the inputs.</p>
<p>Unlike a TensorShape object, a TensorSpec object contains both shape
and dtype information for a tensor. This method allows layers to provide
output dtype information if it is different from the input dtype.
For any layer that doesn't implement this function,
the framework will fall back to use <code>compute_output_shape</code>, and will
assume that the output dtype matches the input dtype.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_signature</td>
<td>None</td>
<td>Single TensorSpec or nested structure of TensorSpec</td>
<td></td>
</tr>
<tr>
<td>objects, describing a candidate input for the layer.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Single TensorSpec or nested structure of TensorSpec objects, describing</td>
</tr>
<tr>
<td>how the layer would transform the provided input.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>TypeError</td>
<td>If input_signature contains a non-TensorSpec object.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.for_subclass_implementers</span>

  <span class="n">def</span> <span class="n">compute_output_signature</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_signature</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Compute the output tensor signature of the layer based on the inputs.</span>

<span class="s2">    Unlike a TensorShape object, a TensorSpec object contains both shape</span>

<span class="s2">    and dtype information for a tensor. This method allows layers to provide</span>

<span class="s2">    output dtype information if it is different from the input dtype.</span>

<span class="s2">    For any layer that doesn&#39;t implement this function,</span>

<span class="s2">    the framework will fall back to use `compute_output_shape`, and will</span>

<span class="s2">    assume that the output dtype matches the input dtype.</span>

<span class="s2">    Args:</span>

<span class="s2">      input_signature: Single TensorSpec or nested structure of TensorSpec</span>

<span class="s2">        objects, describing a candidate input for the layer.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Single TensorSpec or nested structure of TensorSpec objects, describing</span>

<span class="s2">        how the layer would transform the provided input.</span>

<span class="s2">    Raises:</span>

<span class="s2">      TypeError: If input_signature contains a non-TensorSpec object.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">def</span> <span class="n">check_type_return_shape</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">:</span>

      <span class="k">if</span> <span class="k">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tensor_spec</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">)</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">TypeError</span><span class="p">(</span>

            <span class="s1">&#39;Only TensorSpec signature types are supported, &#39;</span>

            <span class="s1">&#39;but saw signature signature entry: {}.&#39;</span><span class="p">.</span><span class="k">format</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

      <span class="k">return</span> <span class="n">s</span><span class="p">.</span><span class="n">shape</span>

    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">check_type_return_shape</span><span class="p">,</span> <span class="n">input_signature</span><span class="p">)</span>

    <span class="n">output_shape</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_compute_dtype</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">input_dtypes</span> <span class="o">=</span> <span class="err">[</span><span class="n">s</span><span class="p">.</span><span class="n">dtype</span> <span class="k">for</span> <span class="n">s</span> <span class="k">in</span> <span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">input_signature</span><span class="p">)</span><span class="err">]</span>

      <span class="c1"># Default behavior when self.dtype is None, is to use the first input&#39;s</span>

      <span class="c1"># dtype.</span>

      <span class="n">dtype</span> <span class="o">=</span> <span class="n">input_dtypes</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

    <span class="k">return</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

        <span class="n">lambda</span> <span class="n">s</span><span class="o">:</span> <span class="n">tensor_spec</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">s</span><span class="p">),</span>

        <span class="n">output_shape</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="count_params_1">count_params</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">count_params</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Count the total number of scalars composing the weights.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>An integer count.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if the layer isn't yet built</td>
</tr>
<tr>
<td>(in which case its weights aren't yet defined).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">count_params</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Count the total number of scalars composing the weights.</span>

<span class="s2">    Returns:</span>

<span class="s2">        An integer count.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: if the layer isn&#39;t yet built</span>

<span class="s2">          (in which case its weights aren&#39;t yet defined).</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_is_graph_network&#39;</span><span class="p">,</span> <span class="no">False</span><span class="p">)</span><span class="o">:</span>

        <span class="k">with</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">maybe_init_scope</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_maybe_build</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">inputs</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;You tried to call `count_params` on &#39;</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="k">name</span> <span class="o">+</span>

                         <span class="s1">&#39;, but the layer isn</span><span class="se">\&#39;</span><span class="s1">t built. &#39;</span>

                         <span class="s1">&#39;You can build it manually via: `&#39;</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="k">name</span> <span class="o">+</span>

                         <span class="s1">&#39;.build(batch_input_shape)`.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">layer_utils</span><span class="p">.</span><span class="n">count_params</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="evaluate_1">evaluate</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Computation is done in batches (see the <code>batch_size</code> arg.)</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:</td>
<td></td>
</tr>
<tr>
<td>- A Numpy array (or array-like), or a list of arrays</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A TensorFlow tensor, or a list of tensors</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A dict mapping input names to the corresponding array/tensors,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>if the model has named inputs.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A <code>tf.data</code> dataset. Should return a tuple</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of either <code>(inputs, targets)</code> or</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>(inputs, targets, sample_weights)</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>or <code>(inputs, targets, sample_weights)</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>A more detailed description of unpacking behavior for iterator types</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(Dataset, generator, Sequence) is given in the `Unpacking behavior</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>for iterator-like inputs<code>section of</code>Model.fit`.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy</td>
<td></td>
</tr>
<tr>
<td>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(you cannot have Numpy inputs and tensor targets, or inversely). If</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>x</code> is a dataset, generator or <code>keras.utils.Sequence</code> instance, <code>y</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>should not be specified (since targets will be obtained from the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>iterator/dataset).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Integer or <code>None</code>. Number of samples per batch of</td>
<td></td>
</tr>
<tr>
<td>computation. If unspecified, <code>batch_size</code> will default to 32. Do not</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>specify the <code>batch_size</code> if your data is in the form of a dataset,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>generators, or <code>keras.utils.Sequence</code> instances (since they generate</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>batches).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>verbose</td>
<td>None</td>
<td>0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional Numpy array of weights for the test samples,</td>
<td></td>
</tr>
<tr>
<td>used for weighting the loss function. You can either pass a flat (1D)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Numpy array with the same length as the input samples</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(1:1 mapping between weights and samples), or in the case of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>temporal data, you can pass a 2D array with shape `(samples,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sequence_length)`, to apply a different weight to every timestep</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of every sample. This argument is not supported when <code>x</code> is a</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>dataset, instead pass sample weights as the third element of <code>x</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>steps</td>
<td>None</td>
<td>Integer or <code>None</code>. Total number of steps (batches of samples)</td>
<td></td>
</tr>
<tr>
<td>before declaring the evaluation round finished. Ignored with the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>default value of <code>None</code>. If x is a <code>tf.data</code> dataset and <code>steps</code> is</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>None, 'evaluate' will run until the dataset is exhausted. This</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>argument is not supported with array inputs.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>callbacks</td>
<td>None</td>
<td>List of <code>keras.callbacks.Callback</code> instances. List of</td>
<td></td>
</tr>
<tr>
<td>callbacks to apply during evaluation. See</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>max_queue_size</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code></td>
<td></td>
</tr>
<tr>
<td>input only. Maximum size for the generator queue. If unspecified,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>max_queue_size</code> will default to 10.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>workers</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input</td>
<td></td>
</tr>
<tr>
<td>only. Maximum number of processes to spin up when using process-based</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>threading. If unspecified, <code>workers</code> will default to 1. If 0, will</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>execute the generator on the main thread.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>None</td>
<td>Boolean. Used for generator or</td>
<td></td>
</tr>
<tr>
<td><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>threading. If unspecified, <code>use_multiprocessing</code> will default to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>False</code>. Note that because this implementation relies on</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>multiprocessing, you should not pass non-picklable arguments to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>generator as they can't be passed easily to children processes.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,</td>
<td></td>
</tr>
<tr>
<td>with each key being the name of the metric. If <code>False</code>, they are</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returned as a list.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>See the discussion of <code>Unpacking behavior for iterator-like inputs</code> for
<code>Model.fit</code>. | None |</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)</td>
</tr>
<tr>
<td>or list of scalars (if the model has multiple outputs</td>
<td></td>
</tr>
<tr>
<td>and/or metrics). The attribute <code>model.metrics_names</code> will give you</td>
<td></td>
</tr>
<tr>
<td>the display labels for the scalar outputs.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.evaluate</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>in case of invalid arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

               <span class="n">x</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

               <span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

               <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

               <span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

               <span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the loss value &amp; metrics values for the model in test mode.</span>

<span class="s2">    Computation is done in batches (see the `batch_size` arg.)</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">            if the model has named inputs.</span>

<span class="s2">          - A `tf.data` dataset. Should return a tuple</span>

<span class="s2">            of either `(inputs, targets)` or</span>

<span class="s2">            `(inputs, targets, sample_weights)`.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="s2">            or `(inputs, targets, sample_weights)`.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely). If</span>

<span class="s2">          `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`</span>

<span class="s2">          should not be specified (since targets will be obtained from the</span>

<span class="s2">          iterator/dataset).</span>

<span class="s2">        batch_size: Integer or `None`. Number of samples per batch of</span>

<span class="s2">          computation. If unspecified, `batch_size` will default to 32. Do not</span>

<span class="s2">          specify the `batch_size` if your data is in the form of a dataset,</span>

<span class="s2">          generators, or `keras.utils.Sequence` instances (since they generate</span>

<span class="s2">          batches).</span>

<span class="s2">        verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</span>

<span class="s2">        sample_weight: Optional Numpy array of weights for the test samples,</span>

<span class="s2">          used for weighting the loss function. You can either pass a flat (1D)</span>

<span class="s2">          Numpy array with the same length as the input samples</span>

<span class="s2">            (1:1 mapping between weights and samples), or in the case of</span>

<span class="s2">              temporal data, you can pass a 2D array with shape `(samples,</span>

<span class="s2">              sequence_length)`, to apply a different weight to every timestep</span>

<span class="s2">              of every sample. This argument is not supported when `x` is a</span>

<span class="s2">              dataset, instead pass sample weights as the third element of `x`.</span>

<span class="s2">        steps: Integer or `None`. Total number of steps (batches of samples)</span>

<span class="s2">          before declaring the evaluation round finished. Ignored with the</span>

<span class="s2">          default value of `None`. If x is a `tf.data` dataset and `steps` is</span>

<span class="s2">          None, &#39;evaluate&#39; will run until the dataset is exhausted. This</span>

<span class="s2">          argument is not supported with array inputs.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances. List of</span>

<span class="s2">          callbacks to apply during evaluation. See</span>

<span class="s2">          [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">          input only. Maximum size for the generator queue. If unspecified,</span>

<span class="s2">          `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">          only. Maximum number of processes to spin up when using process-based</span>

<span class="s2">          threading. If unspecified, `workers` will default to 1. If 0, will</span>

<span class="s2">          execute the generator on the main thread.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">          `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">          threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">          `False`. Note that because this implementation relies on</span>

<span class="s2">          multiprocessing, you should not pass non-picklable arguments to the</span>

<span class="s2">          generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.evaluate` is wrapped in `tf.function`.</span>

<span class="s2">        ValueError: in case of invalid arguments.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

    <span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;evaluate&#39;</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="c1"># Use cached evaluation data only when it&#39;s called in `Model.fit`</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_fit_frame&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span>

          <span class="k">and</span> <span class="n">tf_inspect</span><span class="p">.</span><span class="n">currentframe</span><span class="p">().</span><span class="n">f_back</span> <span class="k">is</span> <span class="n">self</span><span class="p">.</span><span class="n">_fit_frame</span>

          <span class="k">and</span> <span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">)</span><span class="o">:</span>

        <span class="n">data_handler</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_eval_data_handler</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

        <span class="n">data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">DataHandler</span><span class="p">(</span>

            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>

            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>

            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

            <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

            <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

            <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

            <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

            <span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

      <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

      <span class="k">if</span> <span class="k">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span>

            <span class="n">callbacks</span><span class="p">,</span>

            <span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="err">{}</span>

      <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_begin</span><span class="p">()</span>

      <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">iterator</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span>  <span class="c1"># Single epoch.</span>

        <span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span>

          <span class="k">for</span> <span class="n">step</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span>

            <span class="k">with</span> <span class="n">trace</span><span class="p">.</span><span class="n">Trace</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span>

              <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

              <span class="n">tmp_logs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

              <span class="k">if</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span>

                <span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span>

              <span class="k">logs</span> <span class="o">=</span> <span class="n">tmp_logs</span>  <span class="c1"># No error, now safe to assign to logs.</span>

              <span class="n">end_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">+</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span>

              <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span> <span class="k">logs</span><span class="p">)</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="k">logs</span><span class="o">=</span><span class="k">logs</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">return_dict</span><span class="o">:</span>

        <span class="k">return</span> <span class="k">logs</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">results</span> <span class="o">=</span> <span class="err">[]</span>

        <span class="k">for</span> <span class="k">name</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="o">:</span>

          <span class="k">if</span> <span class="k">name</span> <span class="k">in</span> <span class="k">logs</span><span class="o">:</span>

            <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="k">logs</span><span class="err">[</span><span class="k">name</span><span class="err">]</span><span class="p">)</span>

        <span class="k">for</span> <span class="k">key</span> <span class="k">in</span> <span class="n">sorted</span><span class="p">(</span><span class="k">logs</span><span class="p">.</span><span class="k">keys</span><span class="p">())</span><span class="o">:</span>

          <span class="k">if</span> <span class="k">key</span> <span class="k">not</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="o">:</span>

            <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="k">logs</span><span class="err">[</span><span class="k">key</span><span class="err">]</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

          <span class="k">return</span> <span class="n">results</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

        <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

</details>
<h4 id="evaluate_generator_1">evaluate_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Evaluates the model on a data generator.</p>
<p>DEPRECATED:
  <code>Model.evaluate</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">evaluate_generator</span><span class="p">(</span><span class="k">self</span><span class="p">,</span>

                         <span class="n">generator</span><span class="p">,</span>

                         <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                         <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                         <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

                         <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                         <span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

                         <span class="k">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Evaluates the model on a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.evaluate` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`Model.evaluate_generator` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `Model.evaluate`, which supports generators.&#39;</span><span class="p">)</span>

    <span class="k">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate_generator&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="k">self</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span>

        <span class="n">generator</span><span class="p">,</span>

        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

        <span class="k">verbose</span><span class="o">=</span><span class="k">verbose</span><span class="p">,</span>

        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="fit_1">fit</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<p>Arguments:
    x: Input data. It could be:
      - A Numpy array (or array-like), or a list of arrays
        (in case the model has multiple inputs).
      - A TensorFlow tensor, or a list of tensors
        (in case the model has multiple inputs).
      - A dict mapping input names to the corresponding array/tensors,
        if the model has named inputs.
      - A <code>tf.data</code> dataset. Should return a tuple
        of either <code>(inputs, targets)</code> or
        <code>(inputs, targets, sample_weights)</code>.
      - A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code>
        or <code>(inputs, targets, sample_weights)</code>.
      A more detailed description of unpacking behavior for iterator types
      (Dataset, generator, Sequence) is given below.
    y: Target data. Like the input data <code>x</code>,
      it could be either Numpy array(s) or TensorFlow tensor(s).
      It should be consistent with <code>x</code> (you cannot have Numpy inputs and
      tensor targets, or inversely). If <code>x</code> is a dataset, generator,
      or <code>keras.utils.Sequence</code> instance, <code>y</code> should
      not be specified (since targets will be obtained from <code>x</code>).
    batch_size: Integer or <code>None</code>.
        Number of samples per gradient update.
        If unspecified, <code>batch_size</code> will default to 32.
        Do not specify the <code>batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    epochs: Integer. Number of epochs to train the model.
        An epoch is an iteration over the entire <code>x</code> and <code>y</code>
        data provided.
        Note that in conjunction with <code>initial_epoch</code>,
        <code>epochs</code> is to be understood as "final epoch".
        The model is not trained for a number of iterations
        given by <code>epochs</code>, but merely until the epoch
        of index <code>epochs</code> is reached.
    verbose: 0, 1, or 2. Verbosity mode.
        0 = silent, 1 = progress bar, 2 = one line per epoch.
        Note that the progress bar is not particularly useful when
        logged to a file, so verbose=2 is recommended when not running
        interactively (eg, in a production environment).
    callbacks: List of <code>keras.callbacks.Callback</code> instances.
        List of callbacks to apply during training.
        See <code>tf.keras.callbacks</code>. Note <code>tf.keras.callbacks.ProgbarLogger</code>
        and <code>tf.keras.callbacks.History</code> callbacks are created automatically
        and need not be passed into <code>model.fit</code>.
        <code>tf.keras.callbacks.ProgbarLogger</code> is created or not based on
        <code>verbose</code> argument to <code>model.fit</code>.
    validation_split: Float between 0 and 1.
        Fraction of the training data to be used as validation data.
        The model will set apart this fraction of the training data,
        will not train on it, and will evaluate
        the loss and any model metrics
        on this data at the end of each epoch.
        The validation data is selected from the last samples
        in the <code>x</code> and <code>y</code> data provided, before shuffling. This argument is
        not supported when <code>x</code> is a dataset, generator or
       <code>keras.utils.Sequence</code> instance.
    validation_data: Data on which to evaluate
        the loss and any model metrics at the end of each epoch.
        The model will not be trained on this data. Thus, note the fact
        that the validation loss of data provided using <code>validation_split</code>
        or <code>validation_data</code> is not affected by regularization layers like
        noise and dropout.
        <code>validation_data</code> will override <code>validation_split</code>.
        <code>validation_data</code> could be:
          - tuple <code>(x_val, y_val)</code> of Numpy arrays or tensors
          - tuple <code>(x_val, y_val, val_sample_weights)</code> of Numpy arrays
          - dataset
        For the first two cases, <code>batch_size</code> must be provided.
        For the last case, <code>validation_steps</code> could be provided.
        Note that <code>validation_data</code> does not support all the data types that
        are supported in <code>x</code>, eg, dict, generator or <code>keras.utils.Sequence</code>.
    shuffle: Boolean (whether to shuffle the training data
        before each epoch) or str (for 'batch'). This argument is ignored
        when <code>x</code> is a generator. 'batch' is a special option for dealing
        with the limitations of HDF5 data; it shuffles in batch-sized
        chunks. Has no effect when <code>steps_per_epoch</code> is not <code>None</code>.
    class_weight: Optional dictionary mapping class indices (integers)
        to a weight (float) value, used for weighting the loss function
        (during training only).
        This can be useful to tell the model to
        "pay more attention" to samples from
        an under-represented class.
    sample_weight: Optional Numpy array of weights for
        the training samples, used for weighting the loss function
        (during training only). You can either pass a flat (1D)
        Numpy array with the same length as the input samples
        (1:1 mapping between weights and samples),
        or in the case of temporal data,
        you can pass a 2D array with shape
        <code>(samples, sequence_length)</code>,
        to apply a different weight to every timestep of every sample. This
        argument is not supported when <code>x</code> is a dataset, generator, or
       <code>keras.utils.Sequence</code> instance, instead provide the sample_weights
        as the third element of <code>x</code>.
    initial_epoch: Integer.
        Epoch at which to start training
        (useful for resuming a previous training run).
    steps_per_epoch: Integer or <code>None</code>.
        Total number of steps (batches of samples)
        before declaring one epoch finished and starting the
        next epoch. When training with input tensors such as
        TensorFlow data tensors, the default <code>None</code> is equal to
        the number of samples in your dataset divided by
        the batch size, or 1 if that cannot be determined. If x is a
        <code>tf.data</code> dataset, and 'steps_per_epoch'
        is None, the epoch will run until the input dataset is exhausted.
        When passing an infinitely repeating dataset, you must specify the
        <code>steps_per_epoch</code> argument. This argument is not supported with
        array inputs.
    validation_steps: Only relevant if <code>validation_data</code> is provided and
        is a <code>tf.data</code> dataset. Total number of steps (batches of
        samples) to draw before stopping when performing validation
        at the end of every epoch. If 'validation_steps' is None, validation
        will run until the <code>validation_data</code> dataset is exhausted. In the
        case of an infinitely repeated dataset, it will run into an
        infinite loop. If 'validation_steps' is specified and only part of
        the dataset will be consumed, the evaluation will start from the
        beginning of the dataset at each epoch. This ensures that the same
        validation samples are used every time.
    validation_batch_size: Integer or <code>None</code>.
        Number of samples per validation batch.
        If unspecified, will default to <code>batch_size</code>.
        Do not specify the <code>validation_batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    validation_freq: Only relevant if validation data is provided. Integer
        or <code>collections_abc.Container</code> instance (e.g. list, tuple, etc.).
        If an integer, specifies how many training epochs to run before a
        new validation run is performed, e.g. <code>validation_freq=2</code> runs
        validation every 2 epochs. If a Container, specifies the epochs on
        which to run validation, e.g. <code>validation_freq=[1, 2, 10]</code> runs
        validation at the end of the 1st, 2nd, and 10th epochs.
    max_queue_size: Integer. Used for generator or <code>keras.utils.Sequence</code>
        input only. Maximum size for the generator queue.
        If unspecified, <code>max_queue_size</code> will default to 10.
    workers: Integer. Used for generator or <code>keras.utils.Sequence</code> input
        only. Maximum number of processes to spin up
        when using process-based threading. If unspecified, <code>workers</code>
        will default to 1. If 0, will execute the generator on the main
        thread.
    use_multiprocessing: Boolean. Used for generator or
        <code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based
        threading. If unspecified, <code>use_multiprocessing</code> will default to
        <code>False</code>. Note that because this implementation relies on
        multiprocessing, you should not pass non-picklable arguments to
        the generator as they can't be passed easily to children processes.</p>
<p>Unpacking behavior for iterator-like inputs:
    A common pattern is to pass a tf.data.Dataset, generator, or
  tf.keras.utils.Sequence to the <code>x</code> argument of fit, which will in fact
  yield not only features (x) but optionally targets (y) and sample weights.
  Keras requires that the output of such iterator-likes be unambiguous. The
  iterator should return a tuple of length 1, 2, or 3, where the optional
  second and third elements will be used for y and sample_weight
  respectively. Any other type provided will be wrapped in a length one
  tuple, effectively treating everything as 'x'. When yielding dicts, they
  should still adhere to the top-level tuple structure.
  e.g. <code>({"x0": x0, "x1": x1}, y)</code>. Keras will not attempt to separate
  features, targets, and weights from the keys of a single dict.
    A notable unsupported data type is the namedtuple. The reason is that
  it behaves like both an ordered datatype (tuple) and a mapping
  datatype (dict). So given a namedtuple of the form:
      <code>namedtuple("example_tuple", ["y", "x"])</code>
  it is ambiguous whether to reverse the order of the elements when
  interpreting the value. Even worse is a tuple of the form:
      <code>namedtuple("other_tuple", ["x", "y", "z"])</code>
  where it is unclear if the tuple was intended to be unpacked into x, y,
  and sample_weight or passed through as a single element to <code>x</code>. As a
  result the data processing code will simply raise a ValueError if it
  encounters a namedtuple. (Along with instructions to remedy the issue.)</p>
<p>Returns:
    A <code>History</code> object. Its <code>History.history</code> attribute is
    a record of training loss values and metrics values
    at successive epochs, as well as validation loss values
    and validation metrics values (if applicable).</p>
<p>Raises:
    RuntimeError: 1. If the model was never compiled or,
    2. If <code>model.fit</code> is  wrapped in <code>tf.function</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span> <span class="n">In</span> <span class="k">case</span> <span class="n">of</span> <span class="n">mismatch</span> <span class="n">between</span> <span class="n">the</span> <span class="n">provided</span> <span class="n">input</span> <span class="n">data</span>
    <span class="n">and</span> <span class="n">what</span> <span class="n">the</span> <span class="n">model</span> <span class="n">expects</span> <span class="n">or</span> <span class="n">when</span> <span class="n">the</span> <span class="n">input</span> <span class="n">data</span> <span class="k">is</span> <span class="n">empty</span><span class="o">.</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

          <span class="n">x</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">y</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">callbacks</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>

          <span class="n">validation_data</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">shuffle</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

          <span class="n">class_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">sample_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

          <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_steps</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

          <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">False</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Trains the model for a fixed number of epochs (iterations on a dataset).</span>

<span class="sd">    Arguments:</span>

<span class="sd">        x: Input data. It could be:</span>

<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="sd">            if the model has named inputs.</span>

<span class="sd">          - A `tf.data` dataset. Should return a tuple</span>

<span class="sd">            of either `(inputs, targets)` or</span>

<span class="sd">            `(inputs, targets, sample_weights)`.</span>

<span class="sd">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="sd">            or `(inputs, targets, sample_weights)`.</span>

<span class="sd">          A more detailed description of unpacking behavior for iterator types</span>

<span class="sd">          (Dataset, generator, Sequence) is given below.</span>

<span class="sd">        y: Target data. Like the input data `x`,</span>

<span class="sd">          it could be either Numpy array(s) or TensorFlow tensor(s).</span>

<span class="sd">          It should be consistent with `x` (you cannot have Numpy inputs and</span>

<span class="sd">          tensor targets, or inversely). If `x` is a dataset, generator,</span>

<span class="sd">          or `keras.utils.Sequence` instance, `y` should</span>

<span class="sd">          not be specified (since targets will be obtained from `x`).</span>

<span class="sd">        batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per gradient update.</span>

<span class="sd">            If unspecified, `batch_size` will default to 32.</span>

<span class="sd">            Do not specify the `batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        epochs: Integer. Number of epochs to train the model.</span>

<span class="sd">            An epoch is an iteration over the entire `x` and `y`</span>

<span class="sd">            data provided.</span>

<span class="sd">            Note that in conjunction with `initial_epoch`,</span>

<span class="sd">            `epochs` is to be understood as &quot;final epoch&quot;.</span>

<span class="sd">            The model is not trained for a number of iterations</span>

<span class="sd">            given by `epochs`, but merely until the epoch</span>

<span class="sd">            of index `epochs` is reached.</span>

<span class="sd">        verbose: 0, 1, or 2. Verbosity mode.</span>

<span class="sd">            0 = silent, 1 = progress bar, 2 = one line per epoch.</span>

<span class="sd">            Note that the progress bar is not particularly useful when</span>

<span class="sd">            logged to a file, so verbose=2 is recommended when not running</span>

<span class="sd">            interactively (eg, in a production environment).</span>

<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="sd">            List of callbacks to apply during training.</span>

<span class="sd">            See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`</span>

<span class="sd">            and `tf.keras.callbacks.History` callbacks are created automatically</span>

<span class="sd">            and need not be passed into `model.fit`.</span>

<span class="sd">            `tf.keras.callbacks.ProgbarLogger` is created or not based on</span>

<span class="sd">            `verbose` argument to `model.fit`.</span>

<span class="sd">        validation_split: Float between 0 and 1.</span>

<span class="sd">            Fraction of the training data to be used as validation data.</span>

<span class="sd">            The model will set apart this fraction of the training data,</span>

<span class="sd">            will not train on it, and will evaluate</span>

<span class="sd">            the loss and any model metrics</span>

<span class="sd">            on this data at the end of each epoch.</span>

<span class="sd">            The validation data is selected from the last samples</span>

<span class="sd">            in the `x` and `y` data provided, before shuffling. This argument is</span>

<span class="sd">            not supported when `x` is a dataset, generator or</span>

<span class="sd">           `keras.utils.Sequence` instance.</span>

<span class="sd">        validation_data: Data on which to evaluate</span>

<span class="sd">            the loss and any model metrics at the end of each epoch.</span>

<span class="sd">            The model will not be trained on this data. Thus, note the fact</span>

<span class="sd">            that the validation loss of data provided using `validation_split`</span>

<span class="sd">            or `validation_data` is not affected by regularization layers like</span>

<span class="sd">            noise and dropout.</span>

<span class="sd">            `validation_data` will override `validation_split`.</span>

<span class="sd">            `validation_data` could be:</span>

<span class="sd">              - tuple `(x_val, y_val)` of Numpy arrays or tensors</span>

<span class="sd">              - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays</span>

<span class="sd">              - dataset</span>

<span class="sd">            For the first two cases, `batch_size` must be provided.</span>

<span class="sd">            For the last case, `validation_steps` could be provided.</span>

<span class="sd">            Note that `validation_data` does not support all the data types that</span>

<span class="sd">            are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.</span>

<span class="sd">        shuffle: Boolean (whether to shuffle the training data</span>

<span class="sd">            before each epoch) or str (for &#39;batch&#39;). This argument is ignored</span>

<span class="sd">            when `x` is a generator. &#39;batch&#39; is a special option for dealing</span>

<span class="sd">            with the limitations of HDF5 data; it shuffles in batch-sized</span>

<span class="sd">            chunks. Has no effect when `steps_per_epoch` is not `None`.</span>

<span class="sd">        class_weight: Optional dictionary mapping class indices (integers)</span>

<span class="sd">            to a weight (float) value, used for weighting the loss function</span>

<span class="sd">            (during training only).</span>

<span class="sd">            This can be useful to tell the model to</span>

<span class="sd">            &quot;pay more attention&quot; to samples from</span>

<span class="sd">            an under-represented class.</span>

<span class="sd">        sample_weight: Optional Numpy array of weights for</span>

<span class="sd">            the training samples, used for weighting the loss function</span>

<span class="sd">            (during training only). You can either pass a flat (1D)</span>

<span class="sd">            Numpy array with the same length as the input samples</span>

<span class="sd">            (1:1 mapping between weights and samples),</span>

<span class="sd">            or in the case of temporal data,</span>

<span class="sd">            you can pass a 2D array with shape</span>

<span class="sd">            `(samples, sequence_length)`,</span>

<span class="sd">            to apply a different weight to every timestep of every sample. This</span>

<span class="sd">            argument is not supported when `x` is a dataset, generator, or</span>

<span class="sd">           `keras.utils.Sequence` instance, instead provide the sample_weights</span>

<span class="sd">            as the third element of `x`.</span>

<span class="sd">        initial_epoch: Integer.</span>

<span class="sd">            Epoch at which to start training</span>

<span class="sd">            (useful for resuming a previous training run).</span>

<span class="sd">        steps_per_epoch: Integer or `None`.</span>

<span class="sd">            Total number of steps (batches of samples)</span>

<span class="sd">            before declaring one epoch finished and starting the</span>

<span class="sd">            next epoch. When training with input tensors such as</span>

<span class="sd">            TensorFlow data tensors, the default `None` is equal to</span>

<span class="sd">            the number of samples in your dataset divided by</span>

<span class="sd">            the batch size, or 1 if that cannot be determined. If x is a</span>

<span class="sd">            `tf.data` dataset, and &#39;steps_per_epoch&#39;</span>

<span class="sd">            is None, the epoch will run until the input dataset is exhausted.</span>

<span class="sd">            When passing an infinitely repeating dataset, you must specify the</span>

<span class="sd">            `steps_per_epoch` argument. This argument is not supported with</span>

<span class="sd">            array inputs.</span>

<span class="sd">        validation_steps: Only relevant if `validation_data` is provided and</span>

<span class="sd">            is a `tf.data` dataset. Total number of steps (batches of</span>

<span class="sd">            samples) to draw before stopping when performing validation</span>

<span class="sd">            at the end of every epoch. If &#39;validation_steps&#39; is None, validation</span>

<span class="sd">            will run until the `validation_data` dataset is exhausted. In the</span>

<span class="sd">            case of an infinitely repeated dataset, it will run into an</span>

<span class="sd">            infinite loop. If &#39;validation_steps&#39; is specified and only part of</span>

<span class="sd">            the dataset will be consumed, the evaluation will start from the</span>

<span class="sd">            beginning of the dataset at each epoch. This ensures that the same</span>

<span class="sd">            validation samples are used every time.</span>

<span class="sd">        validation_batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per validation batch.</span>

<span class="sd">            If unspecified, will default to `batch_size`.</span>

<span class="sd">            Do not specify the `validation_batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        validation_freq: Only relevant if validation data is provided. Integer</span>

<span class="sd">            or `collections_abc.Container` instance (e.g. list, tuple, etc.).</span>

<span class="sd">            If an integer, specifies how many training epochs to run before a</span>

<span class="sd">            new validation run is performed, e.g. `validation_freq=2` runs</span>

<span class="sd">            validation every 2 epochs. If a Container, specifies the epochs on</span>

<span class="sd">            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs</span>

<span class="sd">            validation at the end of the 1st, 2nd, and 10th epochs.</span>

<span class="sd">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="sd">            input only. Maximum size for the generator queue.</span>

<span class="sd">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="sd">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="sd">            only. Maximum number of processes to spin up</span>

<span class="sd">            when using process-based threading. If unspecified, `workers`</span>

<span class="sd">            will default to 1. If 0, will execute the generator on the main</span>

<span class="sd">            thread.</span>

<span class="sd">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="sd">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="sd">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="sd">            `False`. Note that because this implementation relies on</span>

<span class="sd">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="sd">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="sd">    Unpacking behavior for iterator-like inputs:</span>

<span class="sd">        A common pattern is to pass a tf.data.Dataset, generator, or</span>

<span class="sd">      tf.keras.utils.Sequence to the `x` argument of fit, which will in fact</span>

<span class="sd">      yield not only features (x) but optionally targets (y) and sample weights.</span>

<span class="sd">      Keras requires that the output of such iterator-likes be unambiguous. The</span>

<span class="sd">      iterator should return a tuple of length 1, 2, or 3, where the optional</span>

<span class="sd">      second and third elements will be used for y and sample_weight</span>

<span class="sd">      respectively. Any other type provided will be wrapped in a length one</span>

<span class="sd">      tuple, effectively treating everything as &#39;x&#39;. When yielding dicts, they</span>

<span class="sd">      should still adhere to the top-level tuple structure.</span>

<span class="sd">      e.g. `({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)`. Keras will not attempt to separate</span>

<span class="sd">      features, targets, and weights from the keys of a single dict.</span>

<span class="sd">        A notable unsupported data type is the namedtuple. The reason is that</span>

<span class="sd">      it behaves like both an ordered datatype (tuple) and a mapping</span>

<span class="sd">      datatype (dict). So given a namedtuple of the form:</span>

<span class="sd">          `namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])`</span>

<span class="sd">      it is ambiguous whether to reverse the order of the elements when</span>

<span class="sd">      interpreting the value. Even worse is a tuple of the form:</span>

<span class="sd">          `namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])`</span>

<span class="sd">      where it is unclear if the tuple was intended to be unpacked into x, y,</span>

<span class="sd">      and sample_weight or passed through as a single element to `x`. As a</span>

<span class="sd">      result the data processing code will simply raise a ValueError if it</span>

<span class="sd">      encounters a namedtuple. (Along with instructions to remedy the issue.)</span>

<span class="sd">    Returns:</span>

<span class="sd">        A `History` object. Its `History.history` attribute is</span>

<span class="sd">        a record of training loss values and metrics values</span>

<span class="sd">        at successive epochs, as well as validation loss values</span>

<span class="sd">        and validation metrics values (if applicable).</span>

<span class="sd">    Raises:</span>

<span class="sd">        RuntimeError: 1. If the model was never compiled or,</span>

<span class="sd">        2. If `model.fit` is  wrapped in `tf.function`.</span>

<span class="sd">        ValueError: In case of mismatch between the provided input data</span>

<span class="sd">            and what the model expects or when the input data is empty.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">base_layer</span><span class="o">.</span><span class="n">keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span>

    <span class="c1"># Legacy graph support is contained in `training_v1.Model`.</span>

    <span class="n">version_utils</span><span class="o">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">validation_split</span><span class="p">:</span>

      <span class="c1"># Create the validation data using the training data. Only supported for</span>

      <span class="c1"># `Tensor` and `NumPy` input.</span>

      <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">),</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span>

          <span class="n">data_adapter</span><span class="o">.</span><span class="n">train_validation_split</span><span class="p">(</span>

              <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">),</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">validation_data</span><span class="p">:</span>

      <span class="n">val_x</span><span class="p">,</span> <span class="n">val_y</span><span class="p">,</span> <span class="n">val_sample_weight</span> <span class="o">=</span> <span class="p">(</span>

          <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">validation_data</span><span class="p">))</span>

    <span class="n">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span> \

         <span class="n">training_utils</span><span class="o">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

      <span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

      <span class="n">data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">DataHandler</span><span class="p">(</span>

          <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

          <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>

          <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>

          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

          <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>

          <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>

          <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

          <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>

          <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>

          <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

          <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

          <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

          <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

          <span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

      <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">):</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">(</span>

            <span class="n">callbacks</span><span class="p">,</span>

            <span class="n">add_history</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="n">False</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_train_function</span><span class="p">()</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_train_counter</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span>

      <span class="n">training_logs</span> <span class="o">=</span> <span class="n">None</span>

      <span class="c1"># Handle fault-tolerance for multi-worker.</span>

      <span class="c1"># TODO(omalleyt): Fix the ordering issues that mean this has to</span>

      <span class="c1"># happen after `callbacks.on_train_begin`.</span>

      <span class="n">data_handler</span><span class="o">.</span><span class="n">_initial_epoch</span> <span class="o">=</span> <span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>

          <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_load_initial_epoch_from_ckpt</span><span class="p">(</span><span class="n">initial_epoch</span><span class="p">))</span>

      <span class="n">logs</span> <span class="o">=</span> <span class="n">None</span>

      <span class="k">for</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">iterator</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

        <span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

        <span class="n">with</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span>

          <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span>

            <span class="n">with</span> <span class="n">trace</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span>

                <span class="s1">&#39;train&#39;</span><span class="p">,</span>

                <span class="n">epoch_num</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>

                <span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span>

                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

                <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>

              <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

              <span class="n">tmp_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

              <span class="k">if</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span>

                <span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span>

              <span class="n">logs</span> <span class="o">=</span> <span class="n">tmp_logs</span>  <span class="c1"># No error, now safe to assign to logs.</span>

              <span class="n">end_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">+</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">step_increment</span>

              <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

                <span class="k">break</span>

        <span class="k">if</span> <span class="n">logs</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

          <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Expect x to be a non-empty array or dataset.&#39;</span><span class="p">)</span>

        <span class="n">epoch_logs</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

        <span class="c1"># Run validation.</span>

        <span class="k">if</span> <span class="n">validation_data</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_eval</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">validation_freq</span><span class="p">):</span>

          <span class="c1"># Create data_handler for evaluation and cache it.</span>

          <span class="k">if</span> <span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span> <span class="n">None</span><span class="p">)</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_frame</span> <span class="o">=</span> <span class="n">tf_inspect</span><span class="o">.</span><span class="n">currentframe</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">DataHandler</span><span class="p">(</span>

                <span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>

                <span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>

                <span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>

                <span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span> <span class="ow">or</span> <span class="n">batch_size</span><span class="p">,</span>

                <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

                <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

                <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

                <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

                <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

                <span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

          <span class="n">val_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>

              <span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>

              <span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>

              <span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>

              <span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span> <span class="ow">or</span> <span class="n">batch_size</span><span class="p">,</span>

              <span class="n">steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

              <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

              <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

              <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

              <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

              <span class="n">return_dict</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>

          <span class="n">val_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;val_&#39;</span> <span class="o">+</span> <span class="n">name</span><span class="p">:</span> <span class="n">val</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

          <span class="n">epoch_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_logs</span><span class="p">)</span>

        <span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">epoch_logs</span><span class="p">)</span>

        <span class="n">training_logs</span> <span class="o">=</span> <span class="n">epoch_logs</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

          <span class="k">break</span>

      <span class="c1"># If eval data_hanlder exists, delete it after all epochs are done.</span>

      <span class="k">if</span> <span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span> <span class="n">None</span><span class="p">)</span> <span class="k">is</span> <span class="ow">not</span> <span class="n">None</span><span class="p">:</span>

        <span class="n">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span>

        <span class="n">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_frame</span>

      <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="o">=</span><span class="n">training_logs</span><span class="p">)</span>

      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>

</details>
<h4 id="fit_generator_1">fit_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Fits the model on data yielded batch-by-batch by a Python generator.</p>
<p>DEPRECATED:
  <code>Model.fit</code> now supports generators, so there is no longer any need to use
  this endpoint.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">fit_generator</span><span class="p">(</span><span class="k">self</span><span class="p">,</span>

                    <span class="n">generator</span><span class="p">,</span>

                    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="k">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">validation_data</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">validation_steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

                    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

                    <span class="n">shuffle</span><span class="o">=</span><span class="k">True</span><span class="p">,</span>

                    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Fits the model on data yielded batch-by-batch by a Python generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.fit` now supports generators, so there is no longer any need to use</span>

<span class="ss">      this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`Model.fit_generator` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `Model.fit`, which supports generators.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="k">self</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>

        <span class="n">generator</span><span class="p">,</span>

        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>

        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

        <span class="k">verbose</span><span class="o">=</span><span class="k">verbose</span><span class="p">,</span>

        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

        <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span>

        <span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

        <span class="n">validation_freq</span><span class="o">=</span><span class="n">validation_freq</span><span class="p">,</span>

        <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>

        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>

        <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_config_1">get_config</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <code>Network</code> (one layer of abstraction above).</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Python dictionary.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">get_config</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="n">raise</span> <span class="n">NotImplementedError</span>
</code></pre></div>

</details>
<h4 id="get_input_at_1">get_input_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor (or list of tensors if the layer has multiple inputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the input tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A tensor (or list of tensors if the layer has multiple inputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;input_tensors&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;input&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_input_mask_at_1">get_input_mask_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_mask_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input mask tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A mask tensor</td>
</tr>
<tr>
<td>(or list of tensors if the layer has multiple inputs).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_mask_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the input mask tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A mask tensor</span>

<span class="ss">        (or list of tensors if the layer has multiple inputs).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_input_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="o">[</span><span class="n">getattr(x, &#39;_keras_mask&#39;, None) for x in inputs</span><span class="o">]</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_keras_mask&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_input_shape_at_1">get_input_shape_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_shape_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input shape(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A shape tuple</td>
</tr>
<tr>
<td>(or list of shape tuples if the layer has multiple inputs).</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_shape_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the input shape(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A shape tuple</span>

<span class="ss">        (or list of shape tuples if the layer has multiple inputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;input_shapes&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;input shape&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_layer_1">get_layer</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_layer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence.
Indices are based on order of horizontal graph traversal (bottom-up).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>None</td>
<td>String, name of layer.</td>
<td>None</td>
</tr>
<tr>
<td>index</td>
<td>None</td>
<td>Integer, index of layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>In case of invalid layer name or index.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">get_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="k">index</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Retrieves a layer based on either its name (unique) or index.</span>

<span class="s2">    If `name` and `index` are both provided, `index` will take precedence.</span>

<span class="s2">    Indices are based on order of horizontal graph traversal (bottom-up).</span>

<span class="s2">    Arguments:</span>

<span class="s2">        name: String, name of layer.</span>

<span class="s2">        index: Integer, index of layer.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A layer instance.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: In case of invalid layer name or index.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="c1"># TODO(fchollet): We could build a dictionary based on layer names</span>

    <span class="c1"># since they are constant, but we have not done that yet.</span>

    <span class="k">if</span> <span class="k">index</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span> <span class="k">and</span> <span class="k">name</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide only a layer name or a layer index.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="k">index</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="k">index</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Was asked to retrieve layer at index &#39;</span> <span class="o">+</span> <span class="n">str</span><span class="p">(</span><span class="k">index</span><span class="p">)</span> <span class="o">+</span>

                         <span class="s1">&#39; but model only has &#39;</span> <span class="o">+</span> <span class="n">str</span><span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">))</span> <span class="o">+</span>

                         <span class="s1">&#39; layers.&#39;</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="err">[</span><span class="k">index</span><span class="err">]</span>

    <span class="k">if</span> <span class="k">name</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">for</span> <span class="n">layer</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="o">:</span>

        <span class="k">if</span> <span class="n">layer</span><span class="p">.</span><span class="k">name</span> <span class="o">==</span> <span class="k">name</span><span class="o">:</span>

          <span class="k">return</span> <span class="n">layer</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;No such layer: &#39;</span> <span class="o">+</span> <span class="k">name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>

    <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide either a layer name or layer index.&#39;</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_losses_for_1">get_losses_for</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_losses_for</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Retrieves losses relevant to a specific set of inputs.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Input tensor or list/tuple of input tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List of loss tensors of the layer that depend on <code>inputs</code>.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_generate_docs</span>

  <span class="n">def</span> <span class="n">get_losses_for</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use!</span>

<span class="s2">    Retrieves losses relevant to a specific set of inputs.</span>

<span class="s2">    Arguments:</span>

<span class="s2">      inputs: Input tensor or list/tuple of input tensors.</span>

<span class="s2">    Returns:</span>

<span class="s2">      List of loss tensors of the layer that depend on `inputs`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.get_losses_for` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `layer.losses` instead.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">losses</span>
</code></pre></div>

</details>
<h4 id="get_output_at_1">get_output_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor (or list of tensors if the layer has multiple outputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the output tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A tensor (or list of tensors if the layer has multiple outputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;output_tensors&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;output&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_output_mask_at_1">get_output_mask_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_mask_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output mask tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A mask tensor</td>
</tr>
<tr>
<td>(or list of tensors if the layer has multiple outputs).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_mask_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the output mask tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A mask tensor</span>

<span class="ss">        (or list of tensors if the layer has multiple outputs).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_output_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="k">output</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="o">[</span><span class="n">getattr(x, &#39;_keras_mask&#39;, None) for x in output</span><span class="o">]</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="k">output</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_keras_mask&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_output_shape_at_1">get_output_shape_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_shape_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output shape(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A shape tuple</td>
</tr>
<tr>
<td>(or list of shape tuples if the layer has multiple outputs).</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_shape_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the output shape(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A shape tuple</span>

<span class="ss">        (or list of shape tuples if the layer has multiple outputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;output_shapes&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;output shape&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_updates_for_1">get_updates_for</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_updates_for</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Retrieves updates relevant to a specific set of inputs.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Input tensor or list/tuple of input tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List of update ops of the layer that depend on <code>inputs</code>.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_generate_docs</span>

  <span class="n">def</span> <span class="n">get_updates_for</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use!</span>

<span class="s2">    Retrieves updates relevant to a specific set of inputs.</span>

<span class="s2">    Arguments:</span>

<span class="s2">      inputs: Input tensor or list/tuple of input tensors.</span>

<span class="s2">    Returns:</span>

<span class="s2">      List of update ops of the layer that depend on `inputs`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.get_updates_for` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `layer.updates` method instead.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">updates</span>
</code></pre></div>

</details>
<h4 id="get_weights_1">get_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the weights of the model.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A flat list of Numpy arrays.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">get_weights</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Retrieves the weights of the model.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A flat list of Numpy arrays.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="k">with</span> <span class="k">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="k">scope</span><span class="p">():</span>

      <span class="k">return</span> <span class="n">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="k">self</span><span class="p">).</span><span class="n">get_weights</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="load_weights_1">load_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">skip_mismatch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p>
<p>If <code>by_name</code> is False weights are loaded based on the network's
topology. This means the architecture should be the same as when the weights
were saved.  Note that layers that don't have weights are not taken into
account in the topological ordering, so adding or removing layers is fine as
long as they don't have weights.</p>
<p>If <code>by_name</code> is True, weights are loaded into layers only if they share the
same name. This is useful for fine-tuning or transfer-learning models where
some of the layers have changed.</p>
<p>Only topological loading (<code>by_name=False</code>) is supported when loading weights
from the TensorFlow format. Note that topological loading differs slightly
between TensorFlow and HDF5 formats for user-defined classes inheriting from
<code>tf.keras.Model</code>: HDF5 loads based on a flattened list of weights, while the
TensorFlow format loads based on the object-local names of attributes to
which layers are assigned in the <code>Model</code>'s constructor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String, path to the weights file to load. For weight files in</td>
<td></td>
</tr>
<tr>
<td>TensorFlow format, this is the file prefix (the same as was passed</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>to <code>save_weights</code>).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>by_name</td>
<td>None</td>
<td>Boolean, whether to load weights by name or by topological</td>
<td></td>
</tr>
<tr>
<td>order. Only topological loading is supported for weight files in</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>TensorFlow format.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>skip_mismatch</td>
<td>None</td>
<td>Boolean, whether to skip loading of layers where there is</td>
<td></td>
</tr>
<tr>
<td>a mismatch in the number of weights, or a mismatch in the shape of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the weight (only valid when <code>by_name=True</code>).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies</td>
<td></td>
</tr>
<tr>
<td>options for loading weights.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>When loading a weight file in TensorFlow format, returns the same status</td>
</tr>
<tr>
<td>object as <code>tf.train.Checkpoint.restore</code>. When graph building, restore</td>
<td></td>
</tr>
<tr>
<td>ops are run automatically as soon as the network is built (on first call</td>
<td></td>
</tr>
<tr>
<td>for user-defined classes inheriting from <code>Model</code>, immediately if it is</td>
<td></td>
</tr>
<tr>
<td>already built).</td>
<td></td>
</tr>
</tbody>
</table>
<p>When loading weights in HDF5 format, returns <code>None</code>. |</p>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If h5py is not available and the weight file is in HDF5</td>
</tr>
<tr>
<td>format.</td>
<td></td>
</tr>
<tr>
<td>ValueError</td>
<td>If <code>skip_mismatch</code> is set to <code>True</code> when <code>by_name</code> is</td>
</tr>
<tr>
<td><code>False</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

                   <span class="n">filepath</span><span class="p">,</span>

                   <span class="n">by_name</span><span class="o">=</span><span class="n">False</span><span class="p">,</span>

                   <span class="n">skip_mismatch</span><span class="o">=</span><span class="n">False</span><span class="p">,</span>

                   <span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</span>

<span class="sd">    If `by_name` is False weights are loaded based on the network&#39;s</span>

<span class="sd">    topology. This means the architecture should be the same as when the weights</span>

<span class="sd">    were saved.  Note that layers that don&#39;t have weights are not taken into</span>

<span class="sd">    account in the topological ordering, so adding or removing layers is fine as</span>

<span class="sd">    long as they don&#39;t have weights.</span>

<span class="sd">    If `by_name` is True, weights are loaded into layers only if they share the</span>

<span class="sd">    same name. This is useful for fine-tuning or transfer-learning models where</span>

<span class="sd">    some of the layers have changed.</span>

<span class="sd">    Only topological loading (`by_name=False`) is supported when loading weights</span>

<span class="sd">    from the TensorFlow format. Note that topological loading differs slightly</span>

<span class="sd">    between TensorFlow and HDF5 formats for user-defined classes inheriting from</span>

<span class="sd">    `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the</span>

<span class="sd">    TensorFlow format loads based on the object-local names of attributes to</span>

<span class="sd">    which layers are assigned in the `Model`&#39;s constructor.</span>

<span class="sd">    Arguments:</span>

<span class="sd">        filepath: String, path to the weights file to load. For weight files in</span>

<span class="sd">            TensorFlow format, this is the file prefix (the same as was passed</span>

<span class="sd">            to `save_weights`).</span>

<span class="sd">        by_name: Boolean, whether to load weights by name or by topological</span>

<span class="sd">            order. Only topological loading is supported for weight files in</span>

<span class="sd">            TensorFlow format.</span>

<span class="sd">        skip_mismatch: Boolean, whether to skip loading of layers where there is</span>

<span class="sd">            a mismatch in the number of weights, or a mismatch in the shape of</span>

<span class="sd">            the weight (only valid when `by_name=True`).</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for loading weights.</span>

<span class="sd">    Returns:</span>

<span class="sd">        When loading a weight file in TensorFlow format, returns the same status</span>

<span class="sd">        object as `tf.train.Checkpoint.restore`. When graph building, restore</span>

<span class="sd">        ops are run automatically as soon as the network is built (on first call</span>

<span class="sd">        for user-defined classes inheriting from `Model`, immediately if it is</span>

<span class="sd">        already built).</span>

<span class="sd">        When loading weights in HDF5 format, returns `None`.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If h5py is not available and the weight file is in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">        ValueError: If `skip_mismatch` is set to `True` when `by_name` is</span>

<span class="sd">          `False`.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">dist_utils</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">):</span>

      <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span>

          <span class="p">(</span><span class="ow">not</span> <span class="n">_is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">))):</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Load weights is not yet supported with TPUStrategy &#39;</span>

                         <span class="s1">&#39;with steps_per_run greater than 1.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">skip_mismatch</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">by_name</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="s1">&#39;When calling model.load_weights, skip_mismatch can only be set to &#39;</span>

          <span class="s1">&#39;True when by_name is True.&#39;</span><span class="p">)</span>

    <span class="n">filepath</span> <span class="o">=</span> <span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">_is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>

      <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="n">try</span><span class="p">:</span>

        <span class="n">py_checkpoint_reader</span><span class="o">.</span><span class="n">NewCheckpointReader</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;tf&#39;</span>

      <span class="n">except</span> <span class="n">errors_impl</span><span class="o">.</span><span class="n">DataLossError</span><span class="p">:</span>

        <span class="c1"># The checkpoint is not readable in TensorFlow format. Try HDF5.</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span><span class="p">:</span>

      <span class="n">status</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">by_name</span><span class="p">:</span>

        <span class="n">raise</span> <span class="n">NotImplementedError</span><span class="p">(</span>

            <span class="s1">&#39;Weights may only be loaded based on topology into Models when &#39;</span>

            <span class="s1">&#39;loading TensorFlow-formatted weights (got by_name=True to &#39;</span>

            <span class="s1">&#39;load_weights).&#39;</span><span class="p">)</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>

        <span class="n">session</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

        <span class="c1"># Restore existing variables (if any) immediately, and set up a</span>

        <span class="c1"># streaming restore for any variables created in the future.</span>

        <span class="n">trackable_utils</span><span class="o">.</span><span class="n">streaming_restore</span><span class="p">(</span><span class="n">status</span><span class="o">=</span><span class="n">status</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">)</span>

      <span class="n">status</span><span class="o">.</span><span class="n">assert_nontrivial_match</span><span class="p">()</span>

      <span class="k">return</span> <span class="n">status</span>

    <span class="k">if</span> <span class="n">h5py</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ImportError</span><span class="p">(</span>

          <span class="s1">&#39;`load_weights` requires h5py when loading weights from HDF5.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="s1">&#39;Unable to load weights saved in HDF5 format into a subclassed &#39;</span>

          <span class="s1">&#39;Model which has not created its variables yet. Call the Model &#39;</span>

          <span class="s1">&#39;first, then load the weights.&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span>

    <span class="n">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>

      <span class="k">if</span> <span class="s1">&#39;layer_names&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span> <span class="ow">and</span> <span class="s1">&#39;model_weights&#39;</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>

        <span class="n">f</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;model_weights&#39;</span><span class="p">]</span>

      <span class="k">if</span> <span class="n">by_name</span><span class="p">:</span>

        <span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group_by_name</span><span class="p">(</span>

            <span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="n">skip_mismatch</span><span class="o">=</span><span class="n">skip_mismatch</span><span class="p">)</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="make_predict_function_1">make_predict_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_predict_function</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of inference.</p>
<p>This method can be overridden to support custom inference logic.
This method is called by <code>Model.predict</code> and <code>Model.predict_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.predict_step</code>.</p>
<p>This function is cached the first time <code>Model.predict</code> or
<code>Model.predict_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a</td>
</tr>
<tr>
<td><code>tf.data.Iterator</code>, and return the outputs of the <code>Model</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">make_predict_function</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of inference.</span>

<span class="s2">    This method can be overridden to support custom inference logic.</span>

<span class="s2">    This method is called by `Model.predict` and `Model.predict_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.predict_step`.</span>

<span class="s2">    This function is cached the first time `Model.predict` or</span>

<span class="s2">    `Model.predict_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return the outputs of the `Model`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span>

    <span class="n">def</span> <span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

      <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

      <span class="n">def</span> <span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span>

        <span class="k">with</span> <span class="n">ops</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

          <span class="n">model</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

        <span class="k">return</span> <span class="n">outputs</span>

      <span class="k">data</span> <span class="o">=</span> <span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">reduce_per_replica</span><span class="p">(</span>

          <span class="n">outputs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;concat&#39;</span><span class="p">)</span>

      <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span> <span class="k">is</span> <span class="k">None</span> <span class="k">or</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with one step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="n">math_ops</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">:</span>

          <span class="n">directives</span><span class="p">.</span><span class="k">set</span><span class="n">_loop_options</span><span class="p">(</span>

              <span class="n">shape_invariants</span><span class="o">=</span><span class="err">[</span><span class="p">(</span>

                  <span class="n">t</span><span class="p">,</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">get_tensor_spec</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span>

                                <span class="k">for</span> <span class="n">t</span> <span class="k">in</span> <span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="err">]</span><span class="p">)</span>

          <span class="n">step_outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

          <span class="n">outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="o">:</span> <span class="nf">concat</span><span class="p">(</span><span class="err">[</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="err">]</span><span class="p">),</span> <span class="n">outputs</span><span class="p">,</span>

                                       <span class="n">step_outputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

      <span class="n">predict_function</span> <span class="o">=</span> <span class="n">def_function</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

          <span class="n">predict_function</span><span class="p">,</span> <span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="n">predict_function</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span>
</code></pre></div>

</details>
<h4 id="make_test_function_1">make_test_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_test_function</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of evaluation.</p>
<p>This method can be overridden to support custom evaluation logic.
This method is called by <code>Model.evaluate</code> and <code>Model.test_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.test_step</code>.</p>
<p>This function is cached the first time <code>Model.evaluate</code> or
<code>Model.test_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a</td>
</tr>
<tr>
<td><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will</td>
<td></td>
</tr>
<tr>
<td>be passed to <code>tf.keras.Callbacks.on_test_batch_end</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">make_test_function</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of evaluation.</span>

<span class="s2">    This method can be overridden to support custom evaluation logic.</span>

<span class="s2">    This method is called by `Model.evaluate` and `Model.test_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.test_step`.</span>

<span class="s2">    This function is cached the first time `Model.evaluate` or</span>

<span class="s2">    `Model.test_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_test_batch_end`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span>

    <span class="n">def</span> <span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

      <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

      <span class="n">def</span> <span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">test_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span>

        <span class="k">with</span> <span class="n">ops</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

          <span class="n">model</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

        <span class="k">return</span> <span class="n">outputs</span>

      <span class="k">data</span> <span class="o">=</span> <span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">reduce_per_replica</span><span class="p">(</span>

          <span class="n">outputs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>

      <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with one step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="n">math_ops</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span>

          <span class="n">outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

      <span class="n">test_function</span> <span class="o">=</span> <span class="n">def_function</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

          <span class="n">test_function</span><span class="p">,</span> <span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="o">=</span> <span class="n">test_function</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span>
</code></pre></div>

</details>
<h4 id="make_train_function_1">make_train_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_train_function</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of training.</p>
<p>This method can be overridden to support custom training logic.
This method is called by <code>Model.fit</code> and <code>Model.train_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual training
logic to <code>Model.train_step</code>.</p>
<p>This function is cached the first time <code>Model.fit</code> or
<code>Model.train_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a</td>
</tr>
<tr>
<td><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will</td>
<td></td>
</tr>
<tr>
<td>be passed to <code>tf.keras.Callbacks.on_train_batch_end</code>, such as</td>
<td></td>
</tr>
<tr>
<td><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">make_train_function</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of training.</span>

<span class="s2">    This method can be overridden to support custom training logic.</span>

<span class="s2">    This method is called by `Model.fit` and `Model.train_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual training</span>

<span class="s2">    logic to `Model.train_step`.</span>

<span class="s2">    This function is cached the first time `Model.fit` or</span>

<span class="s2">    `Model.train_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_train_batch_end`, such as</span>

<span class="s2">      `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span>

    <span class="n">def</span> <span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

      <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single training step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

      <span class="n">def</span> <span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">train_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="c1"># Ensure counter is updated only if `train_step` succeeds.</span>

        <span class="k">with</span> <span class="n">ops</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

          <span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

        <span class="k">return</span> <span class="n">outputs</span>

      <span class="k">data</span> <span class="o">=</span> <span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">reduce_per_replica</span><span class="p">(</span>

          <span class="n">outputs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>

      <span class="n">write_scalar_summaries</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

      <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with one step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="n">math_ops</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span>

          <span class="n">outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

      <span class="n">train_function</span> <span class="o">=</span> <span class="n">def_function</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

          <span class="n">train_function</span><span class="p">,</span> <span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="n">train_function</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span>
</code></pre></div>

</details>
<h4 id="predict_1">predict</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches. This method is designed for performance in
large scale inputs. For small amount of inputs that fit in one batch,
directly using <code>__call__</code> is recommended for faster execution, e.g.,
<code>model(x)</code>, or <code>model(x, training=False)</code> if you have layers such as
<code>tf.keras.layers.BatchNormalization</code> that behaves differently during
inference. Also, note the fact that test loss is not affected by
regularization layers like noise and dropout.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input samples. It could be:</td>
<td></td>
</tr>
<tr>
<td>- A Numpy array (or array-like), or a list of arrays</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A TensorFlow tensor, or a list of tensors</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A <code>tf.data</code> dataset.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A generator or <code>keras.utils.Sequence</code> instance.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>A more detailed description of unpacking behavior for iterator types</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(Dataset, generator, Sequence) is given in the `Unpacking behavior</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>for iterator-like inputs<code>section of</code>Model.fit`.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Integer or <code>None</code>.</td>
<td></td>
</tr>
<tr>
<td>Number of samples per batch.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>If unspecified, <code>batch_size</code> will default to 32.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Do not specify the <code>batch_size</code> if your data is in the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>form of dataset, generators, or <code>keras.utils.Sequence</code> instances</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(since they generate batches).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>verbose</td>
<td>None</td>
<td>Verbosity mode, 0 or 1.</td>
<td>None</td>
</tr>
<tr>
<td>steps</td>
<td>None</td>
<td>Total number of steps (batches of samples)</td>
<td></td>
</tr>
<tr>
<td>before declaring the prediction round finished.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Ignored with the default value of <code>None</code>. If x is a <code>tf.data</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>dataset and <code>steps</code> is None, <code>predict</code> will</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>run until the input dataset is exhausted.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>callbacks</td>
<td>None</td>
<td>List of <code>keras.callbacks.Callback</code> instances.</td>
<td></td>
</tr>
<tr>
<td>List of callbacks to apply during prediction.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>See <a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>max_queue_size</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code></td>
<td></td>
</tr>
<tr>
<td>input only. Maximum size for the generator queue.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>If unspecified, <code>max_queue_size</code> will default to 10.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>workers</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input</td>
<td></td>
</tr>
<tr>
<td>only. Maximum number of processes to spin up when using</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>process-based threading. If unspecified, <code>workers</code> will default</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>to 1. If 0, will execute the generator on the main thread.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>None</td>
<td>Boolean. Used for generator or</td>
<td></td>
</tr>
<tr>
<td><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>threading. If unspecified, <code>use_multiprocessing</code> will default to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>False</code>. Note that because this implementation relies on</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>multiprocessing, you should not pass non-picklable arguments to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the generator as they can't be passed easily to children processes.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>See the discussion of <code>Unpacking behavior for iterator-like inputs</code> for
<code>Model.fit</code>. Note that Model.predict uses the same interpretation rules as
<code>Model.fit</code> and <code>Model.evaluate</code>, so inputs must be unambiguous for all
three methods. | None |</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between the provided</td>
</tr>
<tr>
<td>input data and the model's expectations,</td>
<td></td>
</tr>
<tr>
<td>or in case a stateful model receives a number of samples</td>
<td></td>
</tr>
<tr>
<td>that is not a multiple of the batch size.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

              <span class="n">x</span><span class="p">,</span>

              <span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

              <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

              <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

              <span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Generates output predictions for the input samples.</span>

<span class="s2">    Computation is done in batches. This method is designed for performance in</span>

<span class="s2">    large scale inputs. For small amount of inputs that fit in one batch,</span>

<span class="s2">    directly using `__call__` is recommended for faster execution, e.g.,</span>

<span class="s2">    `model(x)`, or `model(x, training=False)` if you have layers such as</span>

<span class="s2">    `tf.keras.layers.BatchNormalization` that behaves differently during</span>

<span class="s2">    inference. Also, note the fact that test loss is not affected by</span>

<span class="s2">    regularization layers like noise and dropout.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input samples. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A `tf.data` dataset.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` instance.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        batch_size: Integer or `None`.</span>

<span class="s2">            Number of samples per batch.</span>

<span class="s2">            If unspecified, `batch_size` will default to 32.</span>

<span class="s2">            Do not specify the `batch_size` if your data is in the</span>

<span class="s2">            form of dataset, generators, or `keras.utils.Sequence` instances</span>

<span class="s2">            (since they generate batches).</span>

<span class="s2">        verbose: Verbosity mode, 0 or 1.</span>

<span class="s2">        steps: Total number of steps (batches of samples)</span>

<span class="s2">            before declaring the prediction round finished.</span>

<span class="s2">            Ignored with the default value of `None`. If x is a `tf.data`</span>

<span class="s2">            dataset and `steps` is None, `predict` will</span>

<span class="s2">            run until the input dataset is exhausted.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="s2">            List of callbacks to apply during prediction.</span>

<span class="s2">            See [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">            input only. Maximum size for the generator queue.</span>

<span class="s2">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">            only. Maximum number of processes to spin up when using</span>

<span class="s2">            process-based threading. If unspecified, `workers` will default</span>

<span class="s2">            to 1. If 0, will execute the generator on the main thread.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">            `False`. Note that because this implementation relies on</span>

<span class="s2">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="s2">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`. Note that Model.predict uses the same interpretation rules as</span>

<span class="s2">    `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all</span>

<span class="s2">    three methods.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Numpy array(s) of predictions.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.predict` is wrapped in `tf.function`.</span>

<span class="s2">        ValueError: In case of mismatch between the provided</span>

<span class="s2">            input data and the model&#39;s expectations,</span>

<span class="s2">            or in case a stateful model receives a number of samples</span>

<span class="s2">            that is not a multiple of the batch size.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

    <span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="k">None</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

      <span class="n">dataset_types</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="p">.</span><span class="n">DatasetV1</span><span class="p">,</span> <span class="n">dataset_ops</span><span class="p">.</span><span class="n">DatasetV2</span><span class="p">)</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span> <span class="k">or</span> <span class="n">_is_tpu_multi_host</span><span class="p">(</span>

          <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">))</span> <span class="k">and</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dataset_types</span><span class="p">)</span><span class="o">:</span>

        <span class="n">try</span><span class="o">:</span>

          <span class="k">options</span> <span class="o">=</span> <span class="n">dataset_ops</span><span class="p">.</span><span class="k">Options</span><span class="p">()</span>

          <span class="n">data_option</span> <span class="o">=</span> <span class="n">AutoShardPolicy</span><span class="p">.</span><span class="k">DATA</span>

          <span class="k">options</span><span class="p">.</span><span class="n">experimental_distribute</span><span class="p">.</span><span class="n">auto_shard_policy</span> <span class="o">=</span> <span class="n">data_option</span>

          <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">with_options</span><span class="p">(</span><span class="k">options</span><span class="p">)</span>

        <span class="k">except</span> <span class="n">ValueError</span><span class="o">:</span>

          <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Using Model.predict with &#39;</span>

                        <span class="s1">&#39;MultiWorkerDistributionStrategy or TPUStrategy and &#39;</span>

                        <span class="s1">&#39;AutoShardPolicy.FILE might lead to out-of-order result&#39;</span>

                        <span class="s1">&#39;. Consider setting it to AutoShardPolicy.DATA.&#39;</span><span class="p">)</span>

      <span class="n">data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">DataHandler</span><span class="p">(</span>

          <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

          <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

          <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

          <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

          <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

          <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

          <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

          <span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

      <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

      <span class="k">if</span> <span class="k">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span>

            <span class="n">callbacks</span><span class="p">,</span>

            <span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_begin</span><span class="p">()</span>

      <span class="n">batch_outputs</span> <span class="o">=</span> <span class="k">None</span>

      <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">iterator</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span>  <span class="c1"># Single epoch.</span>

        <span class="k">with</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span>

          <span class="k">for</span> <span class="n">step</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span>

            <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

            <span class="n">tmp_batch_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span>

              <span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span>

            <span class="n">batch_outputs</span> <span class="o">=</span> <span class="n">tmp_batch_outputs</span>  <span class="c1"># No error, now safe to assign.</span>

            <span class="k">if</span> <span class="n">outputs</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

              <span class="n">outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span> <span class="n">batch_output</span><span class="o">:</span> <span class="err">[</span><span class="n">batch_output</span><span class="err">]</span><span class="p">,</span>

                                           <span class="n">batch_outputs</span><span class="p">)</span>

            <span class="k">else</span><span class="o">:</span>

              <span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>

                  <span class="n">batch_outputs</span><span class="p">,</span>

                  <span class="n">lambda</span> <span class="n">output</span><span class="p">,</span> <span class="n">batch_output</span><span class="o">:</span> <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_output</span><span class="p">),</span>

                  <span class="n">outputs</span><span class="p">,</span> <span class="n">batch_outputs</span><span class="p">)</span>

            <span class="n">end_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">+</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span>

            <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span> <span class="err">{</span><span class="s1">&#39;outputs&#39;</span><span class="o">:</span> <span class="n">batch_outputs</span><span class="err">}</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">batch_outputs</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Expect x to be a non-empty array or dataset.&#39;</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_end</span><span class="p">()</span>

    <span class="n">all_outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span><span class="n">batch_outputs</span><span class="p">,</span> <span class="n">concat</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_generator_1">predict_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates predictions for the input samples from a data generator.</p>
<p>DEPRECATED:
  <code>Model.predict</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">predict_generator</span><span class="p">(</span><span class="k">self</span><span class="p">,</span>

                        <span class="n">generator</span><span class="p">,</span>

                        <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                        <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                        <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

                        <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

                        <span class="k">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Generates predictions for the input samples from a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.predict` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`Model.predict_generator` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `Model.predict`, which supports generators.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="k">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span>

        <span class="n">generator</span><span class="p">,</span>

        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

        <span class="k">verbose</span><span class="o">=</span><span class="k">verbose</span><span class="p">,</span>

        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_on_batch_1">predict_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns predictions for a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be: - A Numpy array (or array-like), or a list</td>
<td></td>
</tr>
<tr>
<td>of arrays (in case the model has multiple inputs). - A TensorFlow</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>tensor, or a list of tensors (in case the model has multiple inputs).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict_on_batch</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between given number of inputs and</td>
</tr>
<tr>
<td>expectations of the model.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">predict_on_batch</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Returns predictions for a single batch of samples.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        x: Input data. It could be: - A Numpy array (or array-like), or a list</span>

<span class="ss">          of arrays (in case the model has multiple inputs). - A TensorFlow</span>

<span class="ss">          tensor, or a list of tensors (in case the model has multiple inputs).</span>

<span class="ss">    Returns:</span>

<span class="ss">        Numpy array(s) of predictions.</span>

<span class="ss">    Raises:</span>

<span class="ss">        RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.</span>

<span class="ss">        ValueError: In case of mismatch between given number of inputs and</span>

<span class="ss">          expectations of the model.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="k">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict_on_batch&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;predict_on_batch&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="k">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="k">scope</span><span class="p">():</span>

      <span class="n">iterator</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

      <span class="k">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_step_1">predict_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference and returns the boxes, scores and labels associated.</p>
<p>Background is discarded the max and argmax operation are performed.
It means that if background was predicted the second maximum score would
be outputed.</p>
<p>Example: background + 3 classes
[0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</p>
<p>"To optimize for AP, we override the prediction of these slots
with the second highest scoring class, using the corresponding confidence"
Part 4. Experiments of Object Detection with Transformers</p>
<p>Returns:</p>
<ul>
<li><em>boxes</em>: A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]
containing the boxes with the coordinates between 0 and 1.</li>
<li><em>scores</em>: A Tensor of shape [batch_size, self.num_queries] containing
the score of the boxes.</li>
<li><em>classes</em>: A Tensor of shape [batch_size, self.num_queries]
containing the class of the boxes [0, num_classes).</li>
</ul>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">predict_step</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="k">data</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Perform an inference and returns the boxes, scores and labels associated.</span>

<span class="ss">        Background is discarded the max and argmax operation are performed.</span>

<span class="ss">        It means that if background was predicted the second maximum score would</span>

<span class="ss">        be outputed.</span>

<span class="ss">        Example: background + 3 classes</span>

<span class="ss">        [0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</span>

<span class="ss">        &quot;</span><span class="k">To</span> <span class="n">optimize</span> <span class="k">for</span> <span class="n">AP</span><span class="p">,</span> <span class="n">we</span> <span class="n">override</span> <span class="n">the</span> <span class="n">prediction</span> <span class="k">of</span> <span class="n">these</span> <span class="n">slots</span>

        <span class="k">with</span> <span class="n">the</span> <span class="k">second</span> <span class="n">highest</span> <span class="n">scoring</span> <span class="k">class</span><span class="p">,</span> <span class="k">using</span> <span class="n">the</span> <span class="k">corresponding</span> <span class="n">confidence</span><span class="ss">&quot;</span>

<span class="ss">        Part 4. Experiments of Object Detection with Transformers</span>

<span class="ss">        Returns:</span>

<span class="ss">        - *boxes*: A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]</span>

<span class="ss">        containing the boxes with the coordinates between 0 and 1.</span>

<span class="ss">        - *scores*: A Tensor of shape [batch_size, self.num_queries] containing</span>

<span class="ss">        the score of the boxes.</span>

<span class="ss">        - *classes*: A Tensor of shape [batch_size, self.num_queries]</span>

<span class="ss">        containing the class of the boxes [0, num_classes).</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="k">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="k">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="k">False</span><span class="p">)</span>

        <span class="n">boxes_without_padding</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">detr_postprocessing</span><span class="p">(</span>

            <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="p">.</span><span class="n">BOXES</span><span class="p">],</span>

            <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="p">.</span><span class="n">SCORES</span><span class="p">],</span>

            <span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES_INFO</span><span class="p">],</span>

            <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span>

        <span class="p">)</span>

        <span class="k">return</span> <span class="n">boxes_without_padding</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span>
</code></pre></div>

</details>
<h4 id="reset_metrics_1">reset_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_metrics</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Resets the state of all the metrics in the model.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>inputs = tf.keras.layers.Input(shape=(3,))
outputs = tf.keras.layers.Dense(2)(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
model.compile(optimizer="Adam", loss="mse", metrics=["mae"])</p>
<p>x = np.random.random((2, 3))
y = np.random.randint(0, 2, (2, 2))
_ = model.fit(x, y, verbose=0)
assert all(float(m.result()) for m in model.metrics)</p>
<p>model.reset_metrics()
assert all(float(m.result()) == 0 for m in model.metrics)</p>
</blockquote>
</blockquote>
</blockquote>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">reset_metrics</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Resets the state of all the metrics in the model.</span>

<span class="ss">    Examples:</span>

<span class="ss">    &gt;&gt;&gt; inputs = tf.keras.layers.Input(shape=(3,))</span>

<span class="ss">    &gt;&gt;&gt; outputs = tf.keras.layers.Dense(2)(inputs)</span>

<span class="ss">    &gt;&gt;&gt; model = tf.keras.models.Model(inputs=inputs, outputs=outputs)</span>

<span class="ss">    &gt;&gt;&gt; model.compile(optimizer=&quot;</span><span class="n">Adam</span><span class="ss">&quot;, loss=&quot;</span><span class="n">mse</span><span class="ss">&quot;, metrics=[&quot;</span><span class="n">mae</span><span class="ss">&quot;])</span>

<span class="ss">    &gt;&gt;&gt; x = np.random.random((2, 3))</span>

<span class="ss">    &gt;&gt;&gt; y = np.random.randint(0, 2, (2, 2))</span>

<span class="ss">    &gt;&gt;&gt; _ = model.fit(x, y, verbose=0)</span>

<span class="ss">    &gt;&gt;&gt; assert all(float(m.result()) for m in model.metrics)</span>

<span class="ss">    &gt;&gt;&gt; model.reset_metrics()</span>

<span class="ss">    &gt;&gt;&gt; assert all(float(m.result()) == 0 for m in model.metrics)</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="k">for</span> <span class="n">m</span> <span class="k">in</span> <span class="k">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">:</span>

      <span class="n">m</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="reset_states_1">reset_states</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_states</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">reset_states</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="k">for</span> <span class="n">layer</span> <span class="k">in</span> <span class="k">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;reset_states&#39;</span><span class="p">)</span> <span class="k">and</span> <span class="n">getattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;stateful&#39;</span><span class="p">,</span> <span class="k">False</span><span class="p">):</span>

        <span class="n">layer</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="save_1">save</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">signatures</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">save_traces</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p>
<p>Please see <code>tf.keras.models.save_model</code> or the
<a href="https://keras.io/guides/serialization_and_saving/">Serialization and Saving guide</a>
for details.</p>
<p>Arguments:
    filepath: String, PathLike, path to SavedModel or H5 file to save the
        model.
    overwrite: Whether to silently overwrite any existing file at the
        target location, or provide the user with a manual prompt.
    include_optimizer: If True, save optimizer's state together.
    save_format: Either <code>'tf'</code> or <code>'h5'</code>, indicating whether to save the
        model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,
        and 'h5' in TF 1.X.
    signatures: Signatures to save with the SavedModel. Applicable to the
        'tf' format only. Please see the <code>signatures</code> argument in
        <code>tf.saved_model.save</code> for details.
    options: (only applies to SavedModel format)
        <code>tf.saved_model.SaveOptions</code> object that specifies options for
        saving to SavedModel.
    save_traces: (only applies to SavedModel format) When enabled, the
        SavedModel will store the function traces for each layer. This
        can be disabled, so that only the configs of each layer are stored.
        Defaults to <code>True</code>. Disabling this will decrease serialization time
        and reduce file size, but it requires that all custom layers/models
        implement a <code>get_config()</code> method.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>  <span class="c1"># creates a HDF5 file &#39;my_model.h5&#39;</span>
<span class="k">del</span> <span class="n">model</span>  <span class="c1"># deletes the existing model</span>

<span class="c1"># returns a compiled model</span>
<span class="c1"># identical to the previous one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">save</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

           <span class="n">filepath</span><span class="p">,</span>

           <span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

           <span class="n">include_optimizer</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

           <span class="n">save_format</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

           <span class="n">signatures</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

           <span class="k">options</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

           <span class="n">save_traces</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span>

    <span class="c1"># pylint: disable=line-too-long</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Saves the model to Tensorflow SavedModel or a single HDF5 file.</span>

<span class="s2">    Please see `tf.keras.models.save_model` or the</span>

<span class="s2">    [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)</span>

<span class="s2">    for details.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        filepath: String, PathLike, path to SavedModel or H5 file to save the</span>

<span class="s2">            model.</span>

<span class="s2">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="s2">            target location, or provide the user with a manual prompt.</span>

<span class="s2">        include_optimizer: If True, save optimizer&#39;s state together.</span>

<span class="s2">        save_format: Either `&#39;tf&#39;` or `&#39;h5&#39;`, indicating whether to save the</span>

<span class="s2">            model to Tensorflow SavedModel or HDF5. Defaults to &#39;tf&#39; in TF 2.X,</span>

<span class="s2">            and &#39;h5&#39; in TF 1.X.</span>

<span class="s2">        signatures: Signatures to save with the SavedModel. Applicable to the</span>

<span class="s2">            &#39;tf&#39; format only. Please see the `signatures` argument in</span>

<span class="s2">            `tf.saved_model.save` for details.</span>

<span class="s2">        options: (only applies to SavedModel format)</span>

<span class="s2">            `tf.saved_model.SaveOptions` object that specifies options for</span>

<span class="s2">            saving to SavedModel.</span>

<span class="s2">        save_traces: (only applies to SavedModel format) When enabled, the</span>

<span class="s2">            SavedModel will store the function traces for each layer. This</span>

<span class="s2">            can be disabled, so that only the configs of each layer are stored.</span>

<span class="s2">            Defaults to `True`. Disabling this will decrease serialization time</span>

<span class="s2">            and reduce file size, but it requires that all custom layers/models</span>

<span class="s2">            implement a `get_config()` method.</span>

<span class="s2">    Example:</span>

<span class="s2">    ```python</span>

<span class="s2">    from keras.models import load_model</span>

<span class="s2">    model.save(&#39;my_model.h5&#39;)  # creates a HDF5 file &#39;my_model.h5&#39;</span>

<span class="s2">    del model  # deletes the existing model</span>

<span class="s2">    # returns a compiled model</span>

<span class="s2">    # identical to the previous one</span>

<span class="s2">    model = load_model(&#39;my_model.h5&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="c1"># pylint: enable=line-too-long</span>

    <span class="n">save</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="p">,</span> <span class="n">save_format</span><span class="p">,</span>

                    <span class="n">signatures</span><span class="p">,</span> <span class="k">options</span><span class="p">,</span> <span class="n">save_traces</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="save_weights_1">save_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves all layer weights.</p>
<p>Either saves in HDF5 or in TensorFlow format based on the <code>save_format</code>
argument.</p>
<p>When saving in HDF5 format, the weight file has:
  - <code>layer_names</code> (attribute), a list of strings
      (ordered names of model layers).
  - For every layer, a <code>group</code> named <code>layer.name</code>
      - For every such layer group, a group attribute <code>weight_names</code>,
          a list of strings
          (ordered names of weights tensor of the layer).
      - For every weight in the layer, a dataset
          storing the weight value, named after the weight tensor.</p>
<p>When saving in TensorFlow format, all objects referenced by the network are
saved in the same format as <code>tf.train.Checkpoint</code>, including any <code>Layer</code>
instances or <code>Optimizer</code> instances assigned to object attributes. For
networks constructed from inputs and outputs using <code>tf.keras.Model(inputs,
outputs)</code>, <code>Layer</code> instances used by the network are tracked/saved
automatically. For user-defined classes which inherit from <code>tf.keras.Model</code>,
<code>Layer</code> instances must be assigned to object attributes, typically in the
constructor. See the documentation of <code>tf.train.Checkpoint</code> and
<code>tf.keras.Model</code> for details.</p>
<p>While the formats are the same, do not mix <code>save_weights</code> and
<code>tf.train.Checkpoint</code>. Checkpoints saved by <code>Model.save_weights</code> should be
loaded using <code>Model.load_weights</code>. Checkpoints saved using
<code>tf.train.Checkpoint.save</code> should be restored using the corresponding
<code>tf.train.Checkpoint.restore</code>. Prefer <code>tf.train.Checkpoint</code> over
<code>save_weights</code> for training checkpoints.</p>
<p>The TensorFlow format matches objects and variables by starting at a root
object, <code>self</code> for <code>save_weights</code>, and greedily matching attribute
names. For <code>Model.save</code> this is the <code>Model</code>, and for <code>Checkpoint.save</code> this
is the <code>Checkpoint</code> even if the <code>Checkpoint</code> has a model attached. This
means saving a <code>tf.keras.Model</code> using <code>save_weights</code> and loading into a
<code>tf.train.Checkpoint</code> with a <code>Model</code> attached (or vice versa) will not match
the <code>Model</code>'s variables. See the <a href="https://www.tensorflow.org/guide/checkpoint">guide to training
checkpoints</a> for details
on the TensorFlow format.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String or PathLike, path to the file to save the weights to.</td>
<td></td>
</tr>
<tr>
<td>When saving in TensorFlow format, this is the prefix used for</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>checkpoint files (multiple files are generated). Note that the '.h5'</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>suffix causes weights to be saved in HDF5 format.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>overwrite</td>
<td>None</td>
<td>Whether to silently overwrite any existing file at the</td>
<td></td>
</tr>
<tr>
<td>target location, or provide the user with a manual prompt.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>save_format</td>
<td>None</td>
<td>Either 'tf' or 'h5'. A <code>filepath</code> ending in '.h5' or</td>
<td></td>
</tr>
<tr>
<td>'.keras' will default to HDF5 if <code>save_format</code> is <code>None</code>. Otherwise</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>None</code> defaults to 'tf'.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies</td>
<td></td>
</tr>
<tr>
<td>options for saving weights.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If h5py is not available when attempting to save in HDF5</td>
</tr>
<tr>
<td>format.</td>
<td></td>
</tr>
<tr>
<td>ValueError</td>
<td>For invalid/unknown format arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

                   <span class="n">filepath</span><span class="p">,</span>

                   <span class="n">overwrite</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

                   <span class="n">save_format</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

                   <span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Saves all layer weights.</span>

<span class="sd">    Either saves in HDF5 or in TensorFlow format based on the `save_format`</span>

<span class="sd">    argument.</span>

<span class="sd">    When saving in HDF5 format, the weight file has:</span>

<span class="sd">      - `layer_names` (attribute), a list of strings</span>

<span class="sd">          (ordered names of model layers).</span>

<span class="sd">      - For every layer, a `group` named `layer.name`</span>

<span class="sd">          - For every such layer group, a group attribute `weight_names`,</span>

<span class="sd">              a list of strings</span>

<span class="sd">              (ordered names of weights tensor of the layer).</span>

<span class="sd">          - For every weight in the layer, a dataset</span>

<span class="sd">              storing the weight value, named after the weight tensor.</span>

<span class="sd">    When saving in TensorFlow format, all objects referenced by the network are</span>

<span class="sd">    saved in the same format as `tf.train.Checkpoint`, including any `Layer`</span>

<span class="sd">    instances or `Optimizer` instances assigned to object attributes. For</span>

<span class="sd">    networks constructed from inputs and outputs using `tf.keras.Model(inputs,</span>

<span class="sd">    outputs)`, `Layer` instances used by the network are tracked/saved</span>

<span class="sd">    automatically. For user-defined classes which inherit from `tf.keras.Model`,</span>

<span class="sd">    `Layer` instances must be assigned to object attributes, typically in the</span>

<span class="sd">    constructor. See the documentation of `tf.train.Checkpoint` and</span>

<span class="sd">    `tf.keras.Model` for details.</span>

<span class="sd">    While the formats are the same, do not mix `save_weights` and</span>

<span class="sd">    `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be</span>

<span class="sd">    loaded using `Model.load_weights`. Checkpoints saved using</span>

<span class="sd">    `tf.train.Checkpoint.save` should be restored using the corresponding</span>

<span class="sd">    `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over</span>

<span class="sd">    `save_weights` for training checkpoints.</span>

<span class="sd">    The TensorFlow format matches objects and variables by starting at a root</span>

<span class="sd">    object, `self` for `save_weights`, and greedily matching attribute</span>

<span class="sd">    names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this</span>

<span class="sd">    is the `Checkpoint` even if the `Checkpoint` has a model attached. This</span>

<span class="sd">    means saving a `tf.keras.Model` using `save_weights` and loading into a</span>

<span class="sd">    `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match</span>

<span class="sd">    the `Model`&#39;s variables. See the [guide to training</span>

<span class="sd">    checkpoints](https://www.tensorflow.org/guide/checkpoint) for details</span>

<span class="sd">    on the TensorFlow format.</span>

<span class="sd">    Arguments:</span>

<span class="sd">        filepath: String or PathLike, path to the file to save the weights to.</span>

<span class="sd">            When saving in TensorFlow format, this is the prefix used for</span>

<span class="sd">            checkpoint files (multiple files are generated). Note that the &#39;.h5&#39;</span>

<span class="sd">            suffix causes weights to be saved in HDF5 format.</span>

<span class="sd">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="sd">            target location, or provide the user with a manual prompt.</span>

<span class="sd">        save_format: Either &#39;tf&#39; or &#39;h5&#39;. A `filepath` ending in &#39;.h5&#39; or</span>

<span class="sd">            &#39;.keras&#39; will default to HDF5 if `save_format` is `None`. Otherwise</span>

<span class="sd">            `None` defaults to &#39;tf&#39;.</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for saving weights.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If h5py is not available when attempting to save in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">        ValueError: For invalid/unknown format arguments.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span>

    <span class="n">filepath</span> <span class="o">=</span> <span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

    <span class="n">filepath_is_h5</span> <span class="o">=</span> <span class="n">_is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">filepath_is_h5</span><span class="p">:</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;tf&#39;</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="n">user_format</span> <span class="o">=</span> <span class="n">save_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

      <span class="k">if</span> <span class="n">user_format</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;tensorflow&#39;</span><span class="p">,</span> <span class="s1">&#39;tf&#39;</span><span class="p">):</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;tf&#39;</span>

      <span class="k">elif</span> <span class="n">user_format</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;hdf5&#39;</span><span class="p">,</span> <span class="s1">&#39;h5&#39;</span><span class="p">,</span> <span class="s1">&#39;keras&#39;</span><span class="p">):</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

            <span class="s1">&#39;Unknown format &quot;</span><span class="si">%s</span><span class="s1">&quot;. Was expecting one of {&quot;tf&quot;, &quot;h5&quot;}.&#39;</span> <span class="o">%</span> <span class="p">(</span>

                <span class="n">save_format</span><span class="p">,))</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span> <span class="ow">and</span> <span class="n">filepath_is_h5</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="p">(</span><span class="s1">&#39;save_weights got save_format=&quot;tf&quot;/&quot;tensorflow&quot;, but the &#39;</span>

           <span class="s1">&#39;filepath (&quot;</span><span class="si">%s</span><span class="s1">&quot;) looks like an HDF5 file. Omit the &quot;.h5&quot;/&quot;.keras&quot; &#39;</span>

           <span class="s1">&#39;when saving in TensorFlow format.&#39;</span><span class="p">)</span>

          <span class="o">%</span> <span class="n">filepath</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;h5&#39;</span> <span class="ow">and</span> <span class="n">h5py</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ImportError</span><span class="p">(</span>

          <span class="s1">&#39;`save_weights` requires h5py when saving in hdf5.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span><span class="p">:</span>

      <span class="n">check_filepath</span> <span class="o">=</span> <span class="n">filepath</span> <span class="o">+</span> <span class="s1">&#39;.index&#39;</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="n">check_filepath</span> <span class="o">=</span> <span class="n">filepath</span>

    <span class="c1"># If file exists and should not be overwritten:</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">overwrite</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">):</span>

      <span class="n">proceed</span> <span class="o">=</span> <span class="n">ask_to_proceed_with_overwrite</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">)</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">proceed</span><span class="p">:</span>

        <span class="k">return</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;h5&#39;</span><span class="p">:</span>

      <span class="n">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>

        <span class="n">hdf5_format</span><span class="o">.</span><span class="n">save_weights_to_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>

        <span class="n">session</span> <span class="o">=</span> <span class="n">None</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">session</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="n">None</span><span class="p">)</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">optimizer</span>

          <span class="ow">and</span> <span class="ow">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">trackable</span><span class="o">.</span><span class="n">Trackable</span><span class="p">)):</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>

            <span class="p">(</span><span class="s1">&#39;This model was compiled with a Keras optimizer (</span><span class="si">%s</span><span class="s1">) but is being &#39;</span>

             <span class="s1">&#39;saved in TensorFlow format with `save_weights`. The model</span><span class="se">\&#39;</span><span class="s1">s &#39;</span>

             <span class="s1">&#39;weights will be saved, but unlike with TensorFlow optimizers in &#39;</span>

             <span class="s1">&#39;the TensorFlow format the optimizer</span><span class="se">\&#39;</span><span class="s1">s state will not be &#39;</span>

             <span class="s1">&#39;saved.</span><span class="se">\n\n</span><span class="s1">Consider using a TensorFlow optimizer from `tf.train`.&#39;</span><span class="p">)</span>

            <span class="o">%</span> <span class="p">(</span><span class="n">optimizer</span><span class="p">,))</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>

      <span class="c1"># Record this checkpoint so it&#39;s visible from tf.train.latest_checkpoint.</span>

      <span class="n">checkpoint_management</span><span class="o">.</span><span class="n">update_checkpoint_state_internal</span><span class="p">(</span>

          <span class="n">save_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">filepath</span><span class="p">),</span>

          <span class="n">model_checkpoint_path</span><span class="o">=</span><span class="n">filepath</span><span class="p">,</span>

          <span class="n">save_relative_paths</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

          <span class="n">all_model_checkpoint_paths</span><span class="o">=</span><span class="p">[</span><span class="n">filepath</span><span class="p">])</span>
</code></pre></div>

</details>
<h4 id="set_weights_1">set_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">weights</span>
<span class="p">)</span>
</code></pre></div>

<p>Sets the weights of the layer, from Numpy arrays.</p>
<p>The weights of a layer represent the state of the layer. This function
sets the weight values from numpy arrays. The weight values should be
passed in the order they are created by the layer. Note that the layer's
weights must be instantiated before calling this function by calling
the layer.</p>
<p>For example, a Dense layer returns a list of two values-- per-output
weights and the bias value. These can be used to set the weights of another
Dense layer:</p>
<blockquote>
<blockquote>
<blockquote>
<p>a = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(1.))
a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))
a.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]
b = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(2.))
b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))
b.get_weights()
[array([[2.],
       [2.],
       [2.]], dtype=float32), array([0.], dtype=float32)]
b.set_weights(a.get_weights())
b.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>weights</td>
<td>None</td>
<td>a list of Numpy arrays. The number</td>
<td></td>
</tr>
<tr>
<td>of arrays and their shape must match</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>number of the dimensions of the weights</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of the layer (i.e. it should match the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>output of <code>get_weights</code>).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>If the provided weights list does not match the</td>
</tr>
<tr>
<td>layer's specifications.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Sets the weights of the layer, from Numpy arrays.</span>

<span class="sd">    The weights of a layer represent the state of the layer. This function</span>

<span class="sd">    sets the weight values from numpy arrays. The weight values should be</span>

<span class="sd">    passed in the order they are created by the layer. Note that the layer&#39;s</span>

<span class="sd">    weights must be instantiated before calling this function by calling</span>

<span class="sd">    the layer.</span>

<span class="sd">    For example, a Dense layer returns a list of two values-- per-output</span>

<span class="sd">    weights and the bias value. These can be used to set the weights of another</span>

<span class="sd">    Dense layer:</span>

<span class="sd">    &gt;&gt;&gt; a = tf.keras.layers.Dense(1,</span>

<span class="sd">    ...   kernel_initializer=tf.constant_initializer(1.))</span>

<span class="sd">    &gt;&gt;&gt; a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))</span>

<span class="sd">    &gt;&gt;&gt; a.get_weights()</span>

<span class="sd">    [array([[1.],</span>

<span class="sd">           [1.],</span>

<span class="sd">           [1.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    &gt;&gt;&gt; b = tf.keras.layers.Dense(1,</span>

<span class="sd">    ...   kernel_initializer=tf.constant_initializer(2.))</span>

<span class="sd">    &gt;&gt;&gt; b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))</span>

<span class="sd">    &gt;&gt;&gt; b.get_weights()</span>

<span class="sd">    [array([[2.],</span>

<span class="sd">           [2.],</span>

<span class="sd">           [2.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    &gt;&gt;&gt; b.set_weights(a.get_weights())</span>

<span class="sd">    &gt;&gt;&gt; b.get_weights()</span>

<span class="sd">    [array([[1.],</span>

<span class="sd">           [1.],</span>

<span class="sd">           [1.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    Arguments:</span>

<span class="sd">        weights: a list of Numpy arrays. The number</span>

<span class="sd">            of arrays and their shape must match</span>

<span class="sd">            number of the dimensions of the weights</span>

<span class="sd">            of the layer (i.e. it should match the</span>

<span class="sd">            output of `get_weights`).</span>

<span class="sd">    Raises:</span>

<span class="sd">        ValueError: If the provided weights list does not match the</span>

<span class="sd">            layer&#39;s specifications.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>

    <span class="n">expected_num_weights</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">TrackableWeightHandler</span><span class="p">):</span>

        <span class="n">expected_num_weights</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">num_tensors</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">expected_num_weights</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">expected_num_weights</span> <span class="o">!=</span> <span class="n">len</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="s1">&#39;You called `set_weights(weights)` on layer &quot;</span><span class="si">%s</span><span class="s1">&quot; &#39;</span>

          <span class="s1">&#39;with a weight list of length </span><span class="si">%s</span><span class="s1">, but the layer was &#39;</span>

          <span class="s1">&#39;expecting </span><span class="si">%s</span><span class="s1"> weights. Provided weights: </span><span class="si">%s</span><span class="s1">...&#39;</span> <span class="o">%</span>

          <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">len</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">expected_num_weights</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">weights</span><span class="p">)[:</span><span class="mi">50</span><span class="p">]))</span>

    <span class="n">weight_index</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">weight_value_tuples</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">TrackableWeightHandler</span><span class="p">):</span>

        <span class="n">num_tensors</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">num_tensors</span>

        <span class="n">tensors</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="p">:</span><span class="n">weight_index</span> <span class="o">+</span> <span class="n">num_tensors</span><span class="p">]</span>

        <span class="n">param</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>

        <span class="n">weight_index</span> <span class="o">+=</span> <span class="n">num_tensors</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">weight</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="p">]</span>

        <span class="n">ref_shape</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">ref_shape</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>

          <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

              <span class="s1">&#39;Layer weight shape </span><span class="si">%s</span><span class="s1"> not compatible with provided weight &#39;</span>

              <span class="s1">&#39;shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ref_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

        <span class="n">weight_value_tuples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">param</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>

        <span class="n">weight_index</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">backend</span><span class="o">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">weight_value_tuples</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="summary_1">summary</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">line_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">print_fn</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Prints a string summary of the network.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>line_length</td>
<td>None</td>
<td>Total length of printed lines</td>
<td></td>
</tr>
<tr>
<td>(e.g. set this to adapt the display to different</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>terminal window sizes).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>positions</td>
<td>None</td>
<td>Relative or absolute positions of log elements</td>
<td></td>
</tr>
<tr>
<td>in each line. If not provided,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>defaults to <code>[.33, .55, .67, 1.]</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>print_fn</td>
<td>None</td>
<td>Print function to use. Defaults to <code>print</code>.</td>
<td></td>
</tr>
<tr>
<td>It will be called on each line of the summary.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>You can set it to a custom function</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>in order to capture the string summary.</td>
<td><code>print</code></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if <code>summary()</code> is called before the model is built.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">line_length</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="n">positions</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="n">print_fn</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Prints a string summary of the network.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        line_length: Total length of printed lines</span>

<span class="s2">            (e.g. set this to adapt the display to different</span>

<span class="s2">            terminal window sizes).</span>

<span class="s2">        positions: Relative or absolute positions of log elements</span>

<span class="s2">            in each line. If not provided,</span>

<span class="s2">            defaults to `[.33, .55, .67, 1.]`.</span>

<span class="s2">        print_fn: Print function to use. Defaults to `print`.</span>

<span class="s2">            It will be called on each line of the summary.</span>

<span class="s2">            You can set it to a custom function</span>

<span class="s2">            in order to capture the string summary.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: if `summary()` is called before the model is built.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;This model has not yet been built. &#39;</span>

                       <span class="s1">&#39;Build the model first by calling `build()` or calling &#39;</span>

                       <span class="s1">&#39;`fit()` with some data, or specify &#39;</span>

                       <span class="s1">&#39;an `input_shape` argument in the first layer(s) for &#39;</span>

                       <span class="s1">&#39;automatic build.&#39;</span><span class="p">)</span>

    <span class="n">layer_utils</span><span class="p">.</span><span class="n">print_summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                              <span class="n">line_length</span><span class="o">=</span><span class="n">line_length</span><span class="p">,</span>

                              <span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span>

                              <span class="n">print_fn</span><span class="o">=</span><span class="n">print_fn</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="test_on_batch_1">test_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Test the model on a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be: - A Numpy array (or array-like), or a list</td>
<td></td>
</tr>
<tr>
<td>of arrays (in case the model has multiple inputs). - A TensorFlow</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>tensor, or a list of tensors (in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A dict mapping input names to the corresponding array/tensors, if</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the model has named inputs.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy</td>
<td></td>
</tr>
<tr>
<td>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional array of the same length as x, containing</td>
<td></td>
</tr>
<tr>
<td>weights to apply to the model's loss for each sample. In the case of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>temporal data, you can pass a 2D array with shape (samples,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sequence_length), to apply a different weight to every timestep of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>every sample.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>reset_metrics</td>
<td>None</td>
<td>If <code>True</code>, the metrics returned will be only for this</td>
<td></td>
</tr>
<tr>
<td>batch. If <code>False</code>, the metrics will be statefully accumulated across</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>batches.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,</td>
<td></td>
</tr>
<tr>
<td>with each key being the name of the metric. If <code>False</code>, they are</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returned as a list.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)</td>
</tr>
<tr>
<td>or list of scalars (if the model has multiple outputs</td>
<td></td>
</tr>
<tr>
<td>and/or metrics). The attribute <code>model.metrics_names</code> will give you</td>
<td></td>
</tr>
<tr>
<td>the display labels for the scalar outputs.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.test_on_batch</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of invalid user-provided arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">test_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                    <span class="n">x</span><span class="p">,</span>

                    <span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

                    <span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Test the model on a single batch of samples.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input data. It could be: - A Numpy array (or array-like), or a list</span>

<span class="s2">          of arrays (in case the model has multiple inputs). - A TensorFlow</span>

<span class="s2">          tensor, or a list of tensors (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors, if</span>

<span class="s2">          the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.</span>

<span class="s2">        ValueError: In case of invalid user-provided arguments.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="n">iterator</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>

                                                    <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">reset_metrics</span><span class="o">:</span>

      <span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

    <span class="k">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_dict</span><span class="o">:</span>

      <span class="k">return</span> <span class="k">logs</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">results</span> <span class="o">=</span> <span class="err">[</span><span class="k">logs</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="k">name</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">for</span> <span class="k">name</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="err">]</span>

      <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

        <span class="k">return</span> <span class="n">results</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

      <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

</details>
<h4 id="test_step_1">test_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="p">#</span> <span class="n">To</span> <span class="n">compute</span> <span class="n">the</span> <span class="n">loss</span> <span class="n">we</span> <span class="n">need</span> <span class="n">to</span> <span class="n">get</span> <span class="n">the</span> <span class="n">results</span> <span class="n">of</span> <span class="n">each</span> <span class="n">decoder</span> <span class="n">layer</span>

        <span class="p">#</span> <span class="n">Setting</span> <span class="n">training</span> <span class="n">to</span> <span class="n">True</span> <span class="n">will</span> <span class="n">provide</span> <span class="n">it</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>

        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mh">1</span><span class="o">:</span><span class="mh">3</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">compute_dtype</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">None</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">loss_metric</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="p">.</span><span class="nl">name:</span> <span class="n">m</span><span class="p">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="n">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">}</span>
</code></pre></div>

</details>
<h4 id="to_json_1">to_json</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a JSON string containing the network configuration.</p>
<p>To load a network from a JSON save file, use
<code>keras.models.model_from_json(json_string, custom_objects={})</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments</td>
<td></td>
</tr>
<tr>
<td>to be passed to <code>json.dumps()</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A JSON string.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Returns a JSON string containing the network configuration.</span>

<span class="sd">    To load a network from a JSON save file, use</span>

<span class="sd">    `keras.models.model_from_json(json_string, custom_objects={})`.</span>

<span class="sd">    Arguments:</span>

<span class="sd">        **kwargs: Additional keyword arguments</span>

<span class="sd">            to be passed to `json.dumps()`.</span>

<span class="sd">    Returns:</span>

<span class="sd">        A JSON string.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_updated_config</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>

        <span class="n">model_config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">json_utils</span><span class="o">.</span><span class="n">get_json_type</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="to_yaml_1">to_yaml</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_yaml</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a yaml string containing the network configuration.</p>
<p>To load a network from a yaml save file, use
<code>keras.models.model_from_yaml(yaml_string, custom_objects={})</code>.</p>
<p><code>custom_objects</code> should be a dictionary mapping
the names of custom losses / layers / etc to the corresponding
functions / classes.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments</td>
<td></td>
</tr>
<tr>
<td>to be passed to <code>yaml.dump()</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A YAML string.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>if yaml module is not found.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">to_yaml</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns a yaml string containing the network configuration.</span>

<span class="s2">    To load a network from a yaml save file, use</span>

<span class="s2">    `keras.models.model_from_yaml(yaml_string, custom_objects={})`.</span>

<span class="s2">    `custom_objects` should be a dictionary mapping</span>

<span class="s2">    the names of custom losses / layers / etc to the corresponding</span>

<span class="s2">    functions / classes.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        **kwargs: Additional keyword arguments</span>

<span class="s2">            to be passed to `yaml.dump()`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A YAML string.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ImportError: if yaml module is not found.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">yaml</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ImportError</span><span class="p">(</span>

          <span class="s1">&#39;Requires yaml module installed (`pip install pyyaml`).&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">yaml</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_updated_config</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="train_on_batch_1">train_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Runs a single gradient update on a single batch of data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:</td>
<td></td>
</tr>
<tr>
<td>- A Numpy array (or array-like), or a list of arrays</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A TensorFlow tensor, or a list of tensors</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A dict mapping input names to the corresponding array/tensors,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>if the model has named inputs.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy</td>
<td></td>
</tr>
<tr>
<td>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional array of the same length as x, containing</td>
<td></td>
</tr>
<tr>
<td>weights to apply to the model's loss for each sample. In the case of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>temporal data, you can pass a 2D array with shape (samples,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sequence_length), to apply a different weight to every timestep of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>every sample.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>class_weight</td>
<td>None</td>
<td>Optional dictionary mapping class indices (integers) to a</td>
<td></td>
</tr>
<tr>
<td>weight (float) to apply to the model's loss for the samples from this</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>class during training. This can be useful to tell the model to "pay</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>more attention" to samples from an under-represented class.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>reset_metrics</td>
<td>None</td>
<td>If <code>True</code>, the metrics returned will be only for this</td>
<td></td>
</tr>
<tr>
<td>batch. If <code>False</code>, the metrics will be statefully accumulated across</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>batches.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,</td>
<td></td>
</tr>
<tr>
<td>with each key being the name of the metric. If <code>False</code>, they are</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returned as a list.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar training loss</td>
</tr>
<tr>
<td>(if the model has a single output and no metrics)</td>
<td></td>
</tr>
<tr>
<td>or list of scalars (if the model has multiple outputs</td>
<td></td>
</tr>
<tr>
<td>and/or metrics). The attribute <code>model.metrics_names</code> will give you</td>
<td></td>
</tr>
<tr>
<td>the display labels for the scalar outputs.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.train_on_batch</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of invalid user-provided arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">train_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                     <span class="n">x</span><span class="p">,</span>

                     <span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                     <span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                     <span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                     <span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

                     <span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single gradient update on a single batch of data.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">              if the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        class_weight: Optional dictionary mapping class indices (integers) to a</span>

<span class="s2">          weight (float) to apply to the model&#39;s loss for the samples from this</span>

<span class="s2">          class during training. This can be useful to tell the model to &quot;</span><span class="n">pay</span>

          <span class="n">more</span> <span class="n">attention</span><span class="s2">&quot; to samples from an under-represented class.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar training loss</span>

<span class="s2">        (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">      RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.</span>

<span class="s2">      ValueError: In case of invalid user-provided arguments.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">(),</span> <span class="err">\</span>

         <span class="n">training_utils</span><span class="p">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

      <span class="n">iterator</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>

                                                    <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span>

                                                    <span class="n">class_weight</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_train_function</span><span class="p">()</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">reset_metrics</span><span class="o">:</span>

      <span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

    <span class="k">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_dict</span><span class="o">:</span>

      <span class="k">return</span> <span class="k">logs</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">results</span> <span class="o">=</span> <span class="err">[</span><span class="k">logs</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="k">name</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">for</span> <span class="k">name</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="err">]</span>

      <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

        <span class="k">return</span> <span class="n">results</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

      <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

</details>
<h4 id="train_step_1">train_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>

            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>

            <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">None</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span> <span class="n">tape</span><span class="o">=</span><span class="n">tape</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span>
</code></pre></div>

</details>
<h3 id="detrresnet50pytorch">DeTrResnet50Pytorch</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">DeTrResnet50Pytorch</span><span class="p">(</span>
    <span class="n">num_classes</span><span class="p">,</span>
    <span class="n">num_queries</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<h4 id="attributes_2">Attributes</h4>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>num_classes</td>
<td>None</td>
<td>The number of classes of your dataset</td>
<td></td>
</tr>
<tr>
<td>(<strong>do not include the background class</strong> it is handle for you)</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>backbone</td>
<td>None</td>
<td>A vision model like ResNet50.</td>
<td>None</td>
</tr>
<tr>
<td>num_queries</td>
<td>None</td>
<td>number of object queries, ie detection slot.</td>
<td></td>
</tr>
<tr>
<td>This is the maximal number of objects</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>DETR can detect in a single image. For COCO, we recommend 100 queries.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Call arguments: | None |
| inputs | None | Tuple
1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]
2. image_informations: A 1D tensor of float32 and shape [(height, width),].
    It contains the shape of the image without any padding.
3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None]
    composed of 0 and 1 which allows to know where a padding has been applied. | None |
| training | None | Is automatically set to <code>True</code> in train mode
Call returns: | None |
| logits | None | A Tensor of shape [batch_size, h, num_classes + 1] class logits | None |
| boxes | None | A Tensor of shape [batch_size, h, 4]
where h is num_queries * transformer_decoder.transformer_num_layers if
training is true and num_queries otherwise. | None |</p>
<h4 id="ancestors-in-mro_2">Ancestors (in MRO)</h4>
<ul>
<li>kerod.model.detr.DeTr</li>
<li>tensorflow.python.keras.engine.training.Model</li>
<li>tensorflow.python.keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>tensorflow.python.keras.utils.version_utils.LayerVersionSelector</li>
<li>tensorflow.python.keras.utils.version_utils.ModelVersionSelector</li>
</ul>
<h4 id="static-methods_2">Static methods</h4>
<h4 id="from_config_2">from_config</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span>
    <span class="n">config</span><span class="p">,</span>
    <span class="n">custom_objects</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a layer from its config.</p>
<p>This method is the reverse of <code>get_config</code>,
capable of instantiating the same layer from the config
dictionary. It does not handle layer connectivity
(handled by Network), nor weights (handled by <code>set_weights</code>).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>config</td>
<td>None</td>
<td>A Python dictionary, typically the</td>
<td></td>
</tr>
<tr>
<td>output of get_config.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nd">@classmethod</span>

  <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>

    <span class="c1"># Since only FunctionalModel produces config, the model can only</span>

    <span class="c1"># be constructed for FunctionalModel</span>

    <span class="kn">from</span> <span class="nn">tensorflow.python.keras.engine</span> <span class="kn">import</span> <span class="n">functional</span>  <span class="c1"># pylint: disable=g-import-not-at-top</span>

    <span class="k">return</span> <span class="n">functional</span><span class="o">.</span><span class="n">Functional</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span>

        <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="n">custom_objects</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="with_name_scope_2">with_name_scope</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">with_name_scope</span><span class="p">(</span>
    <span class="n">method</span>
<span class="p">)</span>
</code></pre></div>

<p>Decorator to automatically enter the module name scope.</p>
<blockquote>
<blockquote>
<blockquote>
<p>class MyModule(tf.Module):
...   @tf.Module.with_name_scope
...   def <strong>call</strong>(self, x):
...     if not hasattr(self, 'w'):
...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))
...     return tf.matmul(x, self.w)</p>
</blockquote>
</blockquote>
</blockquote>
<p>Using the above module would produce <code>tf.Variable</code>s and <code>tf.Tensor</code>s whose
names included the module name:</p>
<blockquote>
<blockquote>
<blockquote>
<p>mod = MyModule()
mod(tf.ones([1, 2]))
<tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>
mod.w
<tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,
numpy=..., dtype=float32)></p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>method</td>
<td>None</td>
<td>The method to wrap.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The original method wrapped such that it enters the module's name scope.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@classmethod</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">with_name_scope</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span><span class="w"> </span><span class="k">method</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Decorator to automatically enter the module name scope.</span>

<span class="ss">    &gt;&gt;&gt; class MyModule(tf.Module):</span>

<span class="ss">    ...   @tf.Module.with_name_scope</span>

<span class="ss">    ...   def __call__(self, x):</span>

<span class="ss">    ...     if not hasattr(self, &#39;w&#39;):</span>

<span class="ss">    ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))</span>

<span class="ss">    ...     return tf.matmul(x, self.w)</span>

<span class="ss">    Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose</span>

<span class="ss">    names included the module name:</span>

<span class="ss">    &gt;&gt;&gt; mod = MyModule()</span>

<span class="ss">    &gt;&gt;&gt; mod(tf.ones([1, 2]))</span>

<span class="ss">    &lt;tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)&gt;</span>

<span class="ss">    &gt;&gt;&gt; mod.w</span>

<span class="ss">    &lt;tf.Variable &#39;my_module/Variable:0&#39; shape=(2, 3) dtype=float32,</span>

<span class="ss">    numpy=..., dtype=float32)&gt;</span>

<span class="ss">    Args:</span>

<span class="ss">      method: The method to wrap.</span>

<span class="ss">    Returns:</span>

<span class="ss">      The original method wrapped such that it enters the module&#39;s name scope.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">method_with_name_scope</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">with</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">name_scope</span><span class="p">:</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">method</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">tf_decorator</span><span class="p">.</span><span class="n">make_decorator</span><span class="p">(</span><span class="k">method</span><span class="p">,</span><span class="w"> </span><span class="n">method_with_name_scope</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="instance-variables_2">Instance variables</h4>
<div class="codehilite"><pre><span></span><code><span class="n">activity_regularizer</span>
</code></pre></div>

<p>Optional regularizer function for the output of this layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">compute_dtype</span>
</code></pre></div>

<p>The dtype of the layer's computations.</p>
<p>This is equivalent to <code>Layer.dtype_policy.compute_dtype</code>. Unless
mixed precision is used, this is the same as <code>Layer.dtype</code>, the dtype of
the weights.</p>
<p>Layers automatically cast their inputs to the compute dtype, which causes
computations and the output to be in the compute dtype as well. This is done
by the base Layer class in <code>Layer.__call__</code>, so you do not have to insert
these casts if implementing your own layer.</p>
<p>Layers often perform certain internal computations in higher precision when
<code>compute_dtype</code> is float16 or bfloat16 for numeric stability. The output
will still typically be float16 or bfloat16 in such cases.</p>
<div class="codehilite"><pre><span></span><code><span class="n">distribute_strategy</span>
</code></pre></div>

<p>The <code>tf.distribute.Strategy</code> this model was created under.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dtype</span>
</code></pre></div>

<p>The dtype of the layer weights.</p>
<p>This is equivalent to <code>Layer.dtype_policy.variable_dtype</code>. Unless
mixed precision is used, this is the same as <code>Layer.compute_dtype</code>, the
dtype of the layer's computations.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dtype_policy</span>
</code></pre></div>

<p>The dtype policy associated with this layer.</p>
<p>This is an instance of a <code>tf.keras.mixed_precision.Policy</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">dynamic</span>
</code></pre></div>

<p>Whether the layer is dynamic (eager-only); set in the constructor.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inbound_nodes</span>
</code></pre></div>

<p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>
<div class="codehilite"><pre><span></span><code><span class="nb">input</span>
</code></pre></div>

<p>Retrieves the input tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_mask</span>
</code></pre></div>

<p>Retrieves the input mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>
<p>Returns:
    Input mask tensor (potentially None) or list of input
    mask tensors.</p>
<p>Raises:
    AttributeError: if the layer is connected to
    more than one incoming layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_shape</span>
</code></pre></div>

<p>Retrieves the input shape(s) of a layer.</p>
<p>Only applicable if the layer has exactly one input,
i.e. if it is connected to one incoming layer, or if all inputs
have the same shape.</p>
<div class="codehilite"><pre><span></span><code><span class="n">input_spec</span>
</code></pre></div>

<p><code>InputSpec</code> instance(s) describing the input format for this layer.</p>
<p>When you create a layer subclass, you can set <code>self.input_spec</code> to enable
the layer to run input compatibility checks when it is called.
Consider a <code>Conv2D</code> layer: it can only be called on a single input tensor
of rank 4. As such, you can set, in <code>__init__()</code>:</p>
<div class="codehilite"><pre><span></span><code><span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputSpec</span><span class="p">(</span><span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div>

<p>Now, if you try to call the layer on an input that isn't rank 4
(for instance, an input of shape <code>(2,)</code>, it will raise a nicely-formatted
error:</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span> <span class="n">Input</span> <span class="mi">0</span> <span class="n">of</span> <span class="n">layer</span> <span class="n">conv2d</span> <span class="k">is</span> <span class="n">incompatible</span> <span class="k">with</span> <span class="n">the</span> <span class="n">layer</span><span class="o">:</span>
<span class="n">expected</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">4</span><span class="o">,</span> <span class="n">found</span> <span class="n">ndim</span><span class="o">=</span><span class="mi">1</span><span class="o">.</span> <span class="n">Full</span> <span class="n">shape</span> <span class="n">received</span><span class="o">:</span> <span class="o">[</span><span class="mi">2</span><span class="o">]</span>
</code></pre></div>

<p>Input checks that can be specified via <code>input_spec</code> include:
- Structure (e.g. a single input, a list of 2 inputs, etc)
- Shape
- Rank (ndim)
- Dtype</p>
<p>For more information, see <code>tf.keras.layers.InputSpec</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">layers</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">losses</span>
</code></pre></div>

<p>List of losses added using the <code>add_loss()</code> API.</p>
<p>Variable regularization tensors are created when this property is accessed,
so it is eager safe: accessing <code>losses</code> under a <code>tf.GradientTape</code> will
propagate gradients back to the corresponding variables.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>class MyLayer(tf.keras.layers.Layer):
...   def call(self, inputs):
...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))
...     return inputs
l = MyLayer()
l(np.ones((10, 1)))
l.losses
[1.0]</p>
<p>inputs = tf.keras.Input(shape=(10,))
x = tf.keras.layers.Dense(10)(inputs)
outputs = tf.keras.layers.Dense(1)(x)
model = tf.keras.Model(inputs, outputs)</p>
<h1 id="activity-regularization_2">Activity regularization.</h1>
<p>len(model.losses)
0
model.add_loss(tf.abs(tf.reduce_mean(x)))
len(model.losses)
1</p>
<p>inputs = tf.keras.Input(shape=(10,))
d = tf.keras.layers.Dense(10, kernel_initializer='ones')
x = d(inputs)
outputs = tf.keras.layers.Dense(1)(x)
model = tf.keras.Model(inputs, outputs)</p>
<h1 id="weight-regularization_2">Weight regularization.</h1>
<p>model.add_loss(lambda: tf.reduce_mean(d.kernel))
model.losses
[<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]</p>
</blockquote>
</blockquote>
</blockquote>
<p>Returns:
  A list of tensors.</p>
<div class="codehilite"><pre><span></span><code><span class="n">metrics</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">metrics_names</span>
</code></pre></div>

<p>Returns the model's display labels for all outputs.</p>
<p>Note: <code>metrics_names</code> are available only after a <code>keras.Model</code> has been
trained/evaluated on actual data.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>inputs = tf.keras.layers.Input(shape=(3,))
outputs = tf.keras.layers.Dense(2)(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
model.compile(optimizer="Adam", loss="mse", metrics=["mae"])
model.metrics_names
[]</p>
<p>x = np.random.random((2, 3))
y = np.random.randint(0, 2, (2, 2))
model.fit(x, y)
model.metrics_names
['loss', 'mae']</p>
<p>inputs = tf.keras.layers.Input(shape=(3,))
d = tf.keras.layers.Dense(2, name='out')
output_1 = d(inputs)
output_2 = d(inputs)
model = tf.keras.models.Model(
...    inputs=inputs, outputs=[output_1, output_2])
model.compile(optimizer="Adam", loss="mse", metrics=["mae", "acc"])
model.fit(x, (y, y))
model.metrics_names
['loss', 'out_loss', 'out_1_loss', 'out_mae', 'out_acc', 'out_1_mae',
'out_1_acc']</p>
</blockquote>
</blockquote>
</blockquote>
<div class="codehilite"><pre><span></span><code><span class="n">name</span>
</code></pre></div>

<p>Name of the layer (string), set in the constructor.</p>
<div class="codehilite"><pre><span></span><code><span class="n">name_scope</span>
</code></pre></div>

<p>Returns a <code>tf.name_scope</code> instance for this class.</p>
<div class="codehilite"><pre><span></span><code><span class="n">non_trainable_variables</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">non_trainable_weights</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">outbound_nodes</span>
</code></pre></div>

<p>Deprecated, do NOT use! Only for compatibility with external Keras.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output</span>
</code></pre></div>

<p>Retrieves the output tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one output,
i.e. if it is connected to one incoming layer.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output_mask</span>
</code></pre></div>

<p>Retrieves the output mask tensor(s) of a layer.</p>
<p>Only applicable if the layer has exactly one inbound node,
i.e. if it is connected to one incoming layer.</p>
<p>Returns:
    Output mask tensor (potentially None) or list of output
    mask tensors.</p>
<p>Raises:
    AttributeError: if the layer is connected to
    more than one incoming layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">output_shape</span>
</code></pre></div>

<p>Retrieves the output shape(s) of a layer.</p>
<p>Only applicable if the layer has one output,
or if all outputs have the same shape.</p>
<div class="codehilite"><pre><span></span><code><span class="n">run_eagerly</span>
</code></pre></div>

<p>Settable attribute indicating whether the model should run eagerly.</p>
<p>Running eagerly means that your model will be run step by step,
like Python code. Your model might run slower, but it should become easier
for you to debug it by stepping into individual layer calls.</p>
<p>By default, we will attempt to compile your model to a static graph to
deliver the best execution performance.</p>
<div class="codehilite"><pre><span></span><code><span class="n">state_updates</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Returns the <code>updates</code> from all layers that are stateful.</p>
<p>This is useful for separating training updates and
state updates, e.g. when we need to update a layer's internal state
during prediction.</p>
<div class="codehilite"><pre><span></span><code><span class="n">stateful</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">submodules</span>
</code></pre></div>

<p>Sequence of all sub-modules.</p>
<p>Submodules are modules which are properties of this module, or found as
properties of modules which are properties of this module (and so on).</p>
<blockquote>
<blockquote>
<blockquote>
<p>a = tf.Module()
b = tf.Module()
c = tf.Module()
a.b = b
b.c = c
list(a.submodules) == [b, c]
True
list(b.submodules) == [c]
True
list(c.submodules) == []
True</p>
</blockquote>
</blockquote>
</blockquote>
<div class="codehilite"><pre><span></span><code><span class="n">supports_masking</span>
</code></pre></div>

<p>Whether this layer supports computing a mask using <code>compute_mask</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">trainable</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">trainable_variables</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">trainable_weights</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">updates</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="n">variable_dtype</span>
</code></pre></div>

<p>Alias of <code>Layer.dtype</code>, the dtype of the weights.</p>
<div class="codehilite"><pre><span></span><code><span class="n">variables</span>
</code></pre></div>

<p>Returns the list of all layer variables/weights.</p>
<p>Alias of <code>self.weights</code>.</p>
<p>Note: This will not track the weights of nested <code>tf.Modules</code> that are not
themselves Keras layers.</p>
<div class="codehilite"><pre><span></span><code><span class="n">weights</span>
</code></pre></div>

<p>Returns the list of all layer variables/weights.</p>
<p>Note: This will not track the weights of nested <code>tf.Modules</code> that are not
themselves Keras layers.</p>
<h4 id="methods_2">Methods</h4>
<h4 id="add_loss_2">add_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">losses</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Add loss tensor(s), potentially dependent on layer inputs.</p>
<p>Some losses (for instance, activity regularization losses) may be dependent
on the inputs passed when calling a layer. Hence, when reusing the same
layer on different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.losses</code> may
be dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>
<p>This method can be used inside a subclassed layer or model's <code>call</code>
function, in which case <code>losses</code> should be a Tensor or list of Tensors.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">inputs</span>
</code></pre></div>

<p>This method can also be called directly on a Functional Model during
construction. In this case, any loss Tensors passed to this Model must
be symbolic and be able to be traced back to the model's <code>Input</code>s. These
losses become part of the model's topology and are tracked in <code>get_config</code>.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="c1"># Activity regularization.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</code></pre></div>

<p>If this is not the case for your loss (if, for example, your loss references
a <code>Variable</code> of one of the model's layers), you can wrap your loss in a
zero-argument lambda. These losses are not tracked as part of the model's
topology since they can't be serialized.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">d</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="c1"># Weight regularization.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">kernel</span><span class="p">))</span>
</code></pre></div>

<p>Arguments:
  losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses
    may also be zero-argument callables which create a loss tensor.
  **kwargs: Additional keyword arguments for backward compatibility.
    Accepted values:
      inputs - Deprecated, will be automatically inferred.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">add_loss</span>(<span class="nb">self</span>, <span class="n">losses</span>, **<span class="n">kwargs</span>):

    <span class="s">&quot;&quot;&quot;Add loss tensor(s), potentially dependent on layer inputs.</span>

<span class="s">    Some losses (for instance, activity regularization losses) may be dependent</span>

<span class="s">    on the inputs passed when calling a layer. Hence, when reusing the same</span>

<span class="s">    layer on different inputs `a` and `b`, some entries in `layer.losses` may</span>

<span class="s">    be dependent on `a` and some on `b`. This method automatically keeps track</span>

<span class="s">    of dependencies.</span>

<span class="s">    This method can be used inside a subclassed layer or model&#39;s `call`</span>

<span class="s">    function, in which case `losses` should be a Tensor or list of Tensors.</span>

<span class="s">    Example:</span>

<span class="s">    ```python</span>

<span class="s">    class MyLayer(tf.keras.layers.Layer):</span>

<span class="s">      def call(self, inputs):</span>

<span class="s">        self.add_loss(tf.abs(tf.reduce_mean(inputs)))</span>

<span class="s">        return inputs</span>

<span class="s">    ```</span>

<span class="s">    This method can also be called directly on a Functional Model during</span>

<span class="s">    construction. In this case, any loss Tensors passed to this Model must</span>

<span class="s">    be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>

<span class="s">    losses become part of the model&#39;s topology and are tracked in `get_config`.</span>

<span class="s">    Example:</span>

<span class="s">    ```python</span>

<span class="s">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s">    x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s">    # Activity regularization.</span>

<span class="s">    model.add_loss(tf.abs(tf.reduce_mean(x)))</span>

<span class="s">    ```</span>

<span class="s">    If this is not the case for your loss (if, for example, your loss references</span>

<span class="s">    a `Variable` of one of the model&#39;s layers), you can wrap your loss in a</span>

<span class="s">    zero-argument lambda. These losses are not tracked as part of the model&#39;s</span>

<span class="s">    topology since they can&#39;t be serialized.</span>

<span class="s">    Example:</span>

<span class="s">    ```python</span>

<span class="s">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s">    d = tf.keras.layers.Dense(10)</span>

<span class="s">    x = d(inputs)</span>

<span class="s">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s">    # Weight regularization.</span>

<span class="s">    model.add_loss(lambda: tf.reduce_mean(d.kernel))</span>

<span class="s">    ```</span>

<span class="s">    Arguments:</span>

<span class="s">      losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses</span>

<span class="s">        may also be zero-argument callables which create a loss tensor.</span>

<span class="s">      **kwargs: Additional keyword arguments for backward compatibility.</span>

<span class="s">        Accepted values:</span>

<span class="s">          inputs - Deprecated, will be automatically inferred.</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="n">kwargs</span>.<span class="nb">pop</span>(<span class="s">&#39;inputs&#39;</span>, <span class="n">None</span>)

    <span class="k">if</span> <span class="n">kwargs:</span>

      <span class="n">raise</span> <span class="n">TypeError</span>(<span class="s">&#39;Unknown keyword arguments: %s&#39;</span> % (<span class="n">kwargs</span>.<span class="nb">keys</span>(),))

    <span class="n">def</span> <span class="n">_tag_callable</span>(<span class="n">loss</span>):

      <span class="s">&quot;&quot;&quot;Tags callable loss tensor as `_unconditional_loss`.&quot;&quot;&quot;</span>

      <span class="k">if</span> <span class="n">callable</span>(<span class="n">loss</span>):

        <span class="c1"># We run the loss without autocasting, as regularizers are often</span>

        <span class="c1"># numerically unstable in float16.</span>

        <span class="k">with</span> <span class="n">autocast_variable</span>.<span class="n">enable_auto_cast_variables</span>(<span class="n">None</span>):

          <span class="n">loss</span> = <span class="n">loss</span>()

      <span class="k">if</span> <span class="n">loss</span> <span class="k">is</span> <span class="n">None:</span>

        <span class="k">return</span> <span class="n">None</span>  <span class="c1"># Will be filtered out when computing the .losses property</span>

      <span class="k">if</span> <span class="nb">not</span> <span class="n">tensor_util</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>):

        <span class="n">loss</span> = <span class="n">ops</span>.<span class="n">convert_to_tensor_v2_with_dispatch</span>(

            <span class="n">loss</span>, <span class="n">dtype</span>=<span class="n">backend</span>.<span class="n">floatx</span>())

      <span class="n">loss</span>.<span class="n">_unconditional_loss</span> = <span class="nb">True</span>  <span class="c1"># pylint: disable=protected-access</span>

      <span class="k">return</span> <span class="n">loss</span>

    <span class="n">losses</span> = <span class="n">nest</span>.<span class="n">flatten</span>(<span class="n">losses</span>)

    <span class="n">callable_losses</span> = []

    <span class="n">eager_losses</span> = []

    <span class="n">symbolic_losses</span> = []

    <span class="k">for</span> <span class="n">loss</span> <span class="nb">in</span> <span class="n">losses:</span>

      <span class="k">if</span> <span class="n">callable</span>(<span class="n">loss</span>):

        <span class="n">callable_losses</span>.<span class="nb">append</span>(<span class="n">functools</span>.<span class="n">partial</span>(<span class="n">_tag_callable</span>, <span class="n">loss</span>))

        <span class="n">continue</span>

      <span class="k">if</span> <span class="n">loss</span> <span class="k">is</span> <span class="n">None:</span>

        <span class="n">continue</span>

      <span class="k">if</span> <span class="nb">not</span> <span class="n">tensor_util</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>) <span class="o">and</span> <span class="nb">not</span> <span class="n">isinstance</span>(

          <span class="n">loss</span>, <span class="n">keras_tensor</span>.<span class="n">KerasTensor</span>):

        <span class="n">loss</span> = <span class="n">ops</span>.<span class="n">convert_to_tensor_v2_with_dispatch</span>(

            <span class="n">loss</span>, <span class="n">dtype</span>=<span class="n">backend</span>.<span class="n">floatx</span>())

      <span class="c1"># TF Functions should take the eager path.</span>

      <span class="k">if</span> ((<span class="n">tf_utils</span>.<span class="n">is_symbolic_tensor</span>(<span class="n">loss</span>) <span class="o">or</span>

           <span class="n">isinstance</span>(<span class="n">loss</span>, <span class="n">keras_tensor</span>.<span class="n">KerasTensor</span>)) <span class="o">and</span>

          <span class="nb">not</span> <span class="n">base_layer_utils</span>.<span class="n">is_in_tf_function</span>()):

        <span class="n">symbolic_losses</span>.<span class="nb">append</span>(<span class="n">loss</span>)

      <span class="n">elif</span> <span class="n">tensor_util</span>.<span class="n">is_tensor</span>(<span class="n">loss</span>):

        <span class="n">eager_losses</span>.<span class="nb">append</span>(<span class="n">loss</span>)

    <span class="nb">self</span>.<span class="n">_callable_losses</span>.<span class="n">extend</span>(<span class="n">callable_losses</span>)

    <span class="n">in_call_context</span> = <span class="n">base_layer_utils</span>.<span class="n">call_context</span>().<span class="n">in_call</span>

    <span class="k">if</span> <span class="n">eager_losses</span> <span class="o">and</span> <span class="nb">not</span> <span class="n">in_call_context:</span>

      <span class="n">raise</span> <span class="n">ValueError</span>(

          <span class="s">&#39;Expected a symbolic Tensors or a callable for the loss value. &#39;</span>

          <span class="s">&#39;Please wrap your loss computation in a zero argument `lambda`.&#39;</span>)

    <span class="nb">self</span>.<span class="n">_eager_losses</span>.<span class="n">extend</span>(<span class="n">eager_losses</span>)

    <span class="k">if</span> <span class="n">in_call_context</span> <span class="o">and</span> <span class="nb">not</span> <span class="n">keras_tensor</span>.<span class="n">keras_tensors_enabled</span>():

      <span class="k">for</span> <span class="n">symbolic_loss</span> <span class="nb">in</span> <span class="n">symbolic_losses:</span>

        <span class="nb">self</span>.<span class="n">_losses</span>.<span class="nb">append</span>(<span class="n">symbolic_loss</span>)

    <span class="n">else:</span>

      <span class="k">for</span> <span class="n">symbolic_loss</span> <span class="nb">in</span> <span class="n">symbolic_losses:</span>

        <span class="k">if</span> <span class="n">getattr</span>(<span class="nb">self</span>, <span class="s">&#39;_is_graph_network&#39;</span>, <span class="nb">False</span>):

          <span class="nb">self</span>.<span class="n">_graph_network_add_loss</span>(<span class="n">symbolic_loss</span>)

        <span class="n">else:</span>

          <span class="c1"># Possible a loss was added in a Layer&#39;s `build`.</span>

          <span class="nb">self</span>.<span class="n">_losses</span>.<span class="nb">append</span>(<span class="n">symbolic_loss</span>)
</code></pre></div>

</details>
<h4 id="add_metric_2">add_metric</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_metric</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">value</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Adds metric tensor to the layer.</p>
<p>This method can be used inside the <code>call()</code> method of a subclassed layer
or model.</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">MyMetricLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyMetricLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_metric_layer&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_2&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span>
</code></pre></div>

<p>This method can also be called directly on a Functional Model during
construction. In this case, any tensor passed to this Model must
be symbolic and be able to be traced back to the model's <code>Input</code>s. These
metrics become part of the model's topology and are tracked when you
save the model via <code>save()</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

<p>Note: Calling <code>add_metric()</code> with the result of a metric object on a
Functional Model, as shown in the example below, is not supported. This is
because we cannot trace the metric result tensor back to the model's inputs.</p>
<div class="codehilite"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">()(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>value</td>
<td>None</td>
<td>Metric tensor.</td>
<td>None</td>
</tr>
<tr>
<td>name</td>
<td>None</td>
<td>String metric name.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments for backward compatibility.</td>
<td></td>
</tr>
<tr>
<td>Accepted values:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>aggregation</code> - When the <code>value</code> tensor provided is not the result of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>calling a <code>keras.Metric</code> instance, it will be aggregated by default</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>using a <code>keras.Metric.Mean</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">add_metric</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="k">value</span><span class="p">,</span> <span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Adds metric tensor to the layer.</span>

<span class="s2">    This method can be used inside the `call()` method of a subclassed layer</span>

<span class="s2">    or model.</span>

<span class="s2">    ```python</span>

<span class="s2">    class MyMetricLayer(tf.keras.layers.Layer):</span>

<span class="s2">      def __init__(self):</span>

<span class="s2">        super(MyMetricLayer, self).__init__(name=&#39;my_metric_layer&#39;)</span>

<span class="s2">        self.mean = tf.keras.metrics.Mean(name=&#39;metric_1&#39;)</span>

<span class="s2">      def call(self, inputs):</span>

<span class="s2">        self.add_metric(self.mean(x))</span>

<span class="s2">        self.add_metric(tf.reduce_sum(x), name=&#39;metric_2&#39;)</span>

<span class="s2">        return inputs</span>

<span class="s2">    ```</span>

<span class="s2">    This method can also be called directly on a Functional Model during</span>

<span class="s2">    construction. In this case, any tensor passed to this Model must</span>

<span class="s2">    be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>

<span class="s2">    metrics become part of the model&#39;s topology and are tracked when you</span>

<span class="s2">    save the model via `save()`.</span>

<span class="s2">    ```python</span>

<span class="s2">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s2">    x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s2">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s2">    model.add_metric(math_ops.reduce_sum(x), name=&#39;metric_1&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    Note: Calling `add_metric()` with the result of a metric object on a</span>

<span class="s2">    Functional Model, as shown in the example below, is not supported. This is</span>

<span class="s2">    because we cannot trace the metric result tensor back to the model&#39;s inputs.</span>

<span class="s2">    ```python</span>

<span class="s2">    inputs = tf.keras.Input(shape=(10,))</span>

<span class="s2">    x = tf.keras.layers.Dense(10)(inputs)</span>

<span class="s2">    outputs = tf.keras.layers.Dense(1)(x)</span>

<span class="s2">    model = tf.keras.Model(inputs, outputs)</span>

<span class="s2">    model.add_metric(tf.keras.metrics.Mean()(x), name=&#39;metric_1&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    Args:</span>

<span class="s2">      value: Metric tensor.</span>

<span class="s2">      name: String metric name.</span>

<span class="s2">      **kwargs: Additional keyword arguments for backward compatibility.</span>

<span class="s2">        Accepted values:</span>

<span class="s2">        `aggregation` - When the `value` tensor provided is not the result of</span>

<span class="s2">        calling a `keras.Metric` instance, it will be aggregated by default</span>

<span class="s2">        using a `keras.Metric.Mean`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">kwargs_keys</span> <span class="o">=</span> <span class="k">list</span><span class="p">(</span><span class="n">kwargs</span><span class="p">.</span><span class="k">keys</span><span class="p">())</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">or</span>

        <span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">and</span> <span class="n">kwargs_keys</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span> <span class="o">!=</span> <span class="s1">&#39;aggregation&#39;</span><span class="p">))</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">TypeError</span><span class="p">(</span><span class="s1">&#39;Unknown keyword arguments: &#39;</span><span class="p">,</span> <span class="n">str</span><span class="p">(</span><span class="n">kwargs</span><span class="p">.</span><span class="k">keys</span><span class="p">()))</span>

    <span class="n">from_metric_obj</span> <span class="o">=</span> <span class="n">hasattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="s1">&#39;_metric_obj&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">keras_tensor</span><span class="p">.</span><span class="n">keras_tensors_enabled</span><span class="p">()</span><span class="o">:</span>

      <span class="n">is_symbolic</span> <span class="o">=</span> <span class="n">isinstance</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="n">keras_tensor</span><span class="p">.</span><span class="n">KerasTensor</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">is_symbolic</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">is_symbolic_tensor</span><span class="p">(</span><span class="k">value</span><span class="p">)</span>

    <span class="n">in_call_context</span> <span class="o">=</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">call_context</span><span class="p">().</span><span class="n">in_call</span>

    <span class="k">if</span> <span class="k">name</span> <span class="k">is</span> <span class="k">None</span> <span class="k">and</span> <span class="k">not</span> <span class="n">from_metric_obj</span><span class="o">:</span>

      <span class="c1"># Eg. `self.add_metric(math_ops.reduce_sum(x))`</span>

      <span class="c1"># In eager mode, we use metric name to lookup a metric. Without a name,</span>

      <span class="c1"># a new Mean metric wrapper will be created on every model/layer call.</span>

      <span class="c1"># So, we raise an error when no name is provided.</span>

      <span class="c1"># We will do the same for symbolic mode for consistency although a name</span>

      <span class="c1"># will be generated if no name is provided.</span>

      <span class="c1"># We will not raise this error in the foll use case for the sake of</span>

      <span class="c1"># consistency as name in provided in the metric constructor.</span>

      <span class="c1"># mean = metrics.Mean(name=&#39;my_metric&#39;)</span>

      <span class="c1"># model.add_metric(mean(outputs))</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Please provide a name for your metric like &#39;</span>

                       <span class="s1">&#39;`self.add_metric(tf.reduce_sum(inputs), &#39;</span>

                       <span class="s1">&#39;name=</span><span class="se">\&#39;</span><span class="s1">mean_activation</span><span class="se">\&#39;</span><span class="s1">)`&#39;</span><span class="p">)</span>

    <span class="n">elif</span> <span class="n">from_metric_obj</span><span class="o">:</span>

      <span class="k">name</span> <span class="o">=</span> <span class="k">value</span><span class="p">.</span><span class="n">_metric_obj</span><span class="p">.</span><span class="k">name</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">in_call_context</span> <span class="k">and</span> <span class="k">not</span> <span class="n">is_symbolic</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Expected a symbolic Tensor for the metric value, &#39;</span>

                       <span class="s1">&#39;received: &#39;</span> <span class="o">+</span> <span class="n">str</span><span class="p">(</span><span class="k">value</span><span class="p">))</span>

    <span class="c1"># If a metric was added in a Layer&#39;s `call` or `build`.</span>

    <span class="k">if</span> <span class="n">in_call_context</span> <span class="k">or</span> <span class="k">not</span> <span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_is_graph_network&#39;</span><span class="p">,</span> <span class="no">False</span><span class="p">)</span><span class="o">:</span>

      <span class="c1"># TF Function path should take the eager path.</span>

      <span class="c1"># If the given metric is available in `metrics` list we just update state</span>

      <span class="c1"># on it, otherwise we create a new metric instance and</span>

      <span class="c1"># add it to the `metrics` list.</span>

      <span class="n">metric_obj</span> <span class="o">=</span> <span class="n">getattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="s1">&#39;_metric_obj&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>

      <span class="c1"># Tensors that come from a Metric object already updated the Metric state.</span>

      <span class="n">should_update_state</span> <span class="o">=</span> <span class="k">not</span> <span class="n">metric_obj</span>

      <span class="k">name</span> <span class="o">=</span> <span class="n">metric_obj</span><span class="p">.</span><span class="k">name</span> <span class="k">if</span> <span class="n">metric_obj</span> <span class="k">else</span> <span class="k">name</span>

      <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">_metrics_lock</span><span class="o">:</span>

        <span class="k">match</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_get_existing_metric</span><span class="p">(</span><span class="k">name</span><span class="p">)</span>

        <span class="k">if</span> <span class="k">match</span><span class="o">:</span>

          <span class="n">metric_obj</span> <span class="o">=</span> <span class="k">match</span>

        <span class="n">elif</span> <span class="n">metric_obj</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

        <span class="k">else</span><span class="o">:</span>

          <span class="c1"># Build the metric object with the value&#39;s dtype if it defines one</span>

          <span class="n">metric_obj</span> <span class="o">=</span> <span class="n">metrics_mod</span><span class="p">.</span><span class="n">Mean</span><span class="p">(</span>

              <span class="k">name</span><span class="o">=</span><span class="k">name</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">getattr</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">))</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_metrics</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">should_update_state</span><span class="o">:</span>

        <span class="n">metric_obj</span><span class="p">(</span><span class="k">value</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">from_metric_obj</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Using the result of calling a `Metric` object &#39;</span>

                         <span class="s1">&#39;when calling `add_metric` on a Functional &#39;</span>

                         <span class="s1">&#39;Model is not supported. Please pass the &#39;</span>

                         <span class="s1">&#39;Tensor to monitor directly.&#39;</span><span class="p">)</span>

      <span class="c1"># Insert layers into the Keras Graph Network.</span>

      <span class="n">aggregation</span> <span class="o">=</span> <span class="k">None</span> <span class="k">if</span> <span class="n">from_metric_obj</span> <span class="k">else</span> <span class="s1">&#39;mean&#39;</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_graph_network_add_metric</span><span class="p">(</span><span class="k">value</span><span class="p">,</span> <span class="n">aggregation</span><span class="p">,</span> <span class="k">name</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="add_update_2">add_update</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_update</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">updates</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Add update op(s), potentially dependent on layer inputs.</p>
<p>Weight updates (for instance, the updates of the moving mean and variance
in a BatchNormalization layer) may be dependent on the inputs passed
when calling a layer. Hence, when reusing the same layer on
different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.updates</code> may be
dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>
<p>This call is ignored when eager execution is enabled (in that case, variable
updates are run on the fly and thus do not need to be tracked for later
execution).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>updates</td>
<td>None</td>
<td>Update op, or list/tuple of update ops, or zero-arg callable</td>
<td></td>
</tr>
<tr>
<td>that returns an update op. A zero-arg callable should be passed in</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>order to disable running the updates by setting <code>trainable=False</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>on this Layer, when executing in Eager mode.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>inputs</td>
<td>None</td>
<td>Deprecated, will be automatically inferred.</td>
<td>None</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_doc_inheritable</span>

  <span class="n">def</span> <span class="n">add_update</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Add update op(s), potentially dependent on layer inputs.</span>

<span class="s2">    Weight updates (for instance, the updates of the moving mean and variance</span>

<span class="s2">    in a BatchNormalization layer) may be dependent on the inputs passed</span>

<span class="s2">    when calling a layer. Hence, when reusing the same layer on</span>

<span class="s2">    different inputs `a` and `b`, some entries in `layer.updates` may be</span>

<span class="s2">    dependent on `a` and some on `b`. This method automatically keeps track</span>

<span class="s2">    of dependencies.</span>

<span class="s2">    This call is ignored when eager execution is enabled (in that case, variable</span>

<span class="s2">    updates are run on the fly and thus do not need to be tracked for later</span>

<span class="s2">    execution).</span>

<span class="s2">    Arguments:</span>

<span class="s2">      updates: Update op, or list/tuple of update ops, or zero-arg callable</span>

<span class="s2">        that returns an update op. A zero-arg callable should be passed in</span>

<span class="s2">        order to disable running the updates by setting `trainable=False`</span>

<span class="s2">        on this Layer, when executing in Eager mode.</span>

<span class="s2">      inputs: Deprecated, will be automatically inferred.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">inputs</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">tf_logging</span><span class="p">.</span><span class="n">warning</span><span class="p">(</span>

          <span class="s1">&#39;`add_update` `inputs` kwarg has been deprecated. You no longer need &#39;</span>

          <span class="s1">&#39;to pass a value to `inputs` as it is being automatically inferred.&#39;</span><span class="p">)</span>

    <span class="n">call_context</span> <span class="o">=</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">call_context</span><span class="p">()</span>

    <span class="c1"># No need to run updates during Functional API construction.</span>

    <span class="k">if</span> <span class="n">call_context</span><span class="p">.</span><span class="n">in_keras_graph</span><span class="o">:</span>

      <span class="k">return</span>

    <span class="c1"># Callable updates are disabled by setting `trainable=False`.</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">call_context</span><span class="p">.</span><span class="n">frozen</span><span class="o">:</span>

      <span class="k">for</span> <span class="k">update</span> <span class="k">in</span> <span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span><span class="o">:</span>

        <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="k">update</span><span class="p">)</span><span class="o">:</span>

          <span class="k">update</span><span class="p">()</span>  <span class="c1"># pylint: disable=not-callable</span>
</code></pre></div>

</details>
<h4 id="add_variable_2">add_variable</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_variable</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use! Alias for <code>add_weight</code>.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_doc_inheritable</span>

  <span class="n">def</span> <span class="n">add_variable</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use! Alias for `add_weight`.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.add_variable` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `layer.add_weight` method instead.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">add_weight</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="add_weight_2">add_weight</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">add_weight</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">trainable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_resource</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">synchronization</span><span class="o">=&lt;</span><span class="n">VariableSynchronization</span><span class="o">.</span><span class="n">AUTO</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=&lt;</span><span class="n">VariableAggregation</span><span class="o">.</span><span class="n">NONE</span><span class="p">:</span> <span class="mi">0</span><span class="o">&gt;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Adds a new variable to the layer.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>None</td>
<td>Variable name.</td>
<td>None</td>
</tr>
<tr>
<td>shape</td>
<td>None</td>
<td>Variable shape. Defaults to scalar if unspecified.</td>
<td>scalar if unspecified</td>
</tr>
<tr>
<td>dtype</td>
<td>None</td>
<td>The type of the variable. Defaults to <code>self.dtype</code>.</td>
<td><code>self.dtype</code></td>
</tr>
<tr>
<td>initializer</td>
<td>None</td>
<td>Initializer instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>regularizer</td>
<td>None</td>
<td>Regularizer instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>trainable</td>
<td>None</td>
<td>Boolean, whether the variable should be part of the layer's</td>
<td></td>
</tr>
<tr>
<td>"trainable_variables" (e.g. variables, biases)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>or "non_trainable_variables" (e.g. BatchNorm mean and variance).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Note that <code>trainable</code> cannot be <code>True</code> if <code>synchronization</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>is set to <code>ON_READ</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>constraint</td>
<td>None</td>
<td>Constraint instance (callable).</td>
<td>None</td>
</tr>
<tr>
<td>use_resource</td>
<td>None</td>
<td>Whether to use <code>ResourceVariable</code>.</td>
<td>None</td>
</tr>
<tr>
<td>synchronization</td>
<td>None</td>
<td>Indicates when a distributed a variable will be</td>
<td></td>
</tr>
<tr>
<td>aggregated. Accepted values are constants defined in the class</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.VariableSynchronization</code>. By default the synchronization is set to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>AUTO</code> and the current <code>DistributionStrategy</code> chooses</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>when to synchronize. If <code>synchronization</code> is set to <code>ON_READ</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>trainable</code> must not be set to <code>True</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>aggregation</td>
<td>None</td>
<td>Indicates how a distributed variable will be aggregated.</td>
<td></td>
</tr>
<tr>
<td>Accepted values are constants defined in the class</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.VariableAggregation</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments. Accepted values are <code>getter</code>,</td>
<td></td>
</tr>
<tr>
<td><code>collections</code>, <code>experimental_autocast</code> and <code>caching_device</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>The variable created.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>When giving unsupported dtype and no initializer or when</td>
</tr>
<tr>
<td>trainable has been set to True with synchronization set as <code>ON_READ</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.for_subclass_implementers</span>

  <span class="n">def</span> <span class="n">add_weight</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                 <span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">shape</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">dtype</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">initializer</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">regularizer</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">trainable</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="k">constraint</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">use_resource</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                 <span class="n">synchronization</span><span class="o">=</span><span class="n">tf_variables</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="p">.</span><span class="n">AUTO</span><span class="p">,</span>

                 <span class="n">aggregation</span><span class="o">=</span><span class="n">tf_variables</span><span class="p">.</span><span class="n">VariableAggregation</span><span class="p">.</span><span class="k">NONE</span><span class="p">,</span>

                 <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Adds a new variable to the layer.</span>

<span class="s2">    Arguments:</span>

<span class="s2">      name: Variable name.</span>

<span class="s2">      shape: Variable shape. Defaults to scalar if unspecified.</span>

<span class="s2">      dtype: The type of the variable. Defaults to `self.dtype`.</span>

<span class="s2">      initializer: Initializer instance (callable).</span>

<span class="s2">      regularizer: Regularizer instance (callable).</span>

<span class="s2">      trainable: Boolean, whether the variable should be part of the layer&#39;s</span>

<span class="s2">        &quot;</span><span class="n">trainable_variables</span><span class="s2">&quot; (e.g. variables, biases)</span>

<span class="s2">        or &quot;</span><span class="n">non_trainable_variables</span><span class="s2">&quot; (e.g. BatchNorm mean and variance).</span>

<span class="s2">        Note that `trainable` cannot be `True` if `synchronization`</span>

<span class="s2">        is set to `ON_READ`.</span>

<span class="s2">      constraint: Constraint instance (callable).</span>

<span class="s2">      use_resource: Whether to use `ResourceVariable`.</span>

<span class="s2">      synchronization: Indicates when a distributed a variable will be</span>

<span class="s2">        aggregated. Accepted values are constants defined in the class</span>

<span class="s2">        `tf.VariableSynchronization`. By default the synchronization is set to</span>

<span class="s2">        `AUTO` and the current `DistributionStrategy` chooses</span>

<span class="s2">        when to synchronize. If `synchronization` is set to `ON_READ`,</span>

<span class="s2">        `trainable` must not be set to `True`.</span>

<span class="s2">      aggregation: Indicates how a distributed variable will be aggregated.</span>

<span class="s2">        Accepted values are constants defined in the class</span>

<span class="s2">        `tf.VariableAggregation`.</span>

<span class="s2">      **kwargs: Additional keyword arguments. Accepted values are `getter`,</span>

<span class="s2">        `collections`, `experimental_autocast` and `caching_device`.</span>

<span class="s2">    Returns:</span>

<span class="s2">      The variable created.</span>

<span class="s2">    Raises:</span>

<span class="s2">      ValueError: When giving unsupported dtype and no initializer or when</span>

<span class="s2">        trainable has been set to True with synchronization set as `ON_READ`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">shape</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">shape</span> <span class="o">=</span> <span class="p">()</span>

    <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;partitioner&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>  <span class="c1"># Ignored.</span>

    <span class="c1"># Validate optional keyword arguments.</span>

    <span class="k">for</span> <span class="n">kwarg</span> <span class="k">in</span> <span class="n">kwargs</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">kwarg</span> <span class="k">not</span> <span class="k">in</span> <span class="err">[</span><span class="s1">&#39;collections&#39;</span><span class="p">,</span> <span class="s1">&#39;experimental_autocast&#39;</span><span class="p">,</span>

                       <span class="s1">&#39;caching_device&#39;</span><span class="p">,</span> <span class="s1">&#39;getter&#39;</span><span class="err">]</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">TypeError</span><span class="p">(</span><span class="s1">&#39;Unknown keyword argument:&#39;</span><span class="p">,</span> <span class="n">kwarg</span><span class="p">)</span>

    <span class="n">collections_arg</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;collections&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>

    <span class="c1"># &#39;experimental_autocast&#39; can be set to False by the caller to indicate an</span>

    <span class="c1"># AutoCastVariable should never be created.</span>

    <span class="n">autocast</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;experimental_autocast&#39;</span><span class="p">,</span> <span class="no">True</span><span class="p">)</span>

    <span class="c1"># See the docstring for tf.Variable about the details for caching_device.</span>

    <span class="n">caching_device</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;caching_device&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">dtype</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">dtype</span> <span class="k">or</span> <span class="n">backend</span><span class="p">.</span><span class="n">floatx</span><span class="p">()</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">dtypes</span><span class="p">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">variable_dtype</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="c1"># The policy is &quot;_infer&quot;, so we infer the policy from the variable dtype.</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_set_dtype_policy</span><span class="p">(</span><span class="n">policy</span><span class="p">.</span><span class="n">Policy</span><span class="p">(</span><span class="n">dtype</span><span class="p">.</span><span class="n">base_dtype</span><span class="p">.</span><span class="k">name</span><span class="p">))</span>

    <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>

    <span class="n">regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="n">regularizer</span><span class="p">)</span>

    <span class="k">constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="k">constraint</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">synchronization</span> <span class="o">==</span> <span class="n">tf_variables</span><span class="p">.</span><span class="n">VariableSynchronization</span><span class="p">.</span><span class="n">ON_READ</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">trainable</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

            <span class="s1">&#39;Synchronization value can be set to &#39;</span>

            <span class="s1">&#39;VariableSynchronization.ON_READ only for non-trainable variables. &#39;</span>

            <span class="s1">&#39;You have specified trainable=True and &#39;</span>

            <span class="s1">&#39;synchronization=VariableSynchronization.ON_READ.&#39;</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="c1"># Set trainable to be false when variable is to be synced on read.</span>

        <span class="n">trainable</span> <span class="o">=</span> <span class="no">False</span>

    <span class="n">elif</span> <span class="n">trainable</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">trainable</span> <span class="o">=</span> <span class="no">True</span>

    <span class="c1"># Initialize variable when no initializer provided</span>

    <span class="k">if</span> <span class="n">initializer</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="c1"># If dtype is DT_FLOAT, provide a uniform unit scaling initializer</span>

      <span class="k">if</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_floating</span><span class="o">:</span>

        <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">)</span>

      <span class="c1"># If dtype is DT_INT/DT_UINT, provide a default value `zero`</span>

      <span class="c1"># If dtype is DT_BOOL, provide a default value `FALSE`</span>

      <span class="n">elif</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_integer</span> <span class="k">or</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_unsigned</span> <span class="k">or</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_bool</span><span class="o">:</span>

        <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="s1">&#39;zeros&#39;</span><span class="p">)</span>

      <span class="c1"># NOTES:Do we need to support for handling DT_STRING and DT_COMPLEX here?</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;An initializer for variable %s of type %s is required&#39;</span>

                         <span class="s1">&#39; for layer %s&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="k">name</span><span class="p">,</span> <span class="n">dtype</span><span class="p">.</span><span class="n">base_dtype</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="k">name</span><span class="p">))</span>

    <span class="n">getter</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;getter&#39;</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">make_variable</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">autocast</span> <span class="k">and</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">compute_dtype</span> <span class="o">!=</span> <span class="n">self</span><span class="p">.</span><span class="n">_dtype_policy</span><span class="p">.</span><span class="n">variable_dtype</span>

        <span class="k">and</span> <span class="n">dtype</span><span class="p">.</span><span class="n">is_floating</span><span class="p">)</span><span class="o">:</span>

      <span class="n">old_getter</span> <span class="o">=</span> <span class="n">getter</span>

      <span class="c1"># Wrap variable constructor to return an AutoCastVariable.</span>

      <span class="n">def</span> <span class="n">getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>  <span class="c1"># pylint: disable=function-redefined</span>

        <span class="n">variable</span> <span class="o">=</span> <span class="n">old_getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">autocast_variable</span><span class="p">.</span><span class="n">create_autocast_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

      <span class="c1"># Also the caching_device does not work with the mixed precision API,</span>

      <span class="c1"># disable it if it is specified.</span>

      <span class="c1"># TODO(b/142020079): Reenable it once the bug is fixed.</span>

      <span class="k">if</span> <span class="n">caching_device</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

        <span class="n">tf_logging</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`caching_device` does not work with mixed precision &#39;</span>

                        <span class="s1">&#39;API. Ignoring user specified `caching_device`.&#39;</span><span class="p">)</span>

        <span class="n">caching_device</span> <span class="o">=</span> <span class="k">None</span>

    <span class="n">variable</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_add_variable_with_custom_getter</span><span class="p">(</span>

        <span class="k">name</span><span class="o">=</span><span class="k">name</span><span class="p">,</span>

        <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>

        <span class="c1"># TODO(allenl): a `make_variable` equivalent should be added as a</span>

        <span class="c1"># `Trackable` method.</span>

        <span class="n">getter</span><span class="o">=</span><span class="n">getter</span><span class="p">,</span>

        <span class="c1"># Manage errors in Layer rather than Trackable.</span>

        <span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

        <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>

        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>

        <span class="k">constraint</span><span class="o">=</span><span class="k">constraint</span><span class="p">,</span>

        <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>

        <span class="n">use_resource</span><span class="o">=</span><span class="n">use_resource</span><span class="p">,</span>

        <span class="n">collections</span><span class="o">=</span><span class="n">collections_arg</span><span class="p">,</span>

        <span class="n">synchronization</span><span class="o">=</span><span class="n">synchronization</span><span class="p">,</span>

        <span class="n">aggregation</span><span class="o">=</span><span class="n">aggregation</span><span class="p">,</span>

        <span class="n">caching_device</span><span class="o">=</span><span class="n">caching_device</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">regularizer</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="c1"># TODO(fchollet): in the future, this should be handled at the</span>

      <span class="c1"># level of variable creation, and weight regularization losses</span>

      <span class="c1"># should be variable attributes.</span>

      <span class="n">name_in_scope</span> <span class="o">=</span> <span class="n">variable</span><span class="p">.</span><span class="k">name</span><span class="err">[</span><span class="o">:</span><span class="n">variable</span><span class="p">.</span><span class="k">name</span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)</span><span class="err">]</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_handle_weight_regularization</span><span class="p">(</span><span class="n">name_in_scope</span><span class="p">,</span>

                                         <span class="n">variable</span><span class="p">,</span>

                                         <span class="n">regularizer</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">base_layer_utils</span><span class="p">.</span><span class="n">is_split_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span><span class="o">:</span>

      <span class="k">for</span> <span class="n">v</span> <span class="k">in</span> <span class="n">variable</span><span class="o">:</span>

        <span class="n">backend</span><span class="p">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">trainable</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

        <span class="k">else</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_non_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">backend</span><span class="p">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">trainable</span><span class="o">:</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_non_trainable_weights</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">variable</span>
</code></pre></div>

</details>
<h4 id="apply_2">apply</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">apply</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="o">*</span><span class="n">args</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>This is an alias of <code>self.__call__</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Input tensor(s).</td>
<td>None</td>
</tr>
<tr>
<td>*args</td>
<td>None</td>
<td>additional positional arguments to be passed to <code>self.call</code>.</td>
<td>None</td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>additional keyword arguments to be passed to <code>self.call</code>.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Output tensor(s).</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">apply</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Deprecated, do NOT use!</span>

<span class="ss">    This is an alias of `self.__call__`.</span>

<span class="ss">    Arguments:</span>

<span class="ss">      inputs: Input tensor(s).</span>

<span class="ss">      *args: additional positional arguments to be passed to `self.call`.</span>

<span class="ss">      **kwargs: additional keyword arguments to be passed to `self.call`.</span>

<span class="ss">    Returns:</span>

<span class="ss">      Output tensor(s).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.apply` is deprecated and &#39;</span><span class="w"></span>

<span class="w">                  </span><span class="s1">&#39;will be removed in a future version. &#39;</span><span class="w"></span>

<span class="w">                  </span><span class="s1">&#39;Please use `layer.__call__` method instead.&#39;</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">__call__</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="build_2">build</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">build</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_shape</span>
<span class="p">)</span>
</code></pre></div>

<p>Builds the model based on input shapes received.</p>
<p>This is to be used for subclassed models, which do not know at instantiation
time what their inputs look like.</p>
<p>This method only exists for users who want to call <code>model.build()</code> in a
standalone way (as a substitute for calling the model on real data to
build it). It will never be called by the framework (and thus it will
never throw unexpected errors in an unrelated workflow).</p>
<p>Args:
 input_shape: Single tuple, TensorShape, or list/dict of shapes, where
     shapes are tuples, integers, or TensorShapes.</p>
<p>Raises:
  ValueError:
    1. In case of invalid user-provided data (not of type tuple,
       list, TensorShape, or dict).
    2. If the model requires call arguments that are agnostic
       to the input shapes (positional or kwarg in call signature).
    3. If not all layers were properly built.
    4. If float type inputs are not supported within the layers.</p>
<p>In each of these cases, the user should build their model by calling it
  on real tensor data.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="s s-Atom">@generic_utils</span><span class="p">.</span><span class="s s-Atom">default</span>

  <span class="s s-Atom">def</span> <span class="nf">build</span><span class="p">(</span><span class="s s-Atom">self</span><span class="p">,</span> <span class="s s-Atom">input_shape</span><span class="p">)</span><span class="s s-Atom">:</span>

    <span class="s2">&quot;&quot;&quot;Builds the model based on input shapes received.</span>

<span class="s2">    This is to be used for subclassed models, which do not know at instantiation</span>

<span class="s2">    time what their inputs look like.</span>

<span class="s2">    This method only exists for users who want to call `model.build()` in a</span>

<span class="s2">    standalone way (as a substitute for calling the model on real data to</span>

<span class="s2">    build it). It will never be called by the framework (and thus it will</span>

<span class="s2">    never throw unexpected errors in an unrelated workflow).</span>

<span class="s2">    Args:</span>

<span class="s2">     input_shape: Single tuple, TensorShape, or list/dict of shapes, where</span>

<span class="s2">         shapes are tuples, integers, or TensorShapes.</span>

<span class="s2">    Raises:</span>

<span class="s2">      ValueError:</span>

<span class="s2">        1. In case of invalid user-provided data (not of type tuple,</span>

<span class="s2">           list, TensorShape, or dict).</span>

<span class="s2">        2. If the model requires call arguments that are agnostic</span>

<span class="s2">           to the input shapes (positional or kwarg in call signature).</span>

<span class="s2">        3. If not all layers were properly built.</span>

<span class="s2">        4. If float type inputs are not supported within the layers.</span>

<span class="s2">      In each of these cases, the user should build their model by calling it</span>

<span class="s2">      on real tensor data.</span>

<span class="s2">    &quot;&quot;&quot;</span>

    <span class="s s-Atom">if</span> <span class="s s-Atom">self</span><span class="p">.</span><span class="k">_</span><span class="s s-Atom">is_graph_network:</span>

      <span class="nf">super</span><span class="p">(</span><span class="nv">Model</span><span class="p">,</span> <span class="s s-Atom">self</span><span class="p">).</span><span class="nf">build</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>

      <span class="s s-Atom">return</span>

    <span class="s s-Atom">if</span> <span class="s s-Atom">input_shape</span> <span class="o">is</span> <span class="nv">None</span><span class="s s-Atom">:</span>

      <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;Input shape must be defined when calling build on a &#39;</span>

                       <span class="s s-Atom">&#39;model subclass network.&#39;</span><span class="p">)</span>

    <span class="s s-Atom">valid_types</span> <span class="o">=</span> <span class="p">(</span><span class="s s-Atom">tuple</span><span class="p">,</span> <span class="s s-Atom">list</span><span class="p">,</span> <span class="s s-Atom">tensor_shape</span><span class="p">.</span><span class="nv">TensorShape</span><span class="p">,</span> <span class="s s-Atom">dict</span><span class="p">)</span>

    <span class="s s-Atom">if</span> <span class="o">not</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">valid_types</span><span class="p">)</span><span class="s s-Atom">:</span>

      <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;Specified input shape is not one of the valid types. &#39;</span>

                       <span class="s s-Atom">&#39;Please specify a batch input shape of type tuple or &#39;</span>

                       <span class="s s-Atom">&#39;list of input shapes. User provided &#39;</span>

                       <span class="s s-Atom">&#39;input type: {}&#39;</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">type</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)))</span>

    <span class="s s-Atom">if</span> <span class="s s-Atom">input_shape</span> <span class="s s-Atom">and</span> <span class="o">not</span> <span class="s s-Atom">self</span><span class="p">.</span><span class="nn">inputs</span><span class="p">:</span>

      <span class="s s-Atom">#</span> <span class="nv">We</span> <span class="s s-Atom">create</span> <span class="s s-Atom">placeholders</span> <span class="s s-Atom">for</span> <span class="s s-Atom">the</span> <span class="err">`</span><span class="nv">None</span><span class="err">`</span><span class="s s-Atom">s</span> <span class="s s-Atom">in</span> <span class="s s-Atom">the</span> <span class="s s-Atom">shape</span> <span class="s s-Atom">and</span> <span class="s s-Atom">build</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model</span>

      <span class="s s-Atom">#</span> <span class="s s-Atom">in</span> <span class="s s-Atom">a</span> <span class="nv">Graph</span><span class="p">.</span> <span class="nv">Since</span> <span class="s s-Atom">tf</span><span class="p">.</span><span class="nv">Variable</span> <span class="o">is</span> <span class="s s-Atom">compatible</span> <span class="s s-Atom">with</span> <span class="s s-Atom">both</span> <span class="s s-Atom">eager</span> <span class="s s-Atom">execution</span>

      <span class="s s-Atom">#</span> <span class="s s-Atom">and</span> <span class="s s-Atom">graph</span> <span class="s s-Atom">building</span><span class="p">,</span> <span class="s s-Atom">the</span> <span class="s s-Atom">variables</span> <span class="s s-Atom">created</span> <span class="s s-Atom">after</span> <span class="s s-Atom">building</span> <span class="s s-Atom">the</span> <span class="s s-Atom">model</span> <span class="s s-Atom">in</span>

      <span class="s s-Atom">#</span> <span class="s s-Atom">a</span> <span class="nv">Graph</span> <span class="s s-Atom">are</span> <span class="s s-Atom">still</span> <span class="s s-Atom">valid</span> <span class="s s-Atom">when</span> <span class="s s-Atom">executing</span> <span class="s s-Atom">eagerly</span><span class="p">.</span>

      <span class="s s-Atom">if</span> <span class="s s-Atom">context</span><span class="p">.</span><span class="nf">executing_eagerly</span><span class="p">()</span><span class="s s-Atom">:</span>

        <span class="s s-Atom">graph</span> <span class="o">=</span> <span class="s s-Atom">func_graph</span><span class="p">.</span><span class="nv">FuncGraph</span><span class="p">(</span><span class="s s-Atom">&#39;build_graph&#39;</span><span class="p">)</span>

      <span class="nn">else</span><span class="p">:</span>

        <span class="s s-Atom">graph</span> <span class="o">=</span> <span class="s s-Atom">backend</span><span class="p">.</span><span class="nf">get_graph</span><span class="p">()</span>

      <span class="s s-Atom">with</span> <span class="s s-Atom">graph</span><span class="p">.</span><span class="nf">as_default</span><span class="p">()</span><span class="s s-Atom">:</span>

        <span class="nf">if</span> <span class="p">(</span><span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">list</span><span class="p">)</span> <span class="s s-Atom">and</span>

            <span class="nf">all</span><span class="p">(</span><span class="s s-Atom">d</span> <span class="o">is</span> <span class="nv">None</span> <span class="s s-Atom">or</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">d</span><span class="p">,</span> <span class="s s-Atom">int</span><span class="p">)</span> <span class="s s-Atom">for</span> <span class="s s-Atom">d</span> <span class="s s-Atom">in</span> <span class="s s-Atom">input_shape</span><span class="p">))</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">input_shape</span> <span class="o">=</span> <span class="nf">tuple</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>

        <span class="s s-Atom">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">list</span><span class="p">)</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">x</span> <span class="o">=</span> <span class="p">[</span><span class="s s-Atom">base_layer_utils</span><span class="p">.</span><span class="nf">generate_placeholders_from_shape</span><span class="p">(</span><span class="s s-Atom">shape</span><span class="p">)</span>

               <span class="s s-Atom">for</span> <span class="s s-Atom">shape</span> <span class="s s-Atom">in</span> <span class="s s-Atom">input_shape</span><span class="p">]</span>

        <span class="s s-Atom">elif</span> <span class="nf">isinstance</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">,</span> <span class="s s-Atom">dict</span><span class="p">)</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">x</span> <span class="o">=</span> <span class="p">{</span>

              <span class="nn">k</span><span class="p">:</span> <span class="s s-Atom">base_layer_utils</span><span class="p">.</span><span class="nf">generate_placeholders_from_shape</span><span class="p">(</span><span class="s s-Atom">shape</span><span class="p">)</span>

              <span class="s s-Atom">for</span> <span class="s s-Atom">k</span><span class="p">,</span> <span class="s s-Atom">shape</span> <span class="s s-Atom">in</span> <span class="s s-Atom">input_shape</span><span class="p">.</span><span class="nf">items</span><span class="p">()</span>

          <span class="p">}</span>

        <span class="nn">else</span><span class="p">:</span>

          <span class="s s-Atom">x</span> <span class="o">=</span> <span class="s s-Atom">base_layer_utils</span><span class="p">.</span><span class="nf">generate_placeholders_from_shape</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>

        <span class="s s-Atom">kwargs</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="s s-Atom">call_signature</span> <span class="o">=</span> <span class="s s-Atom">self</span><span class="p">.</span><span class="k">_</span><span class="s s-Atom">call_full_argspec</span>

        <span class="s s-Atom">call_args</span> <span class="o">=</span> <span class="s s-Atom">call_signature</span><span class="p">.</span><span class="s s-Atom">args</span>

        <span class="s s-Atom">#</span> <span class="nv">Exclude</span> <span class="err">`</span><span class="s s-Atom">self</span><span class="err">`</span><span class="p">,</span> <span class="err">`</span><span class="s s-Atom">inputs</span><span class="err">`</span><span class="p">,</span> <span class="s s-Atom">and</span> <span class="s s-Atom">any</span> <span class="s s-Atom">argument</span> <span class="s s-Atom">with</span> <span class="s s-Atom">a</span> <span class="s s-Atom">default</span> <span class="s s-Atom">value</span><span class="p">.</span>

        <span class="s s-Atom">if</span> <span class="nf">len</span><span class="p">(</span><span class="s s-Atom">call_args</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">if</span> <span class="s s-Atom">call_signature</span><span class="p">.</span><span class="nn">defaults</span><span class="p">:</span>

            <span class="s s-Atom">call_args</span> <span class="o">=</span> <span class="s s-Atom">call_args</span><span class="p">[</span><span class="mi">2</span><span class="p">:-</span><span class="nf">len</span><span class="p">(</span><span class="s s-Atom">call_signature</span><span class="p">.</span><span class="s s-Atom">defaults</span><span class="p">)]</span>

          <span class="nn">else</span><span class="p">:</span>

            <span class="s s-Atom">call_args</span> <span class="o">=</span> <span class="s s-Atom">call_args</span><span class="p">[</span><span class="mi">2</span><span class="s s-Atom">:</span><span class="p">]</span>

          <span class="s s-Atom">for</span> <span class="s s-Atom">arg</span> <span class="s s-Atom">in</span> <span class="s s-Atom">call_args:</span>

            <span class="s s-Atom">if</span> <span class="s s-Atom">arg</span> <span class="o">==</span> <span class="s s-Atom">&#39;training&#39;:</span>

              <span class="s s-Atom">#</span> <span class="nv">Case</span> <span class="s s-Atom">where</span> <span class="err">`</span><span class="s s-Atom">training</span><span class="err">`</span> <span class="o">is</span> <span class="s s-Atom">a</span> <span class="s s-Atom">positional</span> <span class="s s-Atom">arg</span> <span class="s s-Atom">with</span> <span class="s s-Atom">no</span> <span class="s s-Atom">default</span><span class="p">.</span>

              <span class="s s-Atom">kwargs</span><span class="p">[</span><span class="s s-Atom">&#39;training&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nv">False</span>

            <span class="nn">else</span><span class="p">:</span>

              <span class="s s-Atom">#</span> <span class="nv">Has</span> <span class="s s-Atom">invalid</span> <span class="s s-Atom">call</span> <span class="s s-Atom">signature</span> <span class="s s-Atom">with</span> <span class="s s-Atom">unknown</span> <span class="s s-Atom">positional</span> <span class="s s-Atom">arguments</span><span class="p">.</span>

              <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span>

                  <span class="s s-Atom">&#39;Currently, you cannot build your model if it has &#39;</span>

                  <span class="s s-Atom">&#39;positional or keyword arguments that are not &#39;</span>

                  <span class="s s-Atom">&#39;inputs to the model, but are required for its &#39;</span>

                  <span class="s s-Atom">&#39;`call` method. Instead, in order to instantiate &#39;</span>

                  <span class="s s-Atom">&#39;and build your model, `call` your model on real &#39;</span>

                  <span class="s s-Atom">&#39;tensor data with all expected call arguments.&#39;</span><span class="p">)</span>

        <span class="s s-Atom">elif</span> <span class="nf">len</span><span class="p">(</span><span class="s s-Atom">call_args</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">#</span> <span class="nv">Signature</span> <span class="s s-Atom">without</span> <span class="err">`</span><span class="s s-Atom">inputs</span><span class="err">`</span><span class="p">.</span>

          <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;You can only call `build` on a model if its `call` &#39;</span>

                           <span class="s s-Atom">&#39;method accepts an `inputs` argument.&#39;</span><span class="p">)</span>

        <span class="nn">try</span><span class="p">:</span>

          <span class="s s-Atom">self</span><span class="p">.</span><span class="nf">call</span><span class="p">(</span><span class="s s-Atom">x</span><span class="p">,</span> <span class="s s-Atom">**kwargs</span><span class="p">)</span>

        <span class="nf">except</span> <span class="p">(</span><span class="s s-Atom">errors</span><span class="p">.</span><span class="nv">InvalidArgumentError</span><span class="p">,</span> <span class="nv">TypeError</span><span class="p">)</span><span class="s s-Atom">:</span>

          <span class="s s-Atom">raise</span> <span class="nv">ValueError</span><span class="p">(</span><span class="s s-Atom">&#39;You cannot build your model by calling `build` &#39;</span>

                           <span class="s s-Atom">&#39;if your layers do not support float type inputs. &#39;</span>

                           <span class="s s-Atom">&#39;Instead, in order to instantiate and build your &#39;</span>

                           <span class="s s-Atom">&#39;model, `call` your model on real tensor data (of &#39;</span>

                           <span class="s s-Atom">&#39;the correct dtype).&#39;</span><span class="p">)</span>

    <span class="nf">super</span><span class="p">(</span><span class="nv">Model</span><span class="p">,</span> <span class="s s-Atom">self</span><span class="p">).</span><span class="nf">build</span><span class="p">(</span><span class="s s-Atom">input_shape</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="call_2">call</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">training</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference in training.</p>
<p>Arguments:</p>
<ul>
<li>
<p><em>inputs</em>: Tuple</p>
<ol>
<li>images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</li>
<li>image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape
of the image without any padding.</li>
<li>images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None] composed of 0 and 1 which allows to know where a padding has been applied.</li>
</ol>
</li>
<li>
<p><em>training</em>: Is automatically set to <code>True</code> in train mode</p>
</li>
</ul>
<p>Returns:</p>
<ul>
<li><em>logits</em>: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</li>
<li><em>boxes</em>: A Tensor of shape [batch_size, num_queries, 4]</li>
</ul>
<p>where h is num_queries * transformer_decoder.transformer_num_layers if
training is true and num_queries otherwise.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="k">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Perform an inference in training.</span>

<span class="s2">        Arguments:</span>

<span class="s2">        - *inputs*: Tuple</span>

<span class="s2">            1. images: A 4-D tensor of float32 and shape [batch_size, None, None, 3]</span>

<span class="s2">            2. image_informations: A 1D tensor of float32 and shape [(height, width),]. It contains the shape</span>

<span class="s2">            of the image without any padding.</span>

<span class="s2">            3. images_padding_mask: A 3D tensor of int8 and shape [batch_size, None, None] composed of 0 and 1 which allows to know where a padding has been applied.</span>

<span class="s2">        - *training*: Is automatically set to `True` in train mode</span>

<span class="s2">        Returns:</span>

<span class="s2">        - *logits*: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="s2">        - *boxes*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="s2">        where h is num_queries * transformer_decoder.transformer_num_layers if</span>

<span class="s2">        training is true and num_queries otherwise.</span>

<span class="s2">        </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="n">images</span> <span class="o">=</span> <span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="err">]</span>

        <span class="n">images_padding_masks</span> <span class="o">=</span> <span class="n">inputs</span><span class="err">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES_PMASK</span><span class="err">]</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

        <span class="c1"># The preprocessing dedicated to the backbone is done inside the model.</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">backbone</span><span class="p">(</span><span class="n">images</span><span class="p">)</span><span class="err">[</span><span class="o">-</span><span class="mi">1</span><span class="err">]</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">images_padding_masks</span><span class="err">[</span><span class="p">...,</span> <span class="k">None</span><span class="err">]</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span>

                                        <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="err">[</span><span class="mi">1</span><span class="o">:</span><span class="mi">3</span><span class="err">]</span><span class="p">,</span>

                                        <span class="n">method</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">ResizeMethod</span><span class="p">.</span><span class="n">NEAREST_NEIGHBOR</span><span class="p">)</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span> <span class="n">tf</span><span class="p">.</span><span class="kt">bool</span><span class="p">)</span>

        <span class="c1"># Positional_encoding for the backbone</span>

        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">pos_embed</span><span class="p">(</span><span class="n">features_mask</span><span class="p">)</span>

        <span class="c1"># [batch_size, num_queries, self.hidden_dim]</span>

        <span class="n">all_the_queries</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">all_the_queries</span><span class="err">[</span><span class="k">None</span><span class="err">]</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># [batch_size, num_queries, self.hidden_dim]</span>

        <span class="n">query_embed</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">query_embed</span><span class="p">(</span><span class="n">all_the_queries</span><span class="p">)</span>

        <span class="c1"># add positional_encoding to x [batch_size, h, w, self.hidden_dim]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">input_proj</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Flatten the position embedding and the spatial tensor</span>

        <span class="c1"># to allow the preprocessing by the Transformer</span>

        <span class="c1"># [batch_size, h * w,  self.hidden_dim]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pos_embed</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">hidden_dim</span><span class="p">))</span>

        <span class="c1"># Flatten the padding masks</span>

        <span class="n">features_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features_mask</span><span class="p">,</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">decoder_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">transformer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>

                                          <span class="n">pos_embed</span><span class="p">,</span>

                                          <span class="n">query_embed</span><span class="p">,</span>

                                          <span class="n">key_padding_mask</span><span class="o">=</span><span class="n">features_mask</span><span class="p">,</span>

                                          <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="n">boxes</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">bbox_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">class_embed</span><span class="p">(</span><span class="n">decoder_out</span><span class="p">)</span>

        <span class="k">return</span> <span class="err">{</span>

            <span class="n">BoxField</span><span class="p">.</span><span class="n">SCORES</span><span class="o">:</span> <span class="n">logits</span><span class="p">,</span>

            <span class="n">BoxField</span><span class="p">.</span><span class="n">BOXES</span><span class="o">:</span> <span class="n">boxes</span><span class="p">,</span>

        <span class="err">}</span>
</code></pre></div>

</details>
<h4 id="compile_2">compile</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">loss_weights</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">weighted_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">run_eagerly</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps_per_execution</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Configures the model for training.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>optimizer</td>
<td>None</td>
<td>String (name of optimizer) or optimizer instance. See</td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.optimizers</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>loss</td>
<td>None</td>
<td>String (name of objective function), objective function or</td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.losses.Loss</code> instance. See <code>tf.keras.losses</code>. An objective</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function is any callable with the signature `loss = fn(y_true,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>y_pred)`, where y_true = ground truth values with shape =</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>[batch_size, d0, .. dN]</code>, except sparse loss functions such as sparse</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>categorical crossentropy where shape = <code>[batch_size, d0, .. dN-1]</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>y_pred = predicted values with shape = <code>[batch_size, d0, .. dN]</code>. It</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returns a weighted loss float tensor. If a custom <code>Loss</code> instance is</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>used and reduction is set to NONE, return value has the shape</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>[batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>otherwise, it is a scalar. If the model has multiple outputs, you can</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>use a different loss on each output by passing a dictionary or a list</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of losses. The loss value that will be minimized by the model will</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>then be the sum of all individual losses.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>metrics</td>
<td>None</td>
<td>List of metrics to be evaluated by the model during training</td>
<td></td>
</tr>
<tr>
<td>and testing. Each of this can be a string (name of a built-in</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function), function or a <code>tf.keras.metrics.Metric</code> instance. See</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics</code>. Typically you will use <code>metrics=['accuracy']</code>. A</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function is any callable with the signature `result = fn(y_true,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>y_pred)`. To specify different metrics for different outputs of a</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>multi-output model, you could also pass a dictionary, such as</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>You can also pass a list (len = len(outputs)) of lists of metrics</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>such as <code>metrics=[['accuracy'], ['accuracy', 'mse']]</code> or</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>metrics=['accuracy', ['accuracy', 'mse']]</code>. When you pass the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>strings 'accuracy' or 'acc', we convert this to one of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics.BinaryAccuracy</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics.CategoricalAccuracy</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.keras.metrics.SparseCategoricalAccuracy</code> based on the loss</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>function used and the model output shape. We do a similar</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>conversion for the strings 'crossentropy' and 'ce' as well.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>loss_weights</td>
<td>None</td>
<td>Optional list or dictionary specifying scalar coefficients</td>
<td></td>
</tr>
<tr>
<td>(Python floats) to weight the loss contributions of different model</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>outputs. The loss value that will be minimized by the model will then</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>be the <em>weighted sum</em> of all individual losses, weighted by the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>loss_weights</code> coefficients.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>If a list, it is expected to have a 1:1 mapping to the model's</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>outputs. If a dict, it is expected to map output names (strings)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>to scalar coefficients.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>weighted_metrics</td>
<td>None</td>
<td>List of metrics to be evaluated and weighted by</td>
<td></td>
</tr>
<tr>
<td>sample_weight or class_weight during training and testing.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>run_eagerly</td>
<td>None</td>
<td>Bool. Defaults to <code>False</code>. If <code>True</code>, this <code>Model</code>'s</td>
<td></td>
</tr>
<tr>
<td>logic will not be wrapped in a <code>tf.function</code>. Recommended to leave</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>this as <code>None</code> unless your <code>Model</code> cannot be run inside a</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>tf.function</code>.</td>
<td><code>False</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td>steps_per_execution</td>
<td>None</td>
<td>Int. Defaults to 1. The number of batches to</td>
<td></td>
</tr>
<tr>
<td>run during each <code>tf.function</code> call. Running multiple batches</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>inside a single <code>tf.function</code> call can greatly improve performance</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>on TPUs or small models with a large Python overhead.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>At most, one full epoch will be run each</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>execution. If a number larger than the size of the epoch is passed,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the execution will be truncated to the size of the epoch.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Note that if <code>steps_per_execution</code> is set to <code>N</code>,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>Callback.on_batch_begin</code> and <code>Callback.on_batch_end</code> methods</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>will only be called every <code>N</code> batches</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(i.e. before/after each <code>tf.function</code> execution).</td>
<td>1</td>
<td></td>
<td></td>
</tr>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Arguments supported for backwards compatibility only.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>In case of invalid arguments for</td>
</tr>
<tr>
<td><code>optimizer</code>, <code>loss</code> or <code>metrics</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">compile</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

              <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>

              <span class="n">loss</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">metrics</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">loss_weights</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">weighted_metrics</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">run_eagerly</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">steps_per_execution</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Configures the model for training.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        optimizer: String (name of optimizer) or optimizer instance. See</span>

<span class="s2">          `tf.keras.optimizers`.</span>

<span class="s2">        loss: String (name of objective function), objective function or</span>

<span class="s2">          `tf.keras.losses.Loss` instance. See `tf.keras.losses`. An objective</span>

<span class="s2">          function is any callable with the signature `loss = fn(y_true,</span>

<span class="s2">          y_pred)`, where y_true = ground truth values with shape =</span>

<span class="s2">          `[batch_size, d0, .. dN]`, except sparse loss functions such as sparse</span>

<span class="s2">          categorical crossentropy where shape = `[batch_size, d0, .. dN-1]`.</span>

<span class="s2">          y_pred = predicted values with shape = `[batch_size, d0, .. dN]`. It</span>

<span class="s2">          returns a weighted loss float tensor. If a custom `Loss` instance is</span>

<span class="s2">          used and reduction is set to NONE, return value has the shape</span>

<span class="s2">          [batch_size, d0, .. dN-1] ie. per-sample or per-timestep loss values;</span>

<span class="s2">          otherwise, it is a scalar. If the model has multiple outputs, you can</span>

<span class="s2">          use a different loss on each output by passing a dictionary or a list</span>

<span class="s2">          of losses. The loss value that will be minimized by the model will</span>

<span class="s2">          then be the sum of all individual losses.</span>

<span class="s2">        metrics: List of metrics to be evaluated by the model during training</span>

<span class="s2">          and testing. Each of this can be a string (name of a built-in</span>

<span class="s2">          function), function or a `tf.keras.metrics.Metric` instance. See</span>

<span class="s2">          `tf.keras.metrics`. Typically you will use `metrics=[&#39;accuracy&#39;]`. A</span>

<span class="s2">          function is any callable with the signature `result = fn(y_true,</span>

<span class="s2">          y_pred)`. To specify different metrics for different outputs of a</span>

<span class="s2">          multi-output model, you could also pass a dictionary, such as</span>

<span class="s2">            `metrics={&#39;output_a&#39;: &#39;accuracy&#39;, &#39;output_b&#39;: [&#39;accuracy&#39;, &#39;mse&#39;]}`.</span>

<span class="s2">              You can also pass a list (len = len(outputs)) of lists of metrics</span>

<span class="s2">              such as `metrics=[[&#39;accuracy&#39;], [&#39;accuracy&#39;, &#39;mse&#39;]]` or</span>

<span class="s2">              `metrics=[&#39;accuracy&#39;, [&#39;accuracy&#39;, &#39;mse&#39;]]`. When you pass the</span>

<span class="s2">              strings &#39;accuracy&#39; or &#39;acc&#39;, we convert this to one of</span>

<span class="s2">              `tf.keras.metrics.BinaryAccuracy`,</span>

<span class="s2">              `tf.keras.metrics.CategoricalAccuracy`,</span>

<span class="s2">              `tf.keras.metrics.SparseCategoricalAccuracy` based on the loss</span>

<span class="s2">              function used and the model output shape. We do a similar</span>

<span class="s2">              conversion for the strings &#39;crossentropy&#39; and &#39;ce&#39; as well.</span>

<span class="s2">        loss_weights: Optional list or dictionary specifying scalar coefficients</span>

<span class="s2">          (Python floats) to weight the loss contributions of different model</span>

<span class="s2">          outputs. The loss value that will be minimized by the model will then</span>

<span class="s2">          be the *weighted sum* of all individual losses, weighted by the</span>

<span class="s2">          `loss_weights` coefficients.</span>

<span class="s2">            If a list, it is expected to have a 1:1 mapping to the model&#39;s</span>

<span class="s2">              outputs. If a dict, it is expected to map output names (strings)</span>

<span class="s2">              to scalar coefficients.</span>

<span class="s2">        weighted_metrics: List of metrics to be evaluated and weighted by</span>

<span class="s2">          sample_weight or class_weight during training and testing.</span>

<span class="s2">        run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`&#39;s</span>

<span class="s2">          logic will not be wrapped in a `tf.function`. Recommended to leave</span>

<span class="s2">          this as `None` unless your `Model` cannot be run inside a</span>

<span class="s2">          `tf.function`.</span>

<span class="s2">        steps_per_execution: Int. Defaults to 1. The number of batches to</span>

<span class="s2">          run during each `tf.function` call. Running multiple batches</span>

<span class="s2">          inside a single `tf.function` call can greatly improve performance</span>

<span class="s2">          on TPUs or small models with a large Python overhead.</span>

<span class="s2">          At most, one full epoch will be run each</span>

<span class="s2">          execution. If a number larger than the size of the epoch is passed,</span>

<span class="s2">          the execution will be truncated to the size of the epoch.</span>

<span class="s2">          Note that if `steps_per_execution` is set to `N`,</span>

<span class="s2">          `Callback.on_batch_begin` and `Callback.on_batch_end` methods</span>

<span class="s2">          will only be called every `N` batches</span>

<span class="s2">          (i.e. before/after each `tf.function` execution).</span>

<span class="s2">        **kwargs: Arguments supported for backwards compatibility only.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: In case of invalid arguments for</span>

<span class="s2">            `optimizer`, `loss` or `metrics`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;compile&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="k">if</span> <span class="s1">&#39;experimental_steps_per_execution&#39;</span> <span class="k">in</span> <span class="n">kwargs</span><span class="o">:</span>

        <span class="n">logging</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;The argument `steps_per_execution` is no longer &#39;</span>

                     <span class="s1">&#39;experimental. Pass `steps_per_execution` instead of &#39;</span>

                     <span class="s1">&#39;`experimental_steps_per_execution`.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="k">not</span> <span class="n">steps_per_execution</span><span class="o">:</span>

          <span class="n">steps_per_execution</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;experimental_steps_per_execution&#39;</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_validate_compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_run_eagerly</span> <span class="o">=</span> <span class="n">run_eagerly</span>

      <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_get_optimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span> <span class="o">=</span> <span class="n">compile_utils</span><span class="p">.</span><span class="n">LossesContainer</span><span class="p">(</span>

          <span class="n">loss</span><span class="p">,</span> <span class="n">loss_weights</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">compiled_metrics</span> <span class="o">=</span> <span class="n">compile_utils</span><span class="p">.</span><span class="n">MetricsContainer</span><span class="p">(</span>

          <span class="n">metrics</span><span class="p">,</span> <span class="n">weighted_metrics</span><span class="p">,</span> <span class="n">output_names</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">output_names</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_configure_steps_per_execution</span><span class="p">(</span><span class="n">steps_per_execution</span> <span class="k">or</span> <span class="mi">1</span><span class="p">)</span>

      <span class="c1"># Initializes attrs that are reset each time `compile` is called.</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_reset_compile_cache</span><span class="p">()</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_is_compiled</span> <span class="o">=</span> <span class="no">True</span>

      <span class="n">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="k">or</span> <span class="err">{}</span>  <span class="c1"># Backwards compat.</span>
</code></pre></div>

</details>
<h4 id="compute_loss_2">compute_loss</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">ground_truths</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">y_pred</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">input_shape</span><span class="p">:</span> <span class="n">tensorflow</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span>
</code></pre></div>

<p>Apply the GIoU, L1 and SCC to each layers of the transformer decoder</p>
<p>Arguments:</p>
<ul>
<li><em>ground_truths</em>:
   see output kerod.dataset.preprocessing for the doc</li>
<li><em>y_pred</em>: A dict<ul>
<li>*scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</li>
<li><em>bbox</em>: A Tensor of shape [batch_size, num_queries, 4]</li>
</ul>
</li>
<li><em>input_shape</em>: [height, width] of the input tensor. It is the shape of the images will all the
padding included. It is used to normalize the ground_truths boxes.</li>
</ul>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="n">compute_loss</span><span class="p">(</span><span class="w"></span>

<span class="w">        </span><span class="n">self</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">ground_truths</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">y_pred</span><span class="p">:</span><span class="w"> </span><span class="n">Dict</span><span class="o">[</span><span class="n">str, tf.Tensor</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">        </span><span class="nl">input_shape</span><span class="p">:</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span><span class="w"></span>

<span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="nc">int</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="ss">&quot;&quot;&quot;Apply the GIoU, L1 and SCC to each layers of the transformer decoder</span>

<span class="ss">        Arguments:</span>

<span class="ss">        - *ground_truths*:</span>

<span class="ss">           see output kerod.dataset.preprocessing for the doc</span>

<span class="ss">        - *y_pred*: A dict</span>

<span class="ss">            - *scores: A Tensor of shape [batch_size, num_queries, num_classes + 1] class logits</span>

<span class="ss">            - *bbox*: A Tensor of shape [batch_size, num_queries, 4]</span>

<span class="ss">        - *input_shape*: [height, width] of the input tensor. It is the shape of the images will all the</span>

<span class="ss">        padding included. It is used to normalize the ground_truths boxes.</span>

<span class="ss">        &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">        </span><span class="n">normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">input_shape</span><span class="o">[</span><span class="n">None</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">1, 2</span><span class="o">]</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">centered_normalized_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">convert_to_center_coordinates</span><span class="p">(</span><span class="n">normalized_boxes</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">{</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="k">add</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">because</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">background</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">counted</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">ground_truths</span><span class="w"> </span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">LABELS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.LABELS</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">centered_normalized_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">WEIGHTS</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.WEIGHTS</span><span class="o">]</span><span class="p">,</span><span class="w"></span>

<span class="w">            </span><span class="n">BoxField</span><span class="p">.</span><span class="nl">NUM_BOXES</span><span class="p">:</span><span class="w"></span>

<span class="w">                </span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="err">}</span><span class="w"></span>

<span class="w">        </span><span class="n">boxes_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.BOXES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">logits_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="n">y_pred</span><span class="o">[</span><span class="n">BoxField.SCORES</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">y_pred_per_lvl</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">{</span>

<span class="n">            BoxField.BOXES: boxes,</span>

<span class="n">            BoxField.SCORES: logits</span>

<span class="n">        } for boxes, logits in zip(boxes_per_lvl, logits_per_lvl)</span><span class="o">]</span><span class="w"></span>

<span class="w">        </span><span class="n">num_boxes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="nf">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">ground_truths</span><span class="o">[</span><span class="n">BoxField.NUM_BOXES</span><span class="o">]</span><span class="p">),</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="n">loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"></span>

<span class="w">        </span><span class="err">#</span><span class="w"> </span><span class="k">Compute</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Giou</span><span class="p">,</span><span class="w"> </span><span class="n">L1</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">SCC</span><span class="w"> </span><span class="k">at</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="n">layers</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">transformer</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">enumerate</span><span class="p">(</span><span class="n">y_pred_per_lvl</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">            </span><span class="err">#</span><span class="w"> </span><span class="n">Logs</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">metrics</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">last</span><span class="w"> </span><span class="n">layer</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">decoder</span><span class="w"></span>

<span class="w">            </span><span class="n">compute_metrics</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">transformer_num_layers</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w"></span>

<span class="w">            </span><span class="n">loss</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">ground_truths</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">num_boxes</span><span class="p">,</span><span class="w"></span>

<span class="w">                                       </span><span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">)</span><span class="w"></span>

<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="n">loss</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_mask_2">compute_mask</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_mask</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span><span class="p">,</span>
    <span class="n">mask</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Computes an output mask tensor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Tensor or list of tensors.</td>
<td>None</td>
</tr>
<tr>
<td>mask</td>
<td>None</td>
<td>Tensor or list of tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>None or a tensor (or list of tensors,</td>
</tr>
<tr>
<td>one per output tensor of the layer).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@generic_utils</span><span class="p">.</span><span class="k">default</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">compute_mask</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">mask</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="err">:</span><span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="nl">pylint</span><span class="p">:</span><span class="w"> </span><span class="n">disable</span><span class="o">=</span><span class="n">unused</span><span class="o">-</span><span class="n">argument</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Computes an output mask tensor.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        inputs: Tensor or list of tensors.</span>

<span class="ss">        mask: Tensor or list of tensors.</span>

<span class="ss">    Returns:</span>

<span class="ss">        None or a tensor (or list of tensors,</span>

<span class="ss">            one per output tensor of the layer).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="nl">_supports_masking</span><span class="p">:</span><span class="w"></span>

<span class="w">      </span><span class="k">if</span><span class="w"> </span><span class="ow">any</span><span class="p">(</span><span class="n">m</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">m</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span><span class="err">:</span><span class="w"></span>

<span class="w">        </span><span class="n">raise</span><span class="w"> </span><span class="n">TypeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">name</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s1">&#39; does not support masking, &#39;</span><span class="w"></span>

<span class="w">                        </span><span class="s1">&#39;but was passed an input_mask: &#39;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nf">str</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span><span class="w"></span>

<span class="w">      </span><span class="err">#</span><span class="w"> </span><span class="n">masking</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="nl">supported</span><span class="p">:</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="k">None</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">mask</span><span class="p">.</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="k">None</span><span class="w"></span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">masking</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="n">supported</span><span class="p">,</span><span class="w"> </span><span class="k">by</span><span class="w"> </span><span class="k">default</span><span class="w"></span>

<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="n">carry</span><span class="w"> </span><span class="k">over</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">input</span><span class="w"> </span><span class="n">mask</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">mask</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="compute_output_shape_2">compute_output_shape</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_shape</span>
<span class="p">)</span>
</code></pre></div>

<p>Computes the output shape of the layer.</p>
<p>If the layer has not been built, this method will call <code>build</code> on the
layer. This assumes that the layer will later be used with inputs that
match the input shape provided here.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_shape</td>
<td>None</td>
<td>Shape tuple (tuple of integers)</td>
<td></td>
</tr>
<tr>
<td>or list of shape tuples (one per output tensor of the layer).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Shape tuples can include None for free dimensions,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>instead of an integer.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>An input shape tuple.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">compute_output_shape</span>(<span class="nb">self</span>, <span class="n">input_shape</span>):

    <span class="s">&quot;&quot;&quot;Computes the output shape of the layer.</span>

<span class="s">    If the layer has not been built, this method will call `build` on the</span>

<span class="s">    layer. This assumes that the layer will later be used with inputs that</span>

<span class="s">    match the input shape provided here.</span>

<span class="s">    Arguments:</span>

<span class="s">        input_shape: Shape tuple (tuple of integers)</span>

<span class="s">            or list of shape tuples (one per output tensor of the layer).</span>

<span class="s">            Shape tuples can include None for free dimensions,</span>

<span class="s">            instead of an integer.</span>

<span class="s">    Returns:</span>

<span class="s">        An input shape tuple.</span>

<span class="s">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">context</span>.<span class="n">executing_eagerly</span>():

      <span class="c1"># In this case we build the model first in order to do shape inference.</span>

      <span class="c1"># This is acceptable because the framework only calls</span>

      <span class="c1"># `compute_output_shape` on shape values that the layer would later be</span>

      <span class="c1"># built for. It would however cause issues in case a user attempts to</span>

      <span class="c1"># use `compute_output_shape` manually with shapes that are incompatible</span>

      <span class="c1"># with the shape the Layer will be called on (these users will have to</span>

      <span class="c1"># implement `compute_output_shape` themselves).</span>

      <span class="nb">self</span>.<span class="n">_maybe_build</span>(<span class="n">input_shape</span>)

      <span class="k">with</span> <span class="n">func_graph</span>.<span class="n">FuncGraph</span>(<span class="n">str</span>(<span class="nb">self</span>.<span class="nb">name</span>) + <span class="s">&#39;_scratch_graph&#39;</span>).<span class="n">as_default</span>():

        <span class="n">input_shape</span> = <span class="n">tf_utils</span>.<span class="n">convert_shapes</span>(<span class="n">input_shape</span>, <span class="n">to_tuples</span>=<span class="nb">False</span>)

        <span class="n">def</span> <span class="n">_make_placeholder_like</span>(<span class="nb">shape</span>):

          <span class="n">ph</span> = <span class="n">backend</span>.<span class="nb">placeholder</span>(<span class="nb">shape</span>=<span class="nb">shape</span>, <span class="n">dtype</span>=<span class="nb">self</span>.<span class="n">dtype</span>)

          <span class="n">ph</span>.<span class="n">_keras_mask</span> = <span class="n">None</span>

          <span class="k">return</span> <span class="n">ph</span>

        <span class="n">inputs</span> = <span class="n">nest</span>.<span class="n">map_structure</span>(<span class="n">_make_placeholder_like</span>, <span class="n">input_shape</span>)

        <span class="n">try:</span>

          <span class="n">outputs</span> = <span class="nb">self</span>(<span class="n">inputs</span>, <span class="n">training</span>=<span class="nb">False</span>)

        <span class="n">except</span> <span class="n">TypeError</span> <span class="n">as</span> <span class="n">e:</span>

          <span class="n">six</span>.<span class="n">raise_from</span>(

              <span class="n">NotImplementedError</span>(

                  <span class="s">&#39;We could not automatically infer the static shape of the &#39;</span>

                  <span class="s">&#39;layer\&#39;s output. Please implement the &#39;</span>

                  <span class="s">&#39;`compute_output_shape` method on your layer (%s).&#39;</span> %

                  <span class="nb">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>), <span class="nb">e</span>)

      <span class="k">return</span> <span class="n">nest</span>.<span class="n">map_structure</span>(<span class="n">lambda</span> <span class="n">t:</span> <span class="nb">t</span>.<span class="nb">shape</span>, <span class="n">outputs</span>)

    <span class="n">raise</span> <span class="n">NotImplementedError</span>(

        <span class="s">&#39;Please run in eager mode or implement the `compute_output_shape` &#39;</span>

        <span class="s">&#39;method on your layer (%s).&#39;</span> % <span class="nb">self</span>.<span class="n">__class__</span>.<span class="n">__name__</span>)
</code></pre></div>

</details>
<h4 id="compute_output_signature_2">compute_output_signature</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">compute_output_signature</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">input_signature</span>
<span class="p">)</span>
</code></pre></div>

<p>Compute the output tensor signature of the layer based on the inputs.</p>
<p>Unlike a TensorShape object, a TensorSpec object contains both shape
and dtype information for a tensor. This method allows layers to provide
output dtype information if it is different from the input dtype.
For any layer that doesn't implement this function,
the framework will fall back to use <code>compute_output_shape</code>, and will
assume that the output dtype matches the input dtype.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>input_signature</td>
<td>None</td>
<td>Single TensorSpec or nested structure of TensorSpec</td>
<td></td>
</tr>
<tr>
<td>objects, describing a candidate input for the layer.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Single TensorSpec or nested structure of TensorSpec objects, describing</td>
</tr>
<tr>
<td>how the layer would transform the provided input.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>TypeError</td>
<td>If input_signature contains a non-TensorSpec object.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.for_subclass_implementers</span>

  <span class="n">def</span> <span class="n">compute_output_signature</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">input_signature</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Compute the output tensor signature of the layer based on the inputs.</span>

<span class="s2">    Unlike a TensorShape object, a TensorSpec object contains both shape</span>

<span class="s2">    and dtype information for a tensor. This method allows layers to provide</span>

<span class="s2">    output dtype information if it is different from the input dtype.</span>

<span class="s2">    For any layer that doesn&#39;t implement this function,</span>

<span class="s2">    the framework will fall back to use `compute_output_shape`, and will</span>

<span class="s2">    assume that the output dtype matches the input dtype.</span>

<span class="s2">    Args:</span>

<span class="s2">      input_signature: Single TensorSpec or nested structure of TensorSpec</span>

<span class="s2">        objects, describing a candidate input for the layer.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Single TensorSpec or nested structure of TensorSpec objects, describing</span>

<span class="s2">        how the layer would transform the provided input.</span>

<span class="s2">    Raises:</span>

<span class="s2">      TypeError: If input_signature contains a non-TensorSpec object.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">def</span> <span class="n">check_type_return_shape</span><span class="p">(</span><span class="n">s</span><span class="p">)</span><span class="o">:</span>

      <span class="k">if</span> <span class="k">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tensor_spec</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">)</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">TypeError</span><span class="p">(</span>

            <span class="s1">&#39;Only TensorSpec signature types are supported, &#39;</span>

            <span class="s1">&#39;but saw signature signature entry: {}.&#39;</span><span class="p">.</span><span class="k">format</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>

      <span class="k">return</span> <span class="n">s</span><span class="p">.</span><span class="n">shape</span>

    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">check_type_return_shape</span><span class="p">,</span> <span class="n">input_signature</span><span class="p">)</span>

    <span class="n">output_shape</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

    <span class="n">dtype</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_compute_dtype</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">input_dtypes</span> <span class="o">=</span> <span class="err">[</span><span class="n">s</span><span class="p">.</span><span class="n">dtype</span> <span class="k">for</span> <span class="n">s</span> <span class="k">in</span> <span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">input_signature</span><span class="p">)</span><span class="err">]</span>

      <span class="c1"># Default behavior when self.dtype is None, is to use the first input&#39;s</span>

      <span class="c1"># dtype.</span>

      <span class="n">dtype</span> <span class="o">=</span> <span class="n">input_dtypes</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

    <span class="k">return</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span>

        <span class="n">lambda</span> <span class="n">s</span><span class="o">:</span> <span class="n">tensor_spec</span><span class="p">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">s</span><span class="p">),</span>

        <span class="n">output_shape</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="count_params_2">count_params</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">count_params</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Count the total number of scalars composing the weights.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>An integer count.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if the layer isn't yet built</td>
</tr>
<tr>
<td>(in which case its weights aren't yet defined).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">count_params</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Count the total number of scalars composing the weights.</span>

<span class="s2">    Returns:</span>

<span class="s2">        An integer count.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: if the layer isn&#39;t yet built</span>

<span class="s2">          (in which case its weights aren&#39;t yet defined).</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_is_graph_network&#39;</span><span class="p">,</span> <span class="no">False</span><span class="p">)</span><span class="o">:</span>

        <span class="k">with</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">maybe_init_scope</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

          <span class="n">self</span><span class="p">.</span><span class="n">_maybe_build</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">inputs</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;You tried to call `count_params` on &#39;</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="k">name</span> <span class="o">+</span>

                         <span class="s1">&#39;, but the layer isn</span><span class="se">\&#39;</span><span class="s1">t built. &#39;</span>

                         <span class="s1">&#39;You can build it manually via: `&#39;</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="k">name</span> <span class="o">+</span>

                         <span class="s1">&#39;.build(batch_input_shape)`.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">layer_utils</span><span class="p">.</span><span class="n">count_params</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="evaluate_2">evaluate</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the loss value &amp; metrics values for the model in test mode.</p>
<p>Computation is done in batches (see the <code>batch_size</code> arg.)</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:</td>
<td></td>
</tr>
<tr>
<td>- A Numpy array (or array-like), or a list of arrays</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A TensorFlow tensor, or a list of tensors</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A dict mapping input names to the corresponding array/tensors,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>if the model has named inputs.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A <code>tf.data</code> dataset. Should return a tuple</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of either <code>(inputs, targets)</code> or</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>(inputs, targets, sample_weights)</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>or <code>(inputs, targets, sample_weights)</code>.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>A more detailed description of unpacking behavior for iterator types</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(Dataset, generator, Sequence) is given in the `Unpacking behavior</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>for iterator-like inputs<code>section of</code>Model.fit`.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy</td>
<td></td>
</tr>
<tr>
<td>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(you cannot have Numpy inputs and tensor targets, or inversely). If</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>x</code> is a dataset, generator or <code>keras.utils.Sequence</code> instance, <code>y</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>should not be specified (since targets will be obtained from the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>iterator/dataset).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Integer or <code>None</code>. Number of samples per batch of</td>
<td></td>
</tr>
<tr>
<td>computation. If unspecified, <code>batch_size</code> will default to 32. Do not</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>specify the <code>batch_size</code> if your data is in the form of a dataset,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>generators, or <code>keras.utils.Sequence</code> instances (since they generate</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>batches).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>verbose</td>
<td>None</td>
<td>0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</td>
<td>None</td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional Numpy array of weights for the test samples,</td>
<td></td>
</tr>
<tr>
<td>used for weighting the loss function. You can either pass a flat (1D)</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Numpy array with the same length as the input samples</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(1:1 mapping between weights and samples), or in the case of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>temporal data, you can pass a 2D array with shape `(samples,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sequence_length)`, to apply a different weight to every timestep</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of every sample. This argument is not supported when <code>x</code> is a</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>dataset, instead pass sample weights as the third element of <code>x</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>steps</td>
<td>None</td>
<td>Integer or <code>None</code>. Total number of steps (batches of samples)</td>
<td></td>
</tr>
<tr>
<td>before declaring the evaluation round finished. Ignored with the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>default value of <code>None</code>. If x is a <code>tf.data</code> dataset and <code>steps</code> is</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>None, 'evaluate' will run until the dataset is exhausted. This</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>argument is not supported with array inputs.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>callbacks</td>
<td>None</td>
<td>List of <code>keras.callbacks.Callback</code> instances. List of</td>
<td></td>
</tr>
<tr>
<td>callbacks to apply during evaluation. See</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>max_queue_size</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code></td>
<td></td>
</tr>
<tr>
<td>input only. Maximum size for the generator queue. If unspecified,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>max_queue_size</code> will default to 10.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>workers</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input</td>
<td></td>
</tr>
<tr>
<td>only. Maximum number of processes to spin up when using process-based</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>threading. If unspecified, <code>workers</code> will default to 1. If 0, will</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>execute the generator on the main thread.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>None</td>
<td>Boolean. Used for generator or</td>
<td></td>
</tr>
<tr>
<td><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>threading. If unspecified, <code>use_multiprocessing</code> will default to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>False</code>. Note that because this implementation relies on</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>multiprocessing, you should not pass non-picklable arguments to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>generator as they can't be passed easily to children processes.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,</td>
<td></td>
</tr>
<tr>
<td>with each key being the name of the metric. If <code>False</code>, they are</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returned as a list.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>See the discussion of <code>Unpacking behavior for iterator-like inputs</code> for
<code>Model.fit</code>. | None |</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)</td>
</tr>
<tr>
<td>or list of scalars (if the model has multiple outputs</td>
<td></td>
</tr>
<tr>
<td>and/or metrics). The attribute <code>model.metrics_names</code> will give you</td>
<td></td>
</tr>
<tr>
<td>the display labels for the scalar outputs.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.evaluate</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>in case of invalid arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

               <span class="n">x</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

               <span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

               <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

               <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

               <span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">,</span>

               <span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns the loss value &amp; metrics values for the model in test mode.</span>

<span class="s2">    Computation is done in batches (see the `batch_size` arg.)</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">            if the model has named inputs.</span>

<span class="s2">          - A `tf.data` dataset. Should return a tuple</span>

<span class="s2">            of either `(inputs, targets)` or</span>

<span class="s2">            `(inputs, targets, sample_weights)`.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="s2">            or `(inputs, targets, sample_weights)`.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely). If</span>

<span class="s2">          `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`</span>

<span class="s2">          should not be specified (since targets will be obtained from the</span>

<span class="s2">          iterator/dataset).</span>

<span class="s2">        batch_size: Integer or `None`. Number of samples per batch of</span>

<span class="s2">          computation. If unspecified, `batch_size` will default to 32. Do not</span>

<span class="s2">          specify the `batch_size` if your data is in the form of a dataset,</span>

<span class="s2">          generators, or `keras.utils.Sequence` instances (since they generate</span>

<span class="s2">          batches).</span>

<span class="s2">        verbose: 0 or 1. Verbosity mode. 0 = silent, 1 = progress bar.</span>

<span class="s2">        sample_weight: Optional Numpy array of weights for the test samples,</span>

<span class="s2">          used for weighting the loss function. You can either pass a flat (1D)</span>

<span class="s2">          Numpy array with the same length as the input samples</span>

<span class="s2">            (1:1 mapping between weights and samples), or in the case of</span>

<span class="s2">              temporal data, you can pass a 2D array with shape `(samples,</span>

<span class="s2">              sequence_length)`, to apply a different weight to every timestep</span>

<span class="s2">              of every sample. This argument is not supported when `x` is a</span>

<span class="s2">              dataset, instead pass sample weights as the third element of `x`.</span>

<span class="s2">        steps: Integer or `None`. Total number of steps (batches of samples)</span>

<span class="s2">          before declaring the evaluation round finished. Ignored with the</span>

<span class="s2">          default value of `None`. If x is a `tf.data` dataset and `steps` is</span>

<span class="s2">          None, &#39;evaluate&#39; will run until the dataset is exhausted. This</span>

<span class="s2">          argument is not supported with array inputs.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances. List of</span>

<span class="s2">          callbacks to apply during evaluation. See</span>

<span class="s2">          [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">          input only. Maximum size for the generator queue. If unspecified,</span>

<span class="s2">          `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">          only. Maximum number of processes to spin up when using process-based</span>

<span class="s2">          threading. If unspecified, `workers` will default to 1. If 0, will</span>

<span class="s2">          execute the generator on the main thread.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">          `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">          threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">          `False`. Note that because this implementation relies on</span>

<span class="s2">          multiprocessing, you should not pass non-picklable arguments to the</span>

<span class="s2">          generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.evaluate` is wrapped in `tf.function`.</span>

<span class="s2">        ValueError: in case of invalid arguments.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

    <span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;evaluate&#39;</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;evaluate&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="c1"># Use cached evaluation data only when it&#39;s called in `Model.fit`</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_fit_frame&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span>

          <span class="k">and</span> <span class="n">tf_inspect</span><span class="p">.</span><span class="n">currentframe</span><span class="p">().</span><span class="n">f_back</span> <span class="k">is</span> <span class="n">self</span><span class="p">.</span><span class="n">_fit_frame</span>

          <span class="k">and</span> <span class="n">getattr</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="p">)</span><span class="o">:</span>

        <span class="n">data_handler</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">_eval_data_handler</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

        <span class="n">data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">DataHandler</span><span class="p">(</span>

            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

            <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>

            <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>

            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

            <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

            <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

            <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

            <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

            <span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

      <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

      <span class="k">if</span> <span class="k">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span>

            <span class="n">callbacks</span><span class="p">,</span>

            <span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="err">{}</span>

      <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_begin</span><span class="p">()</span>

      <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">iterator</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span>  <span class="c1"># Single epoch.</span>

        <span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

        <span class="k">with</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span>

          <span class="k">for</span> <span class="n">step</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span>

            <span class="k">with</span> <span class="n">trace</span><span class="p">.</span><span class="n">Trace</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span>

              <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

              <span class="n">tmp_logs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

              <span class="k">if</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span>

                <span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span>

              <span class="k">logs</span> <span class="o">=</span> <span class="n">tmp_logs</span>  <span class="c1"># No error, now safe to assign to logs.</span>

              <span class="n">end_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">+</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span>

              <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span> <span class="k">logs</span><span class="p">)</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="k">logs</span><span class="o">=</span><span class="k">logs</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">return_dict</span><span class="o">:</span>

        <span class="k">return</span> <span class="k">logs</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="n">results</span> <span class="o">=</span> <span class="err">[]</span>

        <span class="k">for</span> <span class="k">name</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="o">:</span>

          <span class="k">if</span> <span class="k">name</span> <span class="k">in</span> <span class="k">logs</span><span class="o">:</span>

            <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="k">logs</span><span class="err">[</span><span class="k">name</span><span class="err">]</span><span class="p">)</span>

        <span class="k">for</span> <span class="k">key</span> <span class="k">in</span> <span class="n">sorted</span><span class="p">(</span><span class="k">logs</span><span class="p">.</span><span class="k">keys</span><span class="p">())</span><span class="o">:</span>

          <span class="k">if</span> <span class="k">key</span> <span class="k">not</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="o">:</span>

            <span class="n">results</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="k">logs</span><span class="err">[</span><span class="k">key</span><span class="err">]</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

          <span class="k">return</span> <span class="n">results</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

        <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

</details>
<h4 id="evaluate_generator_2">evaluate_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">evaluate_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Evaluates the model on a data generator.</p>
<p>DEPRECATED:
  <code>Model.evaluate</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">evaluate_generator</span><span class="p">(</span><span class="k">self</span><span class="p">,</span>

                         <span class="n">generator</span><span class="p">,</span>

                         <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                         <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                         <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

                         <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                         <span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

                         <span class="k">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Evaluates the model on a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.evaluate` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`Model.evaluate_generator` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `Model.evaluate`, which supports generators.&#39;</span><span class="p">)</span>

    <span class="k">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;evaluate_generator&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="k">self</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span>

        <span class="n">generator</span><span class="p">,</span>

        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

        <span class="k">verbose</span><span class="o">=</span><span class="k">verbose</span><span class="p">,</span>

        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="fit_2">fit</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Trains the model for a fixed number of epochs (iterations on a dataset).</p>
<p>Arguments:
    x: Input data. It could be:
      - A Numpy array (or array-like), or a list of arrays
        (in case the model has multiple inputs).
      - A TensorFlow tensor, or a list of tensors
        (in case the model has multiple inputs).
      - A dict mapping input names to the corresponding array/tensors,
        if the model has named inputs.
      - A <code>tf.data</code> dataset. Should return a tuple
        of either <code>(inputs, targets)</code> or
        <code>(inputs, targets, sample_weights)</code>.
      - A generator or <code>keras.utils.Sequence</code> returning <code>(inputs, targets)</code>
        or <code>(inputs, targets, sample_weights)</code>.
      A more detailed description of unpacking behavior for iterator types
      (Dataset, generator, Sequence) is given below.
    y: Target data. Like the input data <code>x</code>,
      it could be either Numpy array(s) or TensorFlow tensor(s).
      It should be consistent with <code>x</code> (you cannot have Numpy inputs and
      tensor targets, or inversely). If <code>x</code> is a dataset, generator,
      or <code>keras.utils.Sequence</code> instance, <code>y</code> should
      not be specified (since targets will be obtained from <code>x</code>).
    batch_size: Integer or <code>None</code>.
        Number of samples per gradient update.
        If unspecified, <code>batch_size</code> will default to 32.
        Do not specify the <code>batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    epochs: Integer. Number of epochs to train the model.
        An epoch is an iteration over the entire <code>x</code> and <code>y</code>
        data provided.
        Note that in conjunction with <code>initial_epoch</code>,
        <code>epochs</code> is to be understood as "final epoch".
        The model is not trained for a number of iterations
        given by <code>epochs</code>, but merely until the epoch
        of index <code>epochs</code> is reached.
    verbose: 0, 1, or 2. Verbosity mode.
        0 = silent, 1 = progress bar, 2 = one line per epoch.
        Note that the progress bar is not particularly useful when
        logged to a file, so verbose=2 is recommended when not running
        interactively (eg, in a production environment).
    callbacks: List of <code>keras.callbacks.Callback</code> instances.
        List of callbacks to apply during training.
        See <code>tf.keras.callbacks</code>. Note <code>tf.keras.callbacks.ProgbarLogger</code>
        and <code>tf.keras.callbacks.History</code> callbacks are created automatically
        and need not be passed into <code>model.fit</code>.
        <code>tf.keras.callbacks.ProgbarLogger</code> is created or not based on
        <code>verbose</code> argument to <code>model.fit</code>.
    validation_split: Float between 0 and 1.
        Fraction of the training data to be used as validation data.
        The model will set apart this fraction of the training data,
        will not train on it, and will evaluate
        the loss and any model metrics
        on this data at the end of each epoch.
        The validation data is selected from the last samples
        in the <code>x</code> and <code>y</code> data provided, before shuffling. This argument is
        not supported when <code>x</code> is a dataset, generator or
       <code>keras.utils.Sequence</code> instance.
    validation_data: Data on which to evaluate
        the loss and any model metrics at the end of each epoch.
        The model will not be trained on this data. Thus, note the fact
        that the validation loss of data provided using <code>validation_split</code>
        or <code>validation_data</code> is not affected by regularization layers like
        noise and dropout.
        <code>validation_data</code> will override <code>validation_split</code>.
        <code>validation_data</code> could be:
          - tuple <code>(x_val, y_val)</code> of Numpy arrays or tensors
          - tuple <code>(x_val, y_val, val_sample_weights)</code> of Numpy arrays
          - dataset
        For the first two cases, <code>batch_size</code> must be provided.
        For the last case, <code>validation_steps</code> could be provided.
        Note that <code>validation_data</code> does not support all the data types that
        are supported in <code>x</code>, eg, dict, generator or <code>keras.utils.Sequence</code>.
    shuffle: Boolean (whether to shuffle the training data
        before each epoch) or str (for 'batch'). This argument is ignored
        when <code>x</code> is a generator. 'batch' is a special option for dealing
        with the limitations of HDF5 data; it shuffles in batch-sized
        chunks. Has no effect when <code>steps_per_epoch</code> is not <code>None</code>.
    class_weight: Optional dictionary mapping class indices (integers)
        to a weight (float) value, used for weighting the loss function
        (during training only).
        This can be useful to tell the model to
        "pay more attention" to samples from
        an under-represented class.
    sample_weight: Optional Numpy array of weights for
        the training samples, used for weighting the loss function
        (during training only). You can either pass a flat (1D)
        Numpy array with the same length as the input samples
        (1:1 mapping between weights and samples),
        or in the case of temporal data,
        you can pass a 2D array with shape
        <code>(samples, sequence_length)</code>,
        to apply a different weight to every timestep of every sample. This
        argument is not supported when <code>x</code> is a dataset, generator, or
       <code>keras.utils.Sequence</code> instance, instead provide the sample_weights
        as the third element of <code>x</code>.
    initial_epoch: Integer.
        Epoch at which to start training
        (useful for resuming a previous training run).
    steps_per_epoch: Integer or <code>None</code>.
        Total number of steps (batches of samples)
        before declaring one epoch finished and starting the
        next epoch. When training with input tensors such as
        TensorFlow data tensors, the default <code>None</code> is equal to
        the number of samples in your dataset divided by
        the batch size, or 1 if that cannot be determined. If x is a
        <code>tf.data</code> dataset, and 'steps_per_epoch'
        is None, the epoch will run until the input dataset is exhausted.
        When passing an infinitely repeating dataset, you must specify the
        <code>steps_per_epoch</code> argument. This argument is not supported with
        array inputs.
    validation_steps: Only relevant if <code>validation_data</code> is provided and
        is a <code>tf.data</code> dataset. Total number of steps (batches of
        samples) to draw before stopping when performing validation
        at the end of every epoch. If 'validation_steps' is None, validation
        will run until the <code>validation_data</code> dataset is exhausted. In the
        case of an infinitely repeated dataset, it will run into an
        infinite loop. If 'validation_steps' is specified and only part of
        the dataset will be consumed, the evaluation will start from the
        beginning of the dataset at each epoch. This ensures that the same
        validation samples are used every time.
    validation_batch_size: Integer or <code>None</code>.
        Number of samples per validation batch.
        If unspecified, will default to <code>batch_size</code>.
        Do not specify the <code>validation_batch_size</code> if your data is in the
        form of datasets, generators, or <code>keras.utils.Sequence</code> instances
        (since they generate batches).
    validation_freq: Only relevant if validation data is provided. Integer
        or <code>collections_abc.Container</code> instance (e.g. list, tuple, etc.).
        If an integer, specifies how many training epochs to run before a
        new validation run is performed, e.g. <code>validation_freq=2</code> runs
        validation every 2 epochs. If a Container, specifies the epochs on
        which to run validation, e.g. <code>validation_freq=[1, 2, 10]</code> runs
        validation at the end of the 1st, 2nd, and 10th epochs.
    max_queue_size: Integer. Used for generator or <code>keras.utils.Sequence</code>
        input only. Maximum size for the generator queue.
        If unspecified, <code>max_queue_size</code> will default to 10.
    workers: Integer. Used for generator or <code>keras.utils.Sequence</code> input
        only. Maximum number of processes to spin up
        when using process-based threading. If unspecified, <code>workers</code>
        will default to 1. If 0, will execute the generator on the main
        thread.
    use_multiprocessing: Boolean. Used for generator or
        <code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based
        threading. If unspecified, <code>use_multiprocessing</code> will default to
        <code>False</code>. Note that because this implementation relies on
        multiprocessing, you should not pass non-picklable arguments to
        the generator as they can't be passed easily to children processes.</p>
<p>Unpacking behavior for iterator-like inputs:
    A common pattern is to pass a tf.data.Dataset, generator, or
  tf.keras.utils.Sequence to the <code>x</code> argument of fit, which will in fact
  yield not only features (x) but optionally targets (y) and sample weights.
  Keras requires that the output of such iterator-likes be unambiguous. The
  iterator should return a tuple of length 1, 2, or 3, where the optional
  second and third elements will be used for y and sample_weight
  respectively. Any other type provided will be wrapped in a length one
  tuple, effectively treating everything as 'x'. When yielding dicts, they
  should still adhere to the top-level tuple structure.
  e.g. <code>({"x0": x0, "x1": x1}, y)</code>. Keras will not attempt to separate
  features, targets, and weights from the keys of a single dict.
    A notable unsupported data type is the namedtuple. The reason is that
  it behaves like both an ordered datatype (tuple) and a mapping
  datatype (dict). So given a namedtuple of the form:
      <code>namedtuple("example_tuple", ["y", "x"])</code>
  it is ambiguous whether to reverse the order of the elements when
  interpreting the value. Even worse is a tuple of the form:
      <code>namedtuple("other_tuple", ["x", "y", "z"])</code>
  where it is unclear if the tuple was intended to be unpacked into x, y,
  and sample_weight or passed through as a single element to <code>x</code>. As a
  result the data processing code will simply raise a ValueError if it
  encounters a namedtuple. (Along with instructions to remedy the issue.)</p>
<p>Returns:
    A <code>History</code> object. Its <code>History.history</code> attribute is
    a record of training loss values and metrics values
    at successive epochs, as well as validation loss values
    and validation metrics values (if applicable).</p>
<p>Raises:
    RuntimeError: 1. If the model was never compiled or,
    2. If <code>model.fit</code> is  wrapped in <code>tf.function</code>.</p>
<div class="codehilite"><pre><span></span><code><span class="n">ValueError</span><span class="o">:</span> <span class="n">In</span> <span class="k">case</span> <span class="n">of</span> <span class="n">mismatch</span> <span class="n">between</span> <span class="n">the</span> <span class="n">provided</span> <span class="n">input</span> <span class="n">data</span>
    <span class="n">and</span> <span class="n">what</span> <span class="n">the</span> <span class="n">model</span> <span class="n">expects</span> <span class="n">or</span> <span class="n">when</span> <span class="n">the</span> <span class="n">input</span> <span class="n">data</span> <span class="k">is</span> <span class="n">empty</span><span class="o">.</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

          <span class="n">x</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">y</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">callbacks</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span>

          <span class="n">validation_data</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">shuffle</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

          <span class="n">class_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">sample_weight</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

          <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_steps</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_batch_size</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

          <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

          <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">False</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Trains the model for a fixed number of epochs (iterations on a dataset).</span>

<span class="sd">    Arguments:</span>

<span class="sd">        x: Input data. It could be:</span>

<span class="sd">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A TensorFlow tensor, or a list of tensors</span>

<span class="sd">            (in case the model has multiple inputs).</span>

<span class="sd">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="sd">            if the model has named inputs.</span>

<span class="sd">          - A `tf.data` dataset. Should return a tuple</span>

<span class="sd">            of either `(inputs, targets)` or</span>

<span class="sd">            `(inputs, targets, sample_weights)`.</span>

<span class="sd">          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`</span>

<span class="sd">            or `(inputs, targets, sample_weights)`.</span>

<span class="sd">          A more detailed description of unpacking behavior for iterator types</span>

<span class="sd">          (Dataset, generator, Sequence) is given below.</span>

<span class="sd">        y: Target data. Like the input data `x`,</span>

<span class="sd">          it could be either Numpy array(s) or TensorFlow tensor(s).</span>

<span class="sd">          It should be consistent with `x` (you cannot have Numpy inputs and</span>

<span class="sd">          tensor targets, or inversely). If `x` is a dataset, generator,</span>

<span class="sd">          or `keras.utils.Sequence` instance, `y` should</span>

<span class="sd">          not be specified (since targets will be obtained from `x`).</span>

<span class="sd">        batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per gradient update.</span>

<span class="sd">            If unspecified, `batch_size` will default to 32.</span>

<span class="sd">            Do not specify the `batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        epochs: Integer. Number of epochs to train the model.</span>

<span class="sd">            An epoch is an iteration over the entire `x` and `y`</span>

<span class="sd">            data provided.</span>

<span class="sd">            Note that in conjunction with `initial_epoch`,</span>

<span class="sd">            `epochs` is to be understood as &quot;final epoch&quot;.</span>

<span class="sd">            The model is not trained for a number of iterations</span>

<span class="sd">            given by `epochs`, but merely until the epoch</span>

<span class="sd">            of index `epochs` is reached.</span>

<span class="sd">        verbose: 0, 1, or 2. Verbosity mode.</span>

<span class="sd">            0 = silent, 1 = progress bar, 2 = one line per epoch.</span>

<span class="sd">            Note that the progress bar is not particularly useful when</span>

<span class="sd">            logged to a file, so verbose=2 is recommended when not running</span>

<span class="sd">            interactively (eg, in a production environment).</span>

<span class="sd">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="sd">            List of callbacks to apply during training.</span>

<span class="sd">            See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`</span>

<span class="sd">            and `tf.keras.callbacks.History` callbacks are created automatically</span>

<span class="sd">            and need not be passed into `model.fit`.</span>

<span class="sd">            `tf.keras.callbacks.ProgbarLogger` is created or not based on</span>

<span class="sd">            `verbose` argument to `model.fit`.</span>

<span class="sd">        validation_split: Float between 0 and 1.</span>

<span class="sd">            Fraction of the training data to be used as validation data.</span>

<span class="sd">            The model will set apart this fraction of the training data,</span>

<span class="sd">            will not train on it, and will evaluate</span>

<span class="sd">            the loss and any model metrics</span>

<span class="sd">            on this data at the end of each epoch.</span>

<span class="sd">            The validation data is selected from the last samples</span>

<span class="sd">            in the `x` and `y` data provided, before shuffling. This argument is</span>

<span class="sd">            not supported when `x` is a dataset, generator or</span>

<span class="sd">           `keras.utils.Sequence` instance.</span>

<span class="sd">        validation_data: Data on which to evaluate</span>

<span class="sd">            the loss and any model metrics at the end of each epoch.</span>

<span class="sd">            The model will not be trained on this data. Thus, note the fact</span>

<span class="sd">            that the validation loss of data provided using `validation_split`</span>

<span class="sd">            or `validation_data` is not affected by regularization layers like</span>

<span class="sd">            noise and dropout.</span>

<span class="sd">            `validation_data` will override `validation_split`.</span>

<span class="sd">            `validation_data` could be:</span>

<span class="sd">              - tuple `(x_val, y_val)` of Numpy arrays or tensors</span>

<span class="sd">              - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays</span>

<span class="sd">              - dataset</span>

<span class="sd">            For the first two cases, `batch_size` must be provided.</span>

<span class="sd">            For the last case, `validation_steps` could be provided.</span>

<span class="sd">            Note that `validation_data` does not support all the data types that</span>

<span class="sd">            are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.</span>

<span class="sd">        shuffle: Boolean (whether to shuffle the training data</span>

<span class="sd">            before each epoch) or str (for &#39;batch&#39;). This argument is ignored</span>

<span class="sd">            when `x` is a generator. &#39;batch&#39; is a special option for dealing</span>

<span class="sd">            with the limitations of HDF5 data; it shuffles in batch-sized</span>

<span class="sd">            chunks. Has no effect when `steps_per_epoch` is not `None`.</span>

<span class="sd">        class_weight: Optional dictionary mapping class indices (integers)</span>

<span class="sd">            to a weight (float) value, used for weighting the loss function</span>

<span class="sd">            (during training only).</span>

<span class="sd">            This can be useful to tell the model to</span>

<span class="sd">            &quot;pay more attention&quot; to samples from</span>

<span class="sd">            an under-represented class.</span>

<span class="sd">        sample_weight: Optional Numpy array of weights for</span>

<span class="sd">            the training samples, used for weighting the loss function</span>

<span class="sd">            (during training only). You can either pass a flat (1D)</span>

<span class="sd">            Numpy array with the same length as the input samples</span>

<span class="sd">            (1:1 mapping between weights and samples),</span>

<span class="sd">            or in the case of temporal data,</span>

<span class="sd">            you can pass a 2D array with shape</span>

<span class="sd">            `(samples, sequence_length)`,</span>

<span class="sd">            to apply a different weight to every timestep of every sample. This</span>

<span class="sd">            argument is not supported when `x` is a dataset, generator, or</span>

<span class="sd">           `keras.utils.Sequence` instance, instead provide the sample_weights</span>

<span class="sd">            as the third element of `x`.</span>

<span class="sd">        initial_epoch: Integer.</span>

<span class="sd">            Epoch at which to start training</span>

<span class="sd">            (useful for resuming a previous training run).</span>

<span class="sd">        steps_per_epoch: Integer or `None`.</span>

<span class="sd">            Total number of steps (batches of samples)</span>

<span class="sd">            before declaring one epoch finished and starting the</span>

<span class="sd">            next epoch. When training with input tensors such as</span>

<span class="sd">            TensorFlow data tensors, the default `None` is equal to</span>

<span class="sd">            the number of samples in your dataset divided by</span>

<span class="sd">            the batch size, or 1 if that cannot be determined. If x is a</span>

<span class="sd">            `tf.data` dataset, and &#39;steps_per_epoch&#39;</span>

<span class="sd">            is None, the epoch will run until the input dataset is exhausted.</span>

<span class="sd">            When passing an infinitely repeating dataset, you must specify the</span>

<span class="sd">            `steps_per_epoch` argument. This argument is not supported with</span>

<span class="sd">            array inputs.</span>

<span class="sd">        validation_steps: Only relevant if `validation_data` is provided and</span>

<span class="sd">            is a `tf.data` dataset. Total number of steps (batches of</span>

<span class="sd">            samples) to draw before stopping when performing validation</span>

<span class="sd">            at the end of every epoch. If &#39;validation_steps&#39; is None, validation</span>

<span class="sd">            will run until the `validation_data` dataset is exhausted. In the</span>

<span class="sd">            case of an infinitely repeated dataset, it will run into an</span>

<span class="sd">            infinite loop. If &#39;validation_steps&#39; is specified and only part of</span>

<span class="sd">            the dataset will be consumed, the evaluation will start from the</span>

<span class="sd">            beginning of the dataset at each epoch. This ensures that the same</span>

<span class="sd">            validation samples are used every time.</span>

<span class="sd">        validation_batch_size: Integer or `None`.</span>

<span class="sd">            Number of samples per validation batch.</span>

<span class="sd">            If unspecified, will default to `batch_size`.</span>

<span class="sd">            Do not specify the `validation_batch_size` if your data is in the</span>

<span class="sd">            form of datasets, generators, or `keras.utils.Sequence` instances</span>

<span class="sd">            (since they generate batches).</span>

<span class="sd">        validation_freq: Only relevant if validation data is provided. Integer</span>

<span class="sd">            or `collections_abc.Container` instance (e.g. list, tuple, etc.).</span>

<span class="sd">            If an integer, specifies how many training epochs to run before a</span>

<span class="sd">            new validation run is performed, e.g. `validation_freq=2` runs</span>

<span class="sd">            validation every 2 epochs. If a Container, specifies the epochs on</span>

<span class="sd">            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs</span>

<span class="sd">            validation at the end of the 1st, 2nd, and 10th epochs.</span>

<span class="sd">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="sd">            input only. Maximum size for the generator queue.</span>

<span class="sd">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="sd">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="sd">            only. Maximum number of processes to spin up</span>

<span class="sd">            when using process-based threading. If unspecified, `workers`</span>

<span class="sd">            will default to 1. If 0, will execute the generator on the main</span>

<span class="sd">            thread.</span>

<span class="sd">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="sd">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="sd">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="sd">            `False`. Note that because this implementation relies on</span>

<span class="sd">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="sd">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="sd">    Unpacking behavior for iterator-like inputs:</span>

<span class="sd">        A common pattern is to pass a tf.data.Dataset, generator, or</span>

<span class="sd">      tf.keras.utils.Sequence to the `x` argument of fit, which will in fact</span>

<span class="sd">      yield not only features (x) but optionally targets (y) and sample weights.</span>

<span class="sd">      Keras requires that the output of such iterator-likes be unambiguous. The</span>

<span class="sd">      iterator should return a tuple of length 1, 2, or 3, where the optional</span>

<span class="sd">      second and third elements will be used for y and sample_weight</span>

<span class="sd">      respectively. Any other type provided will be wrapped in a length one</span>

<span class="sd">      tuple, effectively treating everything as &#39;x&#39;. When yielding dicts, they</span>

<span class="sd">      should still adhere to the top-level tuple structure.</span>

<span class="sd">      e.g. `({&quot;x0&quot;: x0, &quot;x1&quot;: x1}, y)`. Keras will not attempt to separate</span>

<span class="sd">      features, targets, and weights from the keys of a single dict.</span>

<span class="sd">        A notable unsupported data type is the namedtuple. The reason is that</span>

<span class="sd">      it behaves like both an ordered datatype (tuple) and a mapping</span>

<span class="sd">      datatype (dict). So given a namedtuple of the form:</span>

<span class="sd">          `namedtuple(&quot;example_tuple&quot;, [&quot;y&quot;, &quot;x&quot;])`</span>

<span class="sd">      it is ambiguous whether to reverse the order of the elements when</span>

<span class="sd">      interpreting the value. Even worse is a tuple of the form:</span>

<span class="sd">          `namedtuple(&quot;other_tuple&quot;, [&quot;x&quot;, &quot;y&quot;, &quot;z&quot;])`</span>

<span class="sd">      where it is unclear if the tuple was intended to be unpacked into x, y,</span>

<span class="sd">      and sample_weight or passed through as a single element to `x`. As a</span>

<span class="sd">      result the data processing code will simply raise a ValueError if it</span>

<span class="sd">      encounters a namedtuple. (Along with instructions to remedy the issue.)</span>

<span class="sd">    Returns:</span>

<span class="sd">        A `History` object. Its `History.history` attribute is</span>

<span class="sd">        a record of training loss values and metrics values</span>

<span class="sd">        at successive epochs, as well as validation loss values</span>

<span class="sd">        and validation metrics values (if applicable).</span>

<span class="sd">    Raises:</span>

<span class="sd">        RuntimeError: 1. If the model was never compiled or,</span>

<span class="sd">        2. If `model.fit` is  wrapped in `tf.function`.</span>

<span class="sd">        ValueError: In case of mismatch between the provided input data</span>

<span class="sd">            and what the model expects or when the input data is empty.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">base_layer</span><span class="o">.</span><span class="n">keras_api_gauge</span><span class="o">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">True</span><span class="p">)</span>

    <span class="c1"># Legacy graph support is contained in `training_v1.Model`.</span>

    <span class="n">version_utils</span><span class="o">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">validation_split</span><span class="p">:</span>

      <span class="c1"># Create the validation data using the training data. Only supported for</span>

      <span class="c1"># `Tensor` and `NumPy` input.</span>

      <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">),</span> <span class="n">validation_data</span> <span class="o">=</span> <span class="p">(</span>

          <span class="n">data_adapter</span><span class="o">.</span><span class="n">train_validation_split</span><span class="p">(</span>

              <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">),</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">validation_data</span><span class="p">:</span>

      <span class="n">val_x</span><span class="p">,</span> <span class="n">val_y</span><span class="p">,</span> <span class="n">val_sample_weight</span> <span class="o">=</span> <span class="p">(</span>

          <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">validation_data</span><span class="p">))</span>

    <span class="n">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">(),</span> \

         <span class="n">training_utils</span><span class="o">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

      <span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

      <span class="n">data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">DataHandler</span><span class="p">(</span>

          <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

          <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>

          <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>

          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

          <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>

          <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">,</span>

          <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

          <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>

          <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>

          <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

          <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

          <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

          <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

          <span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

      <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">):</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_module</span><span class="o">.</span><span class="n">CallbackList</span><span class="p">(</span>

            <span class="n">callbacks</span><span class="p">,</span>

            <span class="n">add_history</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="o">.</span><span class="n">inferred_steps</span><span class="p">)</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="n">False</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_train_function</span><span class="p">()</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_train_counter</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span>

      <span class="n">training_logs</span> <span class="o">=</span> <span class="n">None</span>

      <span class="c1"># Handle fault-tolerance for multi-worker.</span>

      <span class="c1"># TODO(omalleyt): Fix the ordering issues that mean this has to</span>

      <span class="c1"># happen after `callbacks.on_train_begin`.</span>

      <span class="n">data_handler</span><span class="o">.</span><span class="n">_initial_epoch</span> <span class="o">=</span> <span class="p">(</span>  <span class="c1"># pylint: disable=protected-access</span>

          <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_load_initial_epoch_from_ckpt</span><span class="p">(</span><span class="n">initial_epoch</span><span class="p">))</span>

      <span class="n">logs</span> <span class="o">=</span> <span class="n">None</span>

      <span class="k">for</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">iterator</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">enumerate_epochs</span><span class="p">():</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reset_metrics</span><span class="p">()</span>

        <span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

        <span class="n">with</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">catch_stop_iteration</span><span class="p">():</span>

          <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">steps</span><span class="p">():</span>

            <span class="n">with</span> <span class="n">trace</span><span class="o">.</span><span class="n">Trace</span><span class="p">(</span>

                <span class="s1">&#39;train&#39;</span><span class="p">,</span>

                <span class="n">epoch_num</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>

                <span class="n">step_num</span><span class="o">=</span><span class="n">step</span><span class="p">,</span>

                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

                <span class="n">_r</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>

              <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

              <span class="n">tmp_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

              <span class="k">if</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">should_sync</span><span class="p">:</span>

                <span class="n">context</span><span class="o">.</span><span class="n">async_wait</span><span class="p">()</span>

              <span class="n">logs</span> <span class="o">=</span> <span class="n">tmp_logs</span>  <span class="c1"># No error, now safe to assign to logs.</span>

              <span class="n">end_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">+</span> <span class="n">data_handler</span><span class="o">.</span><span class="n">step_increment</span>

              <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

                <span class="k">break</span>

        <span class="k">if</span> <span class="n">logs</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

          <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Expect x to be a non-empty array or dataset.&#39;</span><span class="p">)</span>

        <span class="n">epoch_logs</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

        <span class="c1"># Run validation.</span>

        <span class="k">if</span> <span class="n">validation_data</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_eval</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">validation_freq</span><span class="p">):</span>

          <span class="c1"># Create data_handler for evaluation and cache it.</span>

          <span class="k">if</span> <span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span> <span class="n">None</span><span class="p">)</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_fit_frame</span> <span class="o">=</span> <span class="n">tf_inspect</span><span class="o">.</span><span class="n">currentframe</span><span class="p">()</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">DataHandler</span><span class="p">(</span>

                <span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>

                <span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>

                <span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>

                <span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span> <span class="ow">or</span> <span class="n">batch_size</span><span class="p">,</span>

                <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

                <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

                <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

                <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

                <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

                <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>

                <span class="n">steps_per_execution</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

          <span class="n">val_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>

              <span class="n">x</span><span class="o">=</span><span class="n">val_x</span><span class="p">,</span>

              <span class="n">y</span><span class="o">=</span><span class="n">val_y</span><span class="p">,</span>

              <span class="n">sample_weight</span><span class="o">=</span><span class="n">val_sample_weight</span><span class="p">,</span>

              <span class="n">batch_size</span><span class="o">=</span><span class="n">validation_batch_size</span> <span class="ow">or</span> <span class="n">batch_size</span><span class="p">,</span>

              <span class="n">steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

              <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

              <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

              <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

              <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

              <span class="n">return_dict</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>

          <span class="n">val_logs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;val_&#39;</span> <span class="o">+</span> <span class="n">name</span><span class="p">:</span> <span class="n">val</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

          <span class="n">epoch_logs</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">val_logs</span><span class="p">)</span>

        <span class="n">callbacks</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">epoch_logs</span><span class="p">)</span>

        <span class="n">training_logs</span> <span class="o">=</span> <span class="n">epoch_logs</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>

          <span class="k">break</span>

      <span class="c1"># If eval data_hanlder exists, delete it after all epochs are done.</span>

      <span class="k">if</span> <span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_eval_data_handler&#39;</span><span class="p">,</span> <span class="n">None</span><span class="p">)</span> <span class="k">is</span> <span class="ow">not</span> <span class="n">None</span><span class="p">:</span>

        <span class="n">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_eval_data_handler</span>

        <span class="n">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit_frame</span>

      <span class="n">callbacks</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="o">=</span><span class="n">training_logs</span><span class="p">)</span>

      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">history</span>
</code></pre></div>

</details>
<h4 id="fit_generator_2">fit_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">fit_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Fits the model on data yielded batch-by-batch by a Python generator.</p>
<p>DEPRECATED:
  <code>Model.fit</code> now supports generators, so there is no longer any need to use
  this endpoint.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">fit_generator</span><span class="p">(</span><span class="k">self</span><span class="p">,</span>

                    <span class="n">generator</span><span class="p">,</span>

                    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="k">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">validation_data</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">validation_steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">validation_freq</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

                    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

                    <span class="n">shuffle</span><span class="o">=</span><span class="k">True</span><span class="p">,</span>

                    <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Fits the model on data yielded batch-by-batch by a Python generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.fit` now supports generators, so there is no longer any need to use</span>

<span class="ss">      this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`Model.fit_generator` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `Model.fit`, which supports generators.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="k">self</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>

        <span class="n">generator</span><span class="p">,</span>

        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>

        <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>

        <span class="k">verbose</span><span class="o">=</span><span class="k">verbose</span><span class="p">,</span>

        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>

        <span class="n">validation_data</span><span class="o">=</span><span class="n">validation_data</span><span class="p">,</span>

        <span class="n">validation_steps</span><span class="o">=</span><span class="n">validation_steps</span><span class="p">,</span>

        <span class="n">validation_freq</span><span class="o">=</span><span class="n">validation_freq</span><span class="p">,</span>

        <span class="n">class_weight</span><span class="o">=</span><span class="n">class_weight</span><span class="p">,</span>

        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

        <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>

        <span class="n">initial_epoch</span><span class="o">=</span><span class="n">initial_epoch</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_config_2">get_config</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <code>Network</code> (one layer of abstraction above).</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Python dictionary.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">get_config</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="n">raise</span> <span class="n">NotImplementedError</span>
</code></pre></div>

</details>
<h4 id="get_input_at_2">get_input_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor (or list of tensors if the layer has multiple inputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the input tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A tensor (or list of tensors if the layer has multiple inputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;input_tensors&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;input&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_input_mask_at_2">get_input_mask_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_mask_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input mask tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A mask tensor</td>
</tr>
<tr>
<td>(or list of tensors if the layer has multiple inputs).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_mask_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the input mask tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A mask tensor</span>

<span class="ss">        (or list of tensors if the layer has multiple inputs).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_input_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="o">[</span><span class="n">getattr(x, &#39;_keras_mask&#39;, None) for x in inputs</span><span class="o">]</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_keras_mask&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_input_shape_at_2">get_input_shape_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_input_shape_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the input shape(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A shape tuple</td>
</tr>
<tr>
<td>(or list of shape tuples if the layer has multiple inputs).</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_input_shape_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the input shape(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A shape tuple</span>

<span class="ss">        (or list of shape tuples if the layer has multiple inputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;input_shapes&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;input shape&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_layer_2">get_layer</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_layer</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">index</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves a layer based on either its name (unique) or index.</p>
<p>If <code>name</code> and <code>index</code> are both provided, <code>index</code> will take precedence.
Indices are based on order of horizontal graph traversal (bottom-up).</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>name</td>
<td>None</td>
<td>String, name of layer.</td>
<td>None</td>
</tr>
<tr>
<td>index</td>
<td>None</td>
<td>Integer, index of layer.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A layer instance.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>In case of invalid layer name or index.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">get_layer</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="k">name</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="k">index</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Retrieves a layer based on either its name (unique) or index.</span>

<span class="s2">    If `name` and `index` are both provided, `index` will take precedence.</span>

<span class="s2">    Indices are based on order of horizontal graph traversal (bottom-up).</span>

<span class="s2">    Arguments:</span>

<span class="s2">        name: String, name of layer.</span>

<span class="s2">        index: Integer, index of layer.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A layer instance.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: In case of invalid layer name or index.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="c1"># TODO(fchollet): We could build a dictionary based on layer names</span>

    <span class="c1"># since they are constant, but we have not done that yet.</span>

    <span class="k">if</span> <span class="k">index</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span> <span class="k">and</span> <span class="k">name</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide only a layer name or a layer index.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="k">index</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="k">index</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Was asked to retrieve layer at index &#39;</span> <span class="o">+</span> <span class="n">str</span><span class="p">(</span><span class="k">index</span><span class="p">)</span> <span class="o">+</span>

                         <span class="s1">&#39; but model only has &#39;</span> <span class="o">+</span> <span class="n">str</span><span class="p">(</span><span class="n">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="p">))</span> <span class="o">+</span>

                         <span class="s1">&#39; layers.&#39;</span><span class="p">)</span>

      <span class="k">else</span><span class="o">:</span>

        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="err">[</span><span class="k">index</span><span class="err">]</span>

    <span class="k">if</span> <span class="k">name</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">for</span> <span class="n">layer</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">layers</span><span class="o">:</span>

        <span class="k">if</span> <span class="n">layer</span><span class="p">.</span><span class="k">name</span> <span class="o">==</span> <span class="k">name</span><span class="o">:</span>

          <span class="k">return</span> <span class="n">layer</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;No such layer: &#39;</span> <span class="o">+</span> <span class="k">name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>

    <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide either a layer name or layer index.&#39;</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="get_losses_for_2">get_losses_for</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_losses_for</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Retrieves losses relevant to a specific set of inputs.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Input tensor or list/tuple of input tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List of loss tensors of the layer that depend on <code>inputs</code>.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_generate_docs</span>

  <span class="n">def</span> <span class="n">get_losses_for</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use!</span>

<span class="s2">    Retrieves losses relevant to a specific set of inputs.</span>

<span class="s2">    Arguments:</span>

<span class="s2">      inputs: Input tensor or list/tuple of input tensors.</span>

<span class="s2">    Returns:</span>

<span class="s2">      List of loss tensors of the layer that depend on `inputs`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.get_losses_for` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `layer.losses` instead.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">losses</span>
</code></pre></div>

</details>
<h4 id="get_output_at_2">get_output_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A tensor (or list of tensors if the layer has multiple outputs).</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the output tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A tensor (or list of tensors if the layer has multiple outputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;output_tensors&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;output&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_output_mask_at_2">get_output_mask_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_mask_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output mask tensor(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A mask tensor</td>
</tr>
<tr>
<td>(or list of tensors if the layer has multiple outputs).</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_mask_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the output mask tensor(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A mask tensor</span>

<span class="ss">        (or list of tensors if the layer has multiple outputs).</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">get_output_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span><span class="w"></span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">isinstance</span><span class="p">(</span><span class="k">output</span><span class="p">,</span><span class="w"> </span><span class="n">list</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="o">[</span><span class="n">getattr(x, &#39;_keras_mask&#39;, None) for x in output</span><span class="o">]</span><span class="w"></span>

<span class="w">    </span><span class="k">else</span><span class="err">:</span><span class="w"></span>

<span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">getattr</span><span class="p">(</span><span class="k">output</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;_keras_mask&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">None</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_output_shape_at_2">get_output_shape_at</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_output_shape_at</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">node_index</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the output shape(s) of a layer at a given node.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>node_index</td>
<td>None</td>
<td>Integer, index of the node</td>
<td></td>
</tr>
<tr>
<td>from which to retrieve the attribute.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>E.g. <code>node_index=0</code> will correspond to the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>first time the layer was called.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A shape tuple</td>
</tr>
<tr>
<td>(or list of shape tuples if the layer has multiple outputs).</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If called in Eager mode.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code><span class="w">  </span><span class="nv">@doc_controls</span><span class="p">.</span><span class="n">do_not_doc_inheritable</span><span class="w"></span>

<span class="w">  </span><span class="n">def</span><span class="w"> </span><span class="n">get_output_shape_at</span><span class="p">(</span><span class="n">self</span><span class="p">,</span><span class="w"> </span><span class="n">node_index</span><span class="p">)</span><span class="err">:</span><span class="w"></span>

<span class="w">    </span><span class="ss">&quot;&quot;&quot;Retrieves the output shape(s) of a layer at a given node.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        node_index: Integer, index of the node</span>

<span class="ss">            from which to retrieve the attribute.</span>

<span class="ss">            E.g. `node_index=0` will correspond to the</span>

<span class="ss">            first time the layer was called.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A shape tuple</span>

<span class="ss">        (or list of shape tuples if the layer has multiple outputs).</span>

<span class="ss">    Raises:</span>

<span class="ss">      RuntimeError: If called in Eager mode.</span>

<span class="ss">    &quot;&quot;&quot;</span><span class="w"></span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;output_shapes&#39;</span><span class="p">,</span><span class="w"></span>

<span class="w">                                             </span><span class="s1">&#39;output shape&#39;</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

</details>
<h4 id="get_updates_for_2">get_updates_for</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_updates_for</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">inputs</span>
<span class="p">)</span>
</code></pre></div>

<p>Deprecated, do NOT use!</p>
<p>Retrieves updates relevant to a specific set of inputs.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>inputs</td>
<td>None</td>
<td>Input tensor or list/tuple of input tensors.</td>
<td>None</td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>List of update ops of the layer that depend on <code>inputs</code>.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="nv">@doc_controls.do_not_generate_docs</span>

  <span class="n">def</span> <span class="n">get_updates_for</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Deprecated, do NOT use!</span>

<span class="s2">    Retrieves updates relevant to a specific set of inputs.</span>

<span class="s2">    Arguments:</span>

<span class="s2">      inputs: Input tensor or list/tuple of input tensors.</span>

<span class="s2">    Returns:</span>

<span class="s2">      List of update ops of the layer that depend on `inputs`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`layer.get_updates_for` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `layer.updates` method instead.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">updates</span>
</code></pre></div>

</details>
<h4 id="get_weights_2">get_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Retrieves the weights of the model.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A flat list of Numpy arrays.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">get_weights</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Retrieves the weights of the model.</span>

<span class="ss">    Returns:</span>

<span class="ss">        A flat list of Numpy arrays.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="k">with</span> <span class="k">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="k">scope</span><span class="p">():</span>

      <span class="k">return</span> <span class="n">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="k">self</span><span class="p">).</span><span class="n">get_weights</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="load_weights_2">load_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">skip_mismatch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</p>
<p>If <code>by_name</code> is False weights are loaded based on the network's
topology. This means the architecture should be the same as when the weights
were saved.  Note that layers that don't have weights are not taken into
account in the topological ordering, so adding or removing layers is fine as
long as they don't have weights.</p>
<p>If <code>by_name</code> is True, weights are loaded into layers only if they share the
same name. This is useful for fine-tuning or transfer-learning models where
some of the layers have changed.</p>
<p>Only topological loading (<code>by_name=False</code>) is supported when loading weights
from the TensorFlow format. Note that topological loading differs slightly
between TensorFlow and HDF5 formats for user-defined classes inheriting from
<code>tf.keras.Model</code>: HDF5 loads based on a flattened list of weights, while the
TensorFlow format loads based on the object-local names of attributes to
which layers are assigned in the <code>Model</code>'s constructor.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String, path to the weights file to load. For weight files in</td>
<td></td>
</tr>
<tr>
<td>TensorFlow format, this is the file prefix (the same as was passed</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>to <code>save_weights</code>).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>by_name</td>
<td>None</td>
<td>Boolean, whether to load weights by name or by topological</td>
<td></td>
</tr>
<tr>
<td>order. Only topological loading is supported for weight files in</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>TensorFlow format.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>skip_mismatch</td>
<td>None</td>
<td>Boolean, whether to skip loading of layers where there is</td>
<td></td>
</tr>
<tr>
<td>a mismatch in the number of weights, or a mismatch in the shape of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the weight (only valid when <code>by_name=True</code>).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies</td>
<td></td>
</tr>
<tr>
<td>options for loading weights.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>When loading a weight file in TensorFlow format, returns the same status</td>
</tr>
<tr>
<td>object as <code>tf.train.Checkpoint.restore</code>. When graph building, restore</td>
<td></td>
</tr>
<tr>
<td>ops are run automatically as soon as the network is built (on first call</td>
<td></td>
</tr>
<tr>
<td>for user-defined classes inheriting from <code>Model</code>, immediately if it is</td>
<td></td>
</tr>
<tr>
<td>already built).</td>
<td></td>
</tr>
</tbody>
</table>
<p>When loading weights in HDF5 format, returns <code>None</code>. |</p>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If h5py is not available and the weight file is in HDF5</td>
</tr>
<tr>
<td>format.</td>
<td></td>
</tr>
<tr>
<td>ValueError</td>
<td>If <code>skip_mismatch</code> is set to <code>True</code> when <code>by_name</code> is</td>
</tr>
<tr>
<td><code>False</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

                   <span class="n">filepath</span><span class="p">,</span>

                   <span class="n">by_name</span><span class="o">=</span><span class="n">False</span><span class="p">,</span>

                   <span class="n">skip_mismatch</span><span class="o">=</span><span class="n">False</span><span class="p">,</span>

                   <span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Loads all layer weights, either from a TensorFlow or an HDF5 weight file.</span>

<span class="sd">    If `by_name` is False weights are loaded based on the network&#39;s</span>

<span class="sd">    topology. This means the architecture should be the same as when the weights</span>

<span class="sd">    were saved.  Note that layers that don&#39;t have weights are not taken into</span>

<span class="sd">    account in the topological ordering, so adding or removing layers is fine as</span>

<span class="sd">    long as they don&#39;t have weights.</span>

<span class="sd">    If `by_name` is True, weights are loaded into layers only if they share the</span>

<span class="sd">    same name. This is useful for fine-tuning or transfer-learning models where</span>

<span class="sd">    some of the layers have changed.</span>

<span class="sd">    Only topological loading (`by_name=False`) is supported when loading weights</span>

<span class="sd">    from the TensorFlow format. Note that topological loading differs slightly</span>

<span class="sd">    between TensorFlow and HDF5 formats for user-defined classes inheriting from</span>

<span class="sd">    `tf.keras.Model`: HDF5 loads based on a flattened list of weights, while the</span>

<span class="sd">    TensorFlow format loads based on the object-local names of attributes to</span>

<span class="sd">    which layers are assigned in the `Model`&#39;s constructor.</span>

<span class="sd">    Arguments:</span>

<span class="sd">        filepath: String, path to the weights file to load. For weight files in</span>

<span class="sd">            TensorFlow format, this is the file prefix (the same as was passed</span>

<span class="sd">            to `save_weights`).</span>

<span class="sd">        by_name: Boolean, whether to load weights by name or by topological</span>

<span class="sd">            order. Only topological loading is supported for weight files in</span>

<span class="sd">            TensorFlow format.</span>

<span class="sd">        skip_mismatch: Boolean, whether to skip loading of layers where there is</span>

<span class="sd">            a mismatch in the number of weights, or a mismatch in the shape of</span>

<span class="sd">            the weight (only valid when `by_name=True`).</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for loading weights.</span>

<span class="sd">    Returns:</span>

<span class="sd">        When loading a weight file in TensorFlow format, returns the same status</span>

<span class="sd">        object as `tf.train.Checkpoint.restore`. When graph building, restore</span>

<span class="sd">        ops are run automatically as soon as the network is built (on first call</span>

<span class="sd">        for user-defined classes inheriting from `Model`, immediately if it is</span>

<span class="sd">        already built).</span>

<span class="sd">        When loading weights in HDF5 format, returns `None`.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If h5py is not available and the weight file is in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">        ValueError: If `skip_mismatch` is set to `True` when `by_name` is</span>

<span class="sd">          `False`.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">dist_utils</span><span class="o">.</span><span class="n">is_tpu_strategy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="p">):</span>

      <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_distribution_strategy</span><span class="o">.</span><span class="n">extended</span><span class="o">.</span><span class="n">steps_per_run</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span>

          <span class="p">(</span><span class="ow">not</span> <span class="n">_is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">))):</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Load weights is not yet supported with TPUStrategy &#39;</span>

                         <span class="s1">&#39;with steps_per_run greater than 1.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">skip_mismatch</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">by_name</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="s1">&#39;When calling model.load_weights, skip_mismatch can only be set to &#39;</span>

          <span class="s1">&#39;True when by_name is True.&#39;</span><span class="p">)</span>

    <span class="n">filepath</span> <span class="o">=</span> <span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">_is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>

      <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="n">try</span><span class="p">:</span>

        <span class="n">py_checkpoint_reader</span><span class="o">.</span><span class="n">NewCheckpointReader</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;tf&#39;</span>

      <span class="n">except</span> <span class="n">errors_impl</span><span class="o">.</span><span class="n">DataLossError</span><span class="p">:</span>

        <span class="c1"># The checkpoint is not readable in TensorFlow format. Try HDF5.</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span><span class="p">:</span>

      <span class="n">status</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">by_name</span><span class="p">:</span>

        <span class="n">raise</span> <span class="n">NotImplementedError</span><span class="p">(</span>

            <span class="s1">&#39;Weights may only be loaded based on topology into Models when &#39;</span>

            <span class="s1">&#39;loading TensorFlow-formatted weights (got by_name=True to &#39;</span>

            <span class="s1">&#39;load_weights).&#39;</span><span class="p">)</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>

        <span class="n">session</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

        <span class="c1"># Restore existing variables (if any) immediately, and set up a</span>

        <span class="c1"># streaming restore for any variables created in the future.</span>

        <span class="n">trackable_utils</span><span class="o">.</span><span class="n">streaming_restore</span><span class="p">(</span><span class="n">status</span><span class="o">=</span><span class="n">status</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">)</span>

      <span class="n">status</span><span class="o">.</span><span class="n">assert_nontrivial_match</span><span class="p">()</span>

      <span class="k">return</span> <span class="n">status</span>

    <span class="k">if</span> <span class="n">h5py</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ImportError</span><span class="p">(</span>

          <span class="s1">&#39;`load_weights` requires h5py when loading weights from HDF5.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_graph_network</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="s1">&#39;Unable to load weights saved in HDF5 format into a subclassed &#39;</span>

          <span class="s1">&#39;Model which has not created its variables yet. Call the Model &#39;</span>

          <span class="s1">&#39;first, then load the weights.&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span>

    <span class="n">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>

      <span class="k">if</span> <span class="s1">&#39;layer_names&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span> <span class="ow">and</span> <span class="s1">&#39;model_weights&#39;</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>

        <span class="n">f</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;model_weights&#39;</span><span class="p">]</span>

      <span class="k">if</span> <span class="n">by_name</span><span class="p">:</span>

        <span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group_by_name</span><span class="p">(</span>

            <span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="n">skip_mismatch</span><span class="o">=</span><span class="n">skip_mismatch</span><span class="p">)</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">hdf5_format</span><span class="o">.</span><span class="n">load_weights_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="make_predict_function_2">make_predict_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_predict_function</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of inference.</p>
<p>This method can be overridden to support custom inference logic.
This method is called by <code>Model.predict</code> and <code>Model.predict_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.predict_step</code>.</p>
<p>This function is cached the first time <code>Model.predict</code> or
<code>Model.predict_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a</td>
</tr>
<tr>
<td><code>tf.data.Iterator</code>, and return the outputs of the <code>Model</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">make_predict_function</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of inference.</span>

<span class="s2">    This method can be overridden to support custom inference logic.</span>

<span class="s2">    This method is called by `Model.predict` and `Model.predict_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.predict_step`.</span>

<span class="s2">    This function is cached the first time `Model.predict` or</span>

<span class="s2">    `Model.predict_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return the outputs of the `Model`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span>

    <span class="n">def</span> <span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

      <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

      <span class="n">def</span> <span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span>

        <span class="k">with</span> <span class="n">ops</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

          <span class="n">model</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

        <span class="k">return</span> <span class="n">outputs</span>

      <span class="k">data</span> <span class="o">=</span> <span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">reduce_per_replica</span><span class="p">(</span>

          <span class="n">outputs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;concat&#39;</span><span class="p">)</span>

      <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span> <span class="k">is</span> <span class="k">None</span> <span class="k">or</span>

        <span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with one step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="n">math_ops</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">:</span>

          <span class="n">directives</span><span class="p">.</span><span class="k">set</span><span class="n">_loop_options</span><span class="p">(</span>

              <span class="n">shape_invariants</span><span class="o">=</span><span class="err">[</span><span class="p">(</span>

                  <span class="n">t</span><span class="p">,</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">get_tensor_spec</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dynamic_batch</span><span class="o">=</span><span class="no">True</span><span class="p">).</span><span class="n">shape</span><span class="p">)</span>

                                <span class="k">for</span> <span class="n">t</span> <span class="k">in</span> <span class="n">nest</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span><span class="err">]</span><span class="p">)</span>

          <span class="n">step_outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

          <span class="n">outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="o">:</span> <span class="nf">concat</span><span class="p">(</span><span class="err">[</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="err">]</span><span class="p">),</span> <span class="n">outputs</span><span class="p">,</span>

                                       <span class="n">step_outputs</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

      <span class="n">predict_function</span> <span class="o">=</span> <span class="n">def_function</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

          <span class="n">predict_function</span><span class="p">,</span> <span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="n">predict_function</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span>
</code></pre></div>

</details>
<h4 id="make_test_function_2">make_test_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_test_function</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of evaluation.</p>
<p>This method can be overridden to support custom evaluation logic.
This method is called by <code>Model.evaluate</code> and <code>Model.test_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual evaluation
logic to <code>Model.test_step</code>.</p>
<p>This function is cached the first time <code>Model.evaluate</code> or
<code>Model.test_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a</td>
</tr>
<tr>
<td><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will</td>
<td></td>
</tr>
<tr>
<td>be passed to <code>tf.keras.Callbacks.on_test_batch_end</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">make_test_function</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of evaluation.</span>

<span class="s2">    This method can be overridden to support custom evaluation logic.</span>

<span class="s2">    This method is called by `Model.evaluate` and `Model.test_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual evaluation</span>

<span class="s2">    logic to `Model.test_step`.</span>

<span class="s2">    This function is cached the first time `Model.evaluate` or</span>

<span class="s2">    `Model.test_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_test_batch_end`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span>

    <span class="n">def</span> <span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

      <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single evaluation step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

      <span class="n">def</span> <span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">test_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="c1"># Ensure counter is updated only if `test_step` succeeds.</span>

        <span class="k">with</span> <span class="n">ops</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

          <span class="n">model</span><span class="p">.</span><span class="n">_test_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

        <span class="k">return</span> <span class="n">outputs</span>

      <span class="k">data</span> <span class="o">=</span> <span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">reduce_per_replica</span><span class="p">(</span>

          <span class="n">outputs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>

      <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with one step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs an evaluation execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="n">math_ops</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span>

          <span class="n">outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

      <span class="n">test_function</span> <span class="o">=</span> <span class="n">def_function</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

          <span class="n">test_function</span><span class="p">,</span> <span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="o">=</span> <span class="n">test_function</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span>
</code></pre></div>

</details>
<h4 id="make_train_function_2">make_train_function</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">make_train_function</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Creates a function that executes one step of training.</p>
<p>This method can be overridden to support custom training logic.
This method is called by <code>Model.fit</code> and <code>Model.train_on_batch</code>.</p>
<p>Typically, this method directly controls <code>tf.function</code> and
<code>tf.distribute.Strategy</code> settings, and delegates the actual training
logic to <code>Model.train_step</code>.</p>
<p>This function is cached the first time <code>Model.fit</code> or
<code>Model.train_on_batch</code> is called. The cache is cleared whenever
<code>Model.compile</code> is called.</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Function. The function created by this method should accept a</td>
</tr>
<tr>
<td><code>tf.data.Iterator</code>, and return a <code>dict</code> containing values that will</td>
<td></td>
</tr>
<tr>
<td>be passed to <code>tf.keras.Callbacks.on_train_batch_end</code>, such as</td>
<td></td>
</tr>
<tr>
<td><code>{'loss': 0.2, 'accuracy': 0.7}</code>.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">make_train_function</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Creates a function that executes one step of training.</span>

<span class="s2">    This method can be overridden to support custom training logic.</span>

<span class="s2">    This method is called by `Model.fit` and `Model.train_on_batch`.</span>

<span class="s2">    Typically, this method directly controls `tf.function` and</span>

<span class="s2">    `tf.distribute.Strategy` settings, and delegates the actual training</span>

<span class="s2">    logic to `Model.train_step`.</span>

<span class="s2">    This function is cached the first time `Model.fit` or</span>

<span class="s2">    `Model.train_on_batch` is called. The cache is cleared whenever</span>

<span class="s2">    `Model.compile` is called.</span>

<span class="s2">    Returns:</span>

<span class="s2">      Function. The function created by this method should accept a</span>

<span class="s2">      `tf.data.Iterator`, and return a `dict` containing values that will</span>

<span class="s2">      be passed to `tf.keras.Callbacks.on_train_batch_end`, such as</span>

<span class="s2">      `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span> <span class="k">is</span> <span class="k">not</span> <span class="k">None</span><span class="o">:</span>

      <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span>

    <span class="n">def</span> <span class="n">step_function</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

      <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single training step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

      <span class="n">def</span> <span class="n">run_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">train_step</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="c1"># Ensure counter is updated only if `train_step` succeeds.</span>

        <span class="k">with</span> <span class="n">ops</span><span class="p">.</span><span class="n">control_dependencies</span><span class="p">(</span><span class="n">_minimum_control_deps</span><span class="p">(</span><span class="n">outputs</span><span class="p">))</span><span class="o">:</span>

          <span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

        <span class="k">return</span> <span class="n">outputs</span>

      <span class="k">data</span> <span class="o">=</span> <span class="k">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">run_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="k">data</span><span class="p">,))</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">reduce_per_replica</span><span class="p">(</span>

          <span class="n">outputs</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span>

      <span class="n">write_scalar_summaries</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">model</span><span class="p">.</span><span class="n">_train_counter</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

      <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">.</span><span class="n">numpy</span><span class="p">().</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with one step.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">return</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">def</span> <span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span><span class="o">:</span>

        <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a training execution with multiple steps.</span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

        <span class="k">for</span> <span class="n">_</span> <span class="k">in</span> <span class="n">math_ops</span><span class="p">.</span><span class="k">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span><span class="o">:</span>

          <span class="n">outputs</span> <span class="o">=</span> <span class="n">step_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">iterator</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">run_eagerly</span><span class="o">:</span>

      <span class="n">train_function</span> <span class="o">=</span> <span class="n">def_function</span><span class="p">.</span><span class="k">function</span><span class="p">(</span>

          <span class="n">train_function</span><span class="p">,</span> <span class="n">experimental_relax_shapes</span><span class="o">=</span><span class="no">True</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="n">train_function</span>

    <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span>
</code></pre></div>

</details>
<h4 id="predict_2">predict</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates output predictions for the input samples.</p>
<p>Computation is done in batches. This method is designed for performance in
large scale inputs. For small amount of inputs that fit in one batch,
directly using <code>__call__</code> is recommended for faster execution, e.g.,
<code>model(x)</code>, or <code>model(x, training=False)</code> if you have layers such as
<code>tf.keras.layers.BatchNormalization</code> that behaves differently during
inference. Also, note the fact that test loss is not affected by
regularization layers like noise and dropout.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input samples. It could be:</td>
<td></td>
</tr>
<tr>
<td>- A Numpy array (or array-like), or a list of arrays</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A TensorFlow tensor, or a list of tensors</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A <code>tf.data</code> dataset.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A generator or <code>keras.utils.Sequence</code> instance.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>A more detailed description of unpacking behavior for iterator types</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(Dataset, generator, Sequence) is given in the `Unpacking behavior</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>for iterator-like inputs<code>section of</code>Model.fit`.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>batch_size</td>
<td>None</td>
<td>Integer or <code>None</code>.</td>
<td></td>
</tr>
<tr>
<td>Number of samples per batch.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>If unspecified, <code>batch_size</code> will default to 32.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Do not specify the <code>batch_size</code> if your data is in the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>form of dataset, generators, or <code>keras.utils.Sequence</code> instances</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(since they generate batches).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>verbose</td>
<td>None</td>
<td>Verbosity mode, 0 or 1.</td>
<td>None</td>
</tr>
<tr>
<td>steps</td>
<td>None</td>
<td>Total number of steps (batches of samples)</td>
<td></td>
</tr>
<tr>
<td>before declaring the prediction round finished.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Ignored with the default value of <code>None</code>. If x is a <code>tf.data</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>dataset and <code>steps</code> is None, <code>predict</code> will</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>run until the input dataset is exhausted.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>callbacks</td>
<td>None</td>
<td>List of <code>keras.callbacks.Callback</code> instances.</td>
<td></td>
</tr>
<tr>
<td>List of callbacks to apply during prediction.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>See <a href="/api_docs/python/tf/keras/callbacks">callbacks</a>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>max_queue_size</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code></td>
<td></td>
</tr>
<tr>
<td>input only. Maximum size for the generator queue.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>If unspecified, <code>max_queue_size</code> will default to 10.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>workers</td>
<td>None</td>
<td>Integer. Used for generator or <code>keras.utils.Sequence</code> input</td>
<td></td>
</tr>
<tr>
<td>only. Maximum number of processes to spin up when using</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>process-based threading. If unspecified, <code>workers</code> will default</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>to 1. If 0, will execute the generator on the main thread.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>use_multiprocessing</td>
<td>None</td>
<td>Boolean. Used for generator or</td>
<td></td>
</tr>
<tr>
<td><code>keras.utils.Sequence</code> input only. If <code>True</code>, use process-based</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>threading. If unspecified, <code>use_multiprocessing</code> will default to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>False</code>. Note that because this implementation relies on</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>multiprocessing, you should not pass non-picklable arguments to</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the generator as they can't be passed easily to children processes.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>See the discussion of <code>Unpacking behavior for iterator-like inputs</code> for
<code>Model.fit</code>. Note that Model.predict uses the same interpretation rules as
<code>Model.fit</code> and <code>Model.evaluate</code>, so inputs must be unambiguous for all
three methods. | None |</p>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between the provided</td>
</tr>
<tr>
<td>input data and the model's expectations,</td>
<td></td>
</tr>
<tr>
<td>or in case a stateful model receives a number of samples</td>
<td></td>
</tr>
<tr>
<td>that is not a multiple of the batch size.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

              <span class="n">x</span><span class="p">,</span>

              <span class="n">batch_size</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

              <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

              <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

              <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

              <span class="n">use_multiprocessing</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Generates output predictions for the input samples.</span>

<span class="s2">    Computation is done in batches. This method is designed for performance in</span>

<span class="s2">    large scale inputs. For small amount of inputs that fit in one batch,</span>

<span class="s2">    directly using `__call__` is recommended for faster execution, e.g.,</span>

<span class="s2">    `model(x)`, or `model(x, training=False)` if you have layers such as</span>

<span class="s2">    `tf.keras.layers.BatchNormalization` that behaves differently during</span>

<span class="s2">    inference. Also, note the fact that test loss is not affected by</span>

<span class="s2">    regularization layers like noise and dropout.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input samples. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">            (in case the model has multiple inputs).</span>

<span class="s2">          - A `tf.data` dataset.</span>

<span class="s2">          - A generator or `keras.utils.Sequence` instance.</span>

<span class="s2">          A more detailed description of unpacking behavior for iterator types</span>

<span class="s2">          (Dataset, generator, Sequence) is given in the `Unpacking behavior</span>

<span class="s2">          for iterator-like inputs` section of `Model.fit`.</span>

<span class="s2">        batch_size: Integer or `None`.</span>

<span class="s2">            Number of samples per batch.</span>

<span class="s2">            If unspecified, `batch_size` will default to 32.</span>

<span class="s2">            Do not specify the `batch_size` if your data is in the</span>

<span class="s2">            form of dataset, generators, or `keras.utils.Sequence` instances</span>

<span class="s2">            (since they generate batches).</span>

<span class="s2">        verbose: Verbosity mode, 0 or 1.</span>

<span class="s2">        steps: Total number of steps (batches of samples)</span>

<span class="s2">            before declaring the prediction round finished.</span>

<span class="s2">            Ignored with the default value of `None`. If x is a `tf.data`</span>

<span class="s2">            dataset and `steps` is None, `predict` will</span>

<span class="s2">            run until the input dataset is exhausted.</span>

<span class="s2">        callbacks: List of `keras.callbacks.Callback` instances.</span>

<span class="s2">            List of callbacks to apply during prediction.</span>

<span class="s2">            See [callbacks](/api_docs/python/tf/keras/callbacks).</span>

<span class="s2">        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`</span>

<span class="s2">            input only. Maximum size for the generator queue.</span>

<span class="s2">            If unspecified, `max_queue_size` will default to 10.</span>

<span class="s2">        workers: Integer. Used for generator or `keras.utils.Sequence` input</span>

<span class="s2">            only. Maximum number of processes to spin up when using</span>

<span class="s2">            process-based threading. If unspecified, `workers` will default</span>

<span class="s2">            to 1. If 0, will execute the generator on the main thread.</span>

<span class="s2">        use_multiprocessing: Boolean. Used for generator or</span>

<span class="s2">            `keras.utils.Sequence` input only. If `True`, use process-based</span>

<span class="s2">            threading. If unspecified, `use_multiprocessing` will default to</span>

<span class="s2">            `False`. Note that because this implementation relies on</span>

<span class="s2">            multiprocessing, you should not pass non-picklable arguments to</span>

<span class="s2">            the generator as they can&#39;t be passed easily to children processes.</span>

<span class="s2">    See the discussion of `Unpacking behavior for iterator-like inputs` for</span>

<span class="s2">    `Model.fit`. Note that Model.predict uses the same interpretation rules as</span>

<span class="s2">    `Model.fit` and `Model.evaluate`, so inputs must be unambiguous for all</span>

<span class="s2">    three methods.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Numpy array(s) of predictions.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.predict` is wrapped in `tf.function`.</span>

<span class="s2">        ValueError: In case of mismatch between the provided</span>

<span class="s2">            input data and the model&#39;s expectations,</span>

<span class="s2">            or in case a stateful model receives a number of samples</span>

<span class="s2">            that is not a multiple of the batch size.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">base_layer</span><span class="p">.</span><span class="n">keras_api_gauge</span><span class="p">.</span><span class="n">get_cell</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">).</span><span class="kt">set</span><span class="p">(</span><span class="no">True</span><span class="p">)</span>

    <span class="n">version_utils</span><span class="p">.</span><span class="n">disallow_legacy_graph</span><span class="p">(</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;predict&#39;</span><span class="p">)</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;predict&#39;</span><span class="p">)</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="k">None</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="c1"># Creates a `tf.data.Dataset` and handles batch and epoch iteration.</span>

      <span class="n">dataset_types</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset_ops</span><span class="p">.</span><span class="n">DatasetV1</span><span class="p">,</span> <span class="n">dataset_ops</span><span class="p">.</span><span class="n">DatasetV2</span><span class="p">)</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_in_multi_worker_mode</span><span class="p">()</span> <span class="k">or</span> <span class="n">_is_tpu_multi_host</span><span class="p">(</span>

          <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">))</span> <span class="k">and</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dataset_types</span><span class="p">)</span><span class="o">:</span>

        <span class="n">try</span><span class="o">:</span>

          <span class="k">options</span> <span class="o">=</span> <span class="n">dataset_ops</span><span class="p">.</span><span class="k">Options</span><span class="p">()</span>

          <span class="n">data_option</span> <span class="o">=</span> <span class="n">AutoShardPolicy</span><span class="p">.</span><span class="k">DATA</span>

          <span class="k">options</span><span class="p">.</span><span class="n">experimental_distribute</span><span class="p">.</span><span class="n">auto_shard_policy</span> <span class="o">=</span> <span class="n">data_option</span>

          <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">with_options</span><span class="p">(</span><span class="k">options</span><span class="p">)</span>

        <span class="k">except</span> <span class="n">ValueError</span><span class="o">:</span>

          <span class="k">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;Using Model.predict with &#39;</span>

                        <span class="s1">&#39;MultiWorkerDistributionStrategy or TPUStrategy and &#39;</span>

                        <span class="s1">&#39;AutoShardPolicy.FILE might lead to out-of-order result&#39;</span>

                        <span class="s1">&#39;. Consider setting it to AutoShardPolicy.DATA.&#39;</span><span class="p">)</span>

      <span class="n">data_handler</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">DataHandler</span><span class="p">(</span>

          <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>

          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>

          <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

          <span class="n">initial_epoch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>

          <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

          <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

          <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

          <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

          <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

          <span class="n">steps_per_execution</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">_steps_per_execution</span><span class="p">)</span>

      <span class="c1"># Container that configures and calls `tf.keras.Callback`s.</span>

      <span class="k">if</span> <span class="k">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">)</span><span class="o">:</span>

        <span class="n">callbacks</span> <span class="o">=</span> <span class="n">callbacks_module</span><span class="p">.</span><span class="n">CallbackList</span><span class="p">(</span>

            <span class="n">callbacks</span><span class="p">,</span>

            <span class="n">add_history</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

            <span class="n">add_progbar</span><span class="o">=</span><span class="n">verbose</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>

            <span class="n">model</span><span class="o">=</span><span class="n">self</span><span class="p">,</span>

            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>

            <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

            <span class="n">steps</span><span class="o">=</span><span class="n">data_handler</span><span class="p">.</span><span class="n">inferred_steps</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span>

      <span class="n">self</span><span class="p">.</span><span class="n">_predict_counter</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_begin</span><span class="p">()</span>

      <span class="n">batch_outputs</span> <span class="o">=</span> <span class="k">None</span>

      <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">iterator</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">enumerate_epochs</span><span class="p">()</span><span class="o">:</span>  <span class="c1"># Single epoch.</span>

        <span class="k">with</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">catch_stop_iteration</span><span class="p">()</span><span class="o">:</span>

          <span class="k">for</span> <span class="n">step</span> <span class="k">in</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">steps</span><span class="p">()</span><span class="o">:</span>

            <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_begin</span><span class="p">(</span><span class="n">step</span><span class="p">)</span>

            <span class="n">tmp_batch_outputs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">should_sync</span><span class="o">:</span>

              <span class="k">context</span><span class="p">.</span><span class="n">async_wait</span><span class="p">()</span>

            <span class="n">batch_outputs</span> <span class="o">=</span> <span class="n">tmp_batch_outputs</span>  <span class="c1"># No error, now safe to assign.</span>

            <span class="k">if</span> <span class="n">outputs</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

              <span class="n">outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure</span><span class="p">(</span><span class="n">lambda</span> <span class="n">batch_output</span><span class="o">:</span> <span class="err">[</span><span class="n">batch_output</span><span class="err">]</span><span class="p">,</span>

                                           <span class="n">batch_outputs</span><span class="p">)</span>

            <span class="k">else</span><span class="o">:</span>

              <span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span>

                  <span class="n">batch_outputs</span><span class="p">,</span>

                  <span class="n">lambda</span> <span class="n">output</span><span class="p">,</span> <span class="n">batch_output</span><span class="o">:</span> <span class="n">output</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_output</span><span class="p">),</span>

                  <span class="n">outputs</span><span class="p">,</span> <span class="n">batch_outputs</span><span class="p">)</span>

            <span class="n">end_step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">+</span> <span class="n">data_handler</span><span class="p">.</span><span class="n">step_increment</span>

            <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_batch_end</span><span class="p">(</span><span class="n">end_step</span><span class="p">,</span> <span class="err">{</span><span class="s1">&#39;outputs&#39;</span><span class="o">:</span> <span class="n">batch_outputs</span><span class="err">}</span><span class="p">)</span>

      <span class="k">if</span> <span class="n">batch_outputs</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;Expect x to be a non-empty array or dataset.&#39;</span><span class="p">)</span>

      <span class="n">callbacks</span><span class="p">.</span><span class="n">on_predict_end</span><span class="p">()</span>

    <span class="n">all_outputs</span> <span class="o">=</span> <span class="n">nest</span><span class="p">.</span><span class="n">map_structure_up_to</span><span class="p">(</span><span class="n">batch_outputs</span><span class="p">,</span> <span class="n">concat</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="n">all_outputs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_generator_2">predict_generator</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_generator</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">,</span>
    <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">use_multiprocessing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="p">)</span>
</code></pre></div>

<p>Generates predictions for the input samples from a data generator.</p>
<p>DEPRECATED:
  <code>Model.predict</code> now supports generators, so there is no longer any need
  to use this endpoint.</p>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">predict_generator</span><span class="p">(</span><span class="k">self</span><span class="p">,</span>

                        <span class="n">generator</span><span class="p">,</span>

                        <span class="n">steps</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                        <span class="n">callbacks</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                        <span class="n">max_queue_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>

                        <span class="n">workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>

                        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="k">False</span><span class="p">,</span>

                        <span class="k">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Generates predictions for the input samples from a data generator.</span>

<span class="ss">    DEPRECATED:</span>

<span class="ss">      `Model.predict` now supports generators, so there is no longer any need</span>

<span class="ss">      to use this endpoint.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="p">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;`Model.predict_generator` is deprecated and &#39;</span>

                  <span class="s1">&#39;will be removed in a future version. &#39;</span>

                  <span class="s1">&#39;Please use `Model.predict`, which supports generators.&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="k">self</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span>

        <span class="n">generator</span><span class="p">,</span>

        <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span>

        <span class="n">max_queue_size</span><span class="o">=</span><span class="n">max_queue_size</span><span class="p">,</span>

        <span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">,</span>

        <span class="n">use_multiprocessing</span><span class="o">=</span><span class="n">use_multiprocessing</span><span class="p">,</span>

        <span class="k">verbose</span><span class="o">=</span><span class="k">verbose</span><span class="p">,</span>

        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_on_batch_2">predict_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns predictions for a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be: - A Numpy array (or array-like), or a list</td>
<td></td>
</tr>
<tr>
<td>of arrays (in case the model has multiple inputs). - A TensorFlow</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>tensor, or a list of tensors (in case the model has multiple inputs).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Numpy array(s) of predictions.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.predict_on_batch</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of mismatch between given number of inputs and</td>
</tr>
<tr>
<td>expectations of the model.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">predict_on_batch</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Returns predictions for a single batch of samples.</span>

<span class="ss">    Arguments:</span>

<span class="ss">        x: Input data. It could be: - A Numpy array (or array-like), or a list</span>

<span class="ss">          of arrays (in case the model has multiple inputs). - A TensorFlow</span>

<span class="ss">          tensor, or a list of tensors (in case the model has multiple inputs).</span>

<span class="ss">    Returns:</span>

<span class="ss">        Numpy array(s) of predictions.</span>

<span class="ss">    Raises:</span>

<span class="ss">        RuntimeError: If `model.predict_on_batch` is wrapped in `tf.function`.</span>

<span class="ss">        ValueError: In case of mismatch between given number of inputs and</span>

<span class="ss">          expectations of the model.</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="k">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;predict_on_batch&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;predict_on_batch&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="k">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="k">scope</span><span class="p">():</span>

      <span class="n">iterator</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

      <span class="k">self</span><span class="p">.</span><span class="n">predict_function</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">make_predict_function</span><span class="p">()</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="k">self</span><span class="p">.</span><span class="n">predict_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="predict_step_2">predict_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<p>Perform an inference and returns the boxes, scores and labels associated.</p>
<p>Background is discarded the max and argmax operation are performed.
It means that if background was predicted the second maximum score would
be outputed.</p>
<p>Example: background + 3 classes
[0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</p>
<p>"To optimize for AP, we override the prediction of these slots
with the second highest scoring class, using the corresponding confidence"
Part 4. Experiments of Object Detection with Transformers</p>
<p>Returns:</p>
<ul>
<li><em>boxes</em>: A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]
containing the boxes with the coordinates between 0 and 1.</li>
<li><em>scores</em>: A Tensor of shape [batch_size, self.num_queries] containing
the score of the boxes.</li>
<li><em>classes</em>: A Tensor of shape [batch_size, self.num_queries]
containing the class of the boxes [0, num_classes).</li>
</ul>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">predict_step</span><span class="p">(</span><span class="k">self</span><span class="p">,</span> <span class="k">data</span><span class="p">):</span>

        <span class="ss">&quot;&quot;&quot;Perform an inference and returns the boxes, scores and labels associated.</span>

<span class="ss">        Background is discarded the max and argmax operation are performed.</span>

<span class="ss">        It means that if background was predicted the second maximum score would</span>

<span class="ss">        be outputed.</span>

<span class="ss">        Example: background + 3 classes</span>

<span class="ss">        [0.54, 0.40, 0.03, 0.03] =&gt; score = 0.40, label = 0 (1 - 1)</span>

<span class="ss">        &quot;</span><span class="k">To</span> <span class="n">optimize</span> <span class="k">for</span> <span class="n">AP</span><span class="p">,</span> <span class="n">we</span> <span class="n">override</span> <span class="n">the</span> <span class="n">prediction</span> <span class="k">of</span> <span class="n">these</span> <span class="n">slots</span>

        <span class="k">with</span> <span class="n">the</span> <span class="k">second</span> <span class="n">highest</span> <span class="n">scoring</span> <span class="k">class</span><span class="p">,</span> <span class="k">using</span> <span class="n">the</span> <span class="k">corresponding</span> <span class="n">confidence</span><span class="ss">&quot;</span>

<span class="ss">        Part 4. Experiments of Object Detection with Transformers</span>

<span class="ss">        Returns:</span>

<span class="ss">        - *boxes*: A Tensor of shape [batch_size, self.num_queries, (y1,x1,y2,x2)]</span>

<span class="ss">        containing the boxes with the coordinates between 0 and 1.</span>

<span class="ss">        - *scores*: A Tensor of shape [batch_size, self.num_queries] containing</span>

<span class="ss">        the score of the boxes.</span>

<span class="ss">        - *classes*: A Tensor of shape [batch_size, self.num_queries]</span>

<span class="ss">        containing the class of the boxes [0, num_classes).</span>

<span class="ss">        &quot;&quot;&quot;</span>

        <span class="k">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="k">data</span><span class="p">)</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="k">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="k">False</span><span class="p">)</span>

        <span class="n">boxes_without_padding</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">detr_postprocessing</span><span class="p">(</span>

            <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="p">.</span><span class="n">BOXES</span><span class="p">],</span>

            <span class="n">y_pred</span><span class="p">[</span><span class="n">BoxField</span><span class="p">.</span><span class="n">SCORES</span><span class="p">],</span>

            <span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES_INFO</span><span class="p">],</span>

            <span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span>

        <span class="p">)</span>

        <span class="k">return</span> <span class="n">boxes_without_padding</span><span class="p">,</span> <span class="n">scores</span><span class="p">,</span> <span class="n">labels</span>
</code></pre></div>

</details>
<h4 id="reset_metrics_2">reset_metrics</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_metrics</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<p>Resets the state of all the metrics in the model.</p>
<p>Examples:</p>
<blockquote>
<blockquote>
<blockquote>
<p>inputs = tf.keras.layers.Input(shape=(3,))
outputs = tf.keras.layers.Dense(2)(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
model.compile(optimizer="Adam", loss="mse", metrics=["mae"])</p>
<p>x = np.random.random((2, 3))
y = np.random.randint(0, 2, (2, 2))
_ = model.fit(x, y, verbose=0)
assert all(float(m.result()) for m in model.metrics)</p>
<p>model.reset_metrics()
assert all(float(m.result()) == 0 for m in model.metrics)</p>
</blockquote>
</blockquote>
</blockquote>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">reset_metrics</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="ss">&quot;&quot;&quot;Resets the state of all the metrics in the model.</span>

<span class="ss">    Examples:</span>

<span class="ss">    &gt;&gt;&gt; inputs = tf.keras.layers.Input(shape=(3,))</span>

<span class="ss">    &gt;&gt;&gt; outputs = tf.keras.layers.Dense(2)(inputs)</span>

<span class="ss">    &gt;&gt;&gt; model = tf.keras.models.Model(inputs=inputs, outputs=outputs)</span>

<span class="ss">    &gt;&gt;&gt; model.compile(optimizer=&quot;</span><span class="n">Adam</span><span class="ss">&quot;, loss=&quot;</span><span class="n">mse</span><span class="ss">&quot;, metrics=[&quot;</span><span class="n">mae</span><span class="ss">&quot;])</span>

<span class="ss">    &gt;&gt;&gt; x = np.random.random((2, 3))</span>

<span class="ss">    &gt;&gt;&gt; y = np.random.randint(0, 2, (2, 2))</span>

<span class="ss">    &gt;&gt;&gt; _ = model.fit(x, y, verbose=0)</span>

<span class="ss">    &gt;&gt;&gt; assert all(float(m.result()) for m in model.metrics)</span>

<span class="ss">    &gt;&gt;&gt; model.reset_metrics()</span>

<span class="ss">    &gt;&gt;&gt; assert all(float(m.result()) == 0 for m in model.metrics)</span>

<span class="ss">    &quot;&quot;&quot;</span>

    <span class="k">for</span> <span class="n">m</span> <span class="k">in</span> <span class="k">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">:</span>

      <span class="n">m</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="reset_states_2">reset_states</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">reset_states</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">reset_states</span><span class="p">(</span><span class="k">self</span><span class="p">):</span>

    <span class="k">for</span> <span class="n">layer</span> <span class="k">in</span> <span class="k">self</span><span class="p">.</span><span class="n">layers</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;reset_states&#39;</span><span class="p">)</span> <span class="k">and</span> <span class="n">getattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;stateful&#39;</span><span class="p">,</span> <span class="k">False</span><span class="p">):</span>

        <span class="n">layer</span><span class="p">.</span><span class="n">reset_states</span><span class="p">()</span>
</code></pre></div>

</details>
<h4 id="save_2">save</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">signatures</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">save_traces</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves the model to Tensorflow SavedModel or a single HDF5 file.</p>
<p>Please see <code>tf.keras.models.save_model</code> or the
<a href="https://keras.io/guides/serialization_and_saving/">Serialization and Saving guide</a>
for details.</p>
<p>Arguments:
    filepath: String, PathLike, path to SavedModel or H5 file to save the
        model.
    overwrite: Whether to silently overwrite any existing file at the
        target location, or provide the user with a manual prompt.
    include_optimizer: If True, save optimizer's state together.
    save_format: Either <code>'tf'</code> or <code>'h5'</code>, indicating whether to save the
        model to Tensorflow SavedModel or HDF5. Defaults to 'tf' in TF 2.X,
        and 'h5' in TF 1.X.
    signatures: Signatures to save with the SavedModel. Applicable to the
        'tf' format only. Please see the <code>signatures</code> argument in
        <code>tf.saved_model.save</code> for details.
    options: (only applies to SavedModel format)
        <code>tf.saved_model.SaveOptions</code> object that specifies options for
        saving to SavedModel.
    save_traces: (only applies to SavedModel format) When enabled, the
        SavedModel will store the function traces for each layer. This
        can be disabled, so that only the configs of each layer are stored.
        Defaults to <code>True</code>. Disabling this will decrease serialization time
        and reduce file size, but it requires that all custom layers/models
        implement a <code>get_config()</code> method.</p>
<p>Example:</p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>

<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>  <span class="c1"># creates a HDF5 file &#39;my_model.h5&#39;</span>
<span class="k">del</span> <span class="n">model</span>  <span class="c1"># deletes the existing model</span>

<span class="c1"># returns a compiled model</span>
<span class="c1"># identical to the previous one</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;my_model.h5&#39;</span><span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">save</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

           <span class="n">filepath</span><span class="p">,</span>

           <span class="n">overwrite</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

           <span class="n">include_optimizer</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

           <span class="n">save_format</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

           <span class="n">signatures</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

           <span class="k">options</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

           <span class="n">save_traces</span><span class="o">=</span><span class="no">True</span><span class="p">)</span><span class="o">:</span>

    <span class="c1"># pylint: disable=line-too-long</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Saves the model to Tensorflow SavedModel or a single HDF5 file.</span>

<span class="s2">    Please see `tf.keras.models.save_model` or the</span>

<span class="s2">    [Serialization and Saving guide](https://keras.io/guides/serialization_and_saving/)</span>

<span class="s2">    for details.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        filepath: String, PathLike, path to SavedModel or H5 file to save the</span>

<span class="s2">            model.</span>

<span class="s2">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="s2">            target location, or provide the user with a manual prompt.</span>

<span class="s2">        include_optimizer: If True, save optimizer&#39;s state together.</span>

<span class="s2">        save_format: Either `&#39;tf&#39;` or `&#39;h5&#39;`, indicating whether to save the</span>

<span class="s2">            model to Tensorflow SavedModel or HDF5. Defaults to &#39;tf&#39; in TF 2.X,</span>

<span class="s2">            and &#39;h5&#39; in TF 1.X.</span>

<span class="s2">        signatures: Signatures to save with the SavedModel. Applicable to the</span>

<span class="s2">            &#39;tf&#39; format only. Please see the `signatures` argument in</span>

<span class="s2">            `tf.saved_model.save` for details.</span>

<span class="s2">        options: (only applies to SavedModel format)</span>

<span class="s2">            `tf.saved_model.SaveOptions` object that specifies options for</span>

<span class="s2">            saving to SavedModel.</span>

<span class="s2">        save_traces: (only applies to SavedModel format) When enabled, the</span>

<span class="s2">            SavedModel will store the function traces for each layer. This</span>

<span class="s2">            can be disabled, so that only the configs of each layer are stored.</span>

<span class="s2">            Defaults to `True`. Disabling this will decrease serialization time</span>

<span class="s2">            and reduce file size, but it requires that all custom layers/models</span>

<span class="s2">            implement a `get_config()` method.</span>

<span class="s2">    Example:</span>

<span class="s2">    ```python</span>

<span class="s2">    from keras.models import load_model</span>

<span class="s2">    model.save(&#39;my_model.h5&#39;)  # creates a HDF5 file &#39;my_model.h5&#39;</span>

<span class="s2">    del model  # deletes the existing model</span>

<span class="s2">    # returns a compiled model</span>

<span class="s2">    # identical to the previous one</span>

<span class="s2">    model = load_model(&#39;my_model.h5&#39;)</span>

<span class="s2">    ```</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="c1"># pylint: enable=line-too-long</span>

    <span class="n">save</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="p">,</span> <span class="n">save_format</span><span class="p">,</span>

                    <span class="n">signatures</span><span class="p">,</span> <span class="k">options</span><span class="p">,</span> <span class="n">save_traces</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="save_weights_2">save_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">filepath</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Saves all layer weights.</p>
<p>Either saves in HDF5 or in TensorFlow format based on the <code>save_format</code>
argument.</p>
<p>When saving in HDF5 format, the weight file has:
  - <code>layer_names</code> (attribute), a list of strings
      (ordered names of model layers).
  - For every layer, a <code>group</code> named <code>layer.name</code>
      - For every such layer group, a group attribute <code>weight_names</code>,
          a list of strings
          (ordered names of weights tensor of the layer).
      - For every weight in the layer, a dataset
          storing the weight value, named after the weight tensor.</p>
<p>When saving in TensorFlow format, all objects referenced by the network are
saved in the same format as <code>tf.train.Checkpoint</code>, including any <code>Layer</code>
instances or <code>Optimizer</code> instances assigned to object attributes. For
networks constructed from inputs and outputs using <code>tf.keras.Model(inputs,
outputs)</code>, <code>Layer</code> instances used by the network are tracked/saved
automatically. For user-defined classes which inherit from <code>tf.keras.Model</code>,
<code>Layer</code> instances must be assigned to object attributes, typically in the
constructor. See the documentation of <code>tf.train.Checkpoint</code> and
<code>tf.keras.Model</code> for details.</p>
<p>While the formats are the same, do not mix <code>save_weights</code> and
<code>tf.train.Checkpoint</code>. Checkpoints saved by <code>Model.save_weights</code> should be
loaded using <code>Model.load_weights</code>. Checkpoints saved using
<code>tf.train.Checkpoint.save</code> should be restored using the corresponding
<code>tf.train.Checkpoint.restore</code>. Prefer <code>tf.train.Checkpoint</code> over
<code>save_weights</code> for training checkpoints.</p>
<p>The TensorFlow format matches objects and variables by starting at a root
object, <code>self</code> for <code>save_weights</code>, and greedily matching attribute
names. For <code>Model.save</code> this is the <code>Model</code>, and for <code>Checkpoint.save</code> this
is the <code>Checkpoint</code> even if the <code>Checkpoint</code> has a model attached. This
means saving a <code>tf.keras.Model</code> using <code>save_weights</code> and loading into a
<code>tf.train.Checkpoint</code> with a <code>Model</code> attached (or vice versa) will not match
the <code>Model</code>'s variables. See the <a href="https://www.tensorflow.org/guide/checkpoint">guide to training
checkpoints</a> for details
on the TensorFlow format.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>filepath</td>
<td>None</td>
<td>String or PathLike, path to the file to save the weights to.</td>
<td></td>
</tr>
<tr>
<td>When saving in TensorFlow format, this is the prefix used for</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>checkpoint files (multiple files are generated). Note that the '.h5'</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>suffix causes weights to be saved in HDF5 format.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>overwrite</td>
<td>None</td>
<td>Whether to silently overwrite any existing file at the</td>
<td></td>
</tr>
<tr>
<td>target location, or provide the user with a manual prompt.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>save_format</td>
<td>None</td>
<td>Either 'tf' or 'h5'. A <code>filepath</code> ending in '.h5' or</td>
<td></td>
</tr>
<tr>
<td>'.keras' will default to HDF5 if <code>save_format</code> is <code>None</code>. Otherwise</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>None</code> defaults to 'tf'.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>options</td>
<td>None</td>
<td>Optional <code>tf.train.CheckpointOptions</code> object that specifies</td>
<td></td>
</tr>
<tr>
<td>options for saving weights.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>If h5py is not available when attempting to save in HDF5</td>
</tr>
<tr>
<td>format.</td>
<td></td>
</tr>
<tr>
<td>ValueError</td>
<td>For invalid/unknown format arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>

                   <span class="n">filepath</span><span class="p">,</span>

                   <span class="n">overwrite</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

                   <span class="n">save_format</span><span class="o">=</span><span class="n">None</span><span class="p">,</span>

                   <span class="n">options</span><span class="o">=</span><span class="n">None</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Saves all layer weights.</span>

<span class="sd">    Either saves in HDF5 or in TensorFlow format based on the `save_format`</span>

<span class="sd">    argument.</span>

<span class="sd">    When saving in HDF5 format, the weight file has:</span>

<span class="sd">      - `layer_names` (attribute), a list of strings</span>

<span class="sd">          (ordered names of model layers).</span>

<span class="sd">      - For every layer, a `group` named `layer.name`</span>

<span class="sd">          - For every such layer group, a group attribute `weight_names`,</span>

<span class="sd">              a list of strings</span>

<span class="sd">              (ordered names of weights tensor of the layer).</span>

<span class="sd">          - For every weight in the layer, a dataset</span>

<span class="sd">              storing the weight value, named after the weight tensor.</span>

<span class="sd">    When saving in TensorFlow format, all objects referenced by the network are</span>

<span class="sd">    saved in the same format as `tf.train.Checkpoint`, including any `Layer`</span>

<span class="sd">    instances or `Optimizer` instances assigned to object attributes. For</span>

<span class="sd">    networks constructed from inputs and outputs using `tf.keras.Model(inputs,</span>

<span class="sd">    outputs)`, `Layer` instances used by the network are tracked/saved</span>

<span class="sd">    automatically. For user-defined classes which inherit from `tf.keras.Model`,</span>

<span class="sd">    `Layer` instances must be assigned to object attributes, typically in the</span>

<span class="sd">    constructor. See the documentation of `tf.train.Checkpoint` and</span>

<span class="sd">    `tf.keras.Model` for details.</span>

<span class="sd">    While the formats are the same, do not mix `save_weights` and</span>

<span class="sd">    `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be</span>

<span class="sd">    loaded using `Model.load_weights`. Checkpoints saved using</span>

<span class="sd">    `tf.train.Checkpoint.save` should be restored using the corresponding</span>

<span class="sd">    `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over</span>

<span class="sd">    `save_weights` for training checkpoints.</span>

<span class="sd">    The TensorFlow format matches objects and variables by starting at a root</span>

<span class="sd">    object, `self` for `save_weights`, and greedily matching attribute</span>

<span class="sd">    names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this</span>

<span class="sd">    is the `Checkpoint` even if the `Checkpoint` has a model attached. This</span>

<span class="sd">    means saving a `tf.keras.Model` using `save_weights` and loading into a</span>

<span class="sd">    `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match</span>

<span class="sd">    the `Model`&#39;s variables. See the [guide to training</span>

<span class="sd">    checkpoints](https://www.tensorflow.org/guide/checkpoint) for details</span>

<span class="sd">    on the TensorFlow format.</span>

<span class="sd">    Arguments:</span>

<span class="sd">        filepath: String or PathLike, path to the file to save the weights to.</span>

<span class="sd">            When saving in TensorFlow format, this is the prefix used for</span>

<span class="sd">            checkpoint files (multiple files are generated). Note that the &#39;.h5&#39;</span>

<span class="sd">            suffix causes weights to be saved in HDF5 format.</span>

<span class="sd">        overwrite: Whether to silently overwrite any existing file at the</span>

<span class="sd">            target location, or provide the user with a manual prompt.</span>

<span class="sd">        save_format: Either &#39;tf&#39; or &#39;h5&#39;. A `filepath` ending in &#39;.h5&#39; or</span>

<span class="sd">            &#39;.keras&#39; will default to HDF5 if `save_format` is `None`. Otherwise</span>

<span class="sd">            `None` defaults to &#39;tf&#39;.</span>

<span class="sd">        options: Optional `tf.train.CheckpointOptions` object that specifies</span>

<span class="sd">            options for saving weights.</span>

<span class="sd">    Raises:</span>

<span class="sd">        ImportError: If h5py is not available when attempting to save in HDF5</span>

<span class="sd">            format.</span>

<span class="sd">        ValueError: For invalid/unknown format arguments.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_assert_weights_created</span><span class="p">()</span>

    <span class="n">filepath</span> <span class="o">=</span> <span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

    <span class="n">filepath_is_h5</span> <span class="o">=</span> <span class="n">_is_hdf5_filepath</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">filepath_is_h5</span><span class="p">:</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;tf&#39;</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="n">user_format</span> <span class="o">=</span> <span class="n">save_format</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

      <span class="k">if</span> <span class="n">user_format</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;tensorflow&#39;</span><span class="p">,</span> <span class="s1">&#39;tf&#39;</span><span class="p">):</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;tf&#39;</span>

      <span class="k">elif</span> <span class="n">user_format</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;hdf5&#39;</span><span class="p">,</span> <span class="s1">&#39;h5&#39;</span><span class="p">,</span> <span class="s1">&#39;keras&#39;</span><span class="p">):</span>

        <span class="n">save_format</span> <span class="o">=</span> <span class="s1">&#39;h5&#39;</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

            <span class="s1">&#39;Unknown format &quot;</span><span class="si">%s</span><span class="s1">&quot;. Was expecting one of {&quot;tf&quot;, &quot;h5&quot;}.&#39;</span> <span class="o">%</span> <span class="p">(</span>

                <span class="n">save_format</span><span class="p">,))</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span> <span class="ow">and</span> <span class="n">filepath_is_h5</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="p">(</span><span class="s1">&#39;save_weights got save_format=&quot;tf&quot;/&quot;tensorflow&quot;, but the &#39;</span>

           <span class="s1">&#39;filepath (&quot;</span><span class="si">%s</span><span class="s1">&quot;) looks like an HDF5 file. Omit the &quot;.h5&quot;/&quot;.keras&quot; &#39;</span>

           <span class="s1">&#39;when saving in TensorFlow format.&#39;</span><span class="p">)</span>

          <span class="o">%</span> <span class="n">filepath</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;h5&#39;</span> <span class="ow">and</span> <span class="n">h5py</span> <span class="k">is</span> <span class="n">None</span><span class="p">:</span>

      <span class="n">raise</span> <span class="n">ImportError</span><span class="p">(</span>

          <span class="s1">&#39;`save_weights` requires h5py when saving in hdf5.&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;tf&#39;</span><span class="p">:</span>

      <span class="n">check_filepath</span> <span class="o">=</span> <span class="n">filepath</span> <span class="o">+</span> <span class="s1">&#39;.index&#39;</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="n">check_filepath</span> <span class="o">=</span> <span class="n">filepath</span>

    <span class="c1"># If file exists and should not be overwritten:</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">overwrite</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">):</span>

      <span class="n">proceed</span> <span class="o">=</span> <span class="n">ask_to_proceed_with_overwrite</span><span class="p">(</span><span class="n">check_filepath</span><span class="p">)</span>

      <span class="k">if</span> <span class="ow">not</span> <span class="n">proceed</span><span class="p">:</span>

        <span class="k">return</span>

    <span class="k">if</span> <span class="n">save_format</span> <span class="o">==</span> <span class="s1">&#39;h5&#39;</span><span class="p">:</span>

      <span class="n">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>

        <span class="n">hdf5_format</span><span class="o">.</span><span class="n">save_weights_to_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">context</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>

        <span class="n">session</span> <span class="o">=</span> <span class="n">None</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">session</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>

      <span class="n">optimizer</span> <span class="o">=</span> <span class="n">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;optimizer&#39;</span><span class="p">,</span> <span class="n">None</span><span class="p">)</span>

      <span class="k">if</span> <span class="p">(</span><span class="n">optimizer</span>

          <span class="ow">and</span> <span class="ow">not</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">trackable</span><span class="o">.</span><span class="n">Trackable</span><span class="p">)):</span>

        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>

            <span class="p">(</span><span class="s1">&#39;This model was compiled with a Keras optimizer (</span><span class="si">%s</span><span class="s1">) but is being &#39;</span>

             <span class="s1">&#39;saved in TensorFlow format with `save_weights`. The model</span><span class="se">\&#39;</span><span class="s1">s &#39;</span>

             <span class="s1">&#39;weights will be saved, but unlike with TensorFlow optimizers in &#39;</span>

             <span class="s1">&#39;the TensorFlow format the optimizer</span><span class="se">\&#39;</span><span class="s1">s state will not be &#39;</span>

             <span class="s1">&#39;saved.</span><span class="se">\n\n</span><span class="s1">Consider using a TensorFlow optimizer from `tf.train`.&#39;</span><span class="p">)</span>

            <span class="o">%</span> <span class="p">(</span><span class="n">optimizer</span><span class="p">,))</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">_trackable_saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">session</span><span class="o">=</span><span class="n">session</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="n">options</span><span class="p">)</span>

      <span class="c1"># Record this checkpoint so it&#39;s visible from tf.train.latest_checkpoint.</span>

      <span class="n">checkpoint_management</span><span class="o">.</span><span class="n">update_checkpoint_state_internal</span><span class="p">(</span>

          <span class="n">save_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">filepath</span><span class="p">),</span>

          <span class="n">model_checkpoint_path</span><span class="o">=</span><span class="n">filepath</span><span class="p">,</span>

          <span class="n">save_relative_paths</span><span class="o">=</span><span class="n">True</span><span class="p">,</span>

          <span class="n">all_model_checkpoint_paths</span><span class="o">=</span><span class="p">[</span><span class="n">filepath</span><span class="p">])</span>
</code></pre></div>

</details>
<h4 id="set_weights_2">set_weights</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">weights</span>
<span class="p">)</span>
</code></pre></div>

<p>Sets the weights of the layer, from Numpy arrays.</p>
<p>The weights of a layer represent the state of the layer. This function
sets the weight values from numpy arrays. The weight values should be
passed in the order they are created by the layer. Note that the layer's
weights must be instantiated before calling this function by calling
the layer.</p>
<p>For example, a Dense layer returns a list of two values-- per-output
weights and the bias value. These can be used to set the weights of another
Dense layer:</p>
<blockquote>
<blockquote>
<blockquote>
<p>a = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(1.))
a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))
a.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]
b = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(2.))
b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))
b.get_weights()
[array([[2.],
       [2.],
       [2.]], dtype=float32), array([0.], dtype=float32)]
b.set_weights(a.get_weights())
b.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>weights</td>
<td>None</td>
<td>a list of Numpy arrays. The number</td>
<td></td>
</tr>
<tr>
<td>of arrays and their shape must match</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>number of the dimensions of the weights</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>of the layer (i.e. it should match the</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>output of <code>get_weights</code>).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>If the provided weights list does not match the</td>
</tr>
<tr>
<td>layer's specifications.</td>
<td></td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Sets the weights of the layer, from Numpy arrays.</span>

<span class="sd">    The weights of a layer represent the state of the layer. This function</span>

<span class="sd">    sets the weight values from numpy arrays. The weight values should be</span>

<span class="sd">    passed in the order they are created by the layer. Note that the layer&#39;s</span>

<span class="sd">    weights must be instantiated before calling this function by calling</span>

<span class="sd">    the layer.</span>

<span class="sd">    For example, a Dense layer returns a list of two values-- per-output</span>

<span class="sd">    weights and the bias value. These can be used to set the weights of another</span>

<span class="sd">    Dense layer:</span>

<span class="sd">    &gt;&gt;&gt; a = tf.keras.layers.Dense(1,</span>

<span class="sd">    ...   kernel_initializer=tf.constant_initializer(1.))</span>

<span class="sd">    &gt;&gt;&gt; a_out = a(tf.convert_to_tensor([[1., 2., 3.]]))</span>

<span class="sd">    &gt;&gt;&gt; a.get_weights()</span>

<span class="sd">    [array([[1.],</span>

<span class="sd">           [1.],</span>

<span class="sd">           [1.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    &gt;&gt;&gt; b = tf.keras.layers.Dense(1,</span>

<span class="sd">    ...   kernel_initializer=tf.constant_initializer(2.))</span>

<span class="sd">    &gt;&gt;&gt; b_out = b(tf.convert_to_tensor([[10., 20., 30.]]))</span>

<span class="sd">    &gt;&gt;&gt; b.get_weights()</span>

<span class="sd">    [array([[2.],</span>

<span class="sd">           [2.],</span>

<span class="sd">           [2.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    &gt;&gt;&gt; b.set_weights(a.get_weights())</span>

<span class="sd">    &gt;&gt;&gt; b.get_weights()</span>

<span class="sd">    [array([[1.],</span>

<span class="sd">           [1.],</span>

<span class="sd">           [1.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    Arguments:</span>

<span class="sd">        weights: a list of Numpy arrays. The number</span>

<span class="sd">            of arrays and their shape must match</span>

<span class="sd">            number of the dimensions of the weights</span>

<span class="sd">            of the layer (i.e. it should match the</span>

<span class="sd">            output of `get_weights`).</span>

<span class="sd">    Raises:</span>

<span class="sd">        ValueError: If the provided weights list does not match the</span>

<span class="sd">            layer&#39;s specifications.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>

    <span class="n">expected_num_weights</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">TrackableWeightHandler</span><span class="p">):</span>

        <span class="n">expected_num_weights</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">num_tensors</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">expected_num_weights</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">expected_num_weights</span> <span class="o">!=</span> <span class="n">len</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

          <span class="s1">&#39;You called `set_weights(weights)` on layer &quot;</span><span class="si">%s</span><span class="s1">&quot; &#39;</span>

          <span class="s1">&#39;with a weight list of length </span><span class="si">%s</span><span class="s1">, but the layer was &#39;</span>

          <span class="s1">&#39;expecting </span><span class="si">%s</span><span class="s1"> weights. Provided weights: </span><span class="si">%s</span><span class="s1">...&#39;</span> <span class="o">%</span>

          <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">len</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">expected_num_weights</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">weights</span><span class="p">)[:</span><span class="mi">50</span><span class="p">]))</span>

    <span class="n">weight_index</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">weight_value_tuples</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>

      <span class="k">if</span> <span class="n">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">TrackableWeightHandler</span><span class="p">):</span>

        <span class="n">num_tensors</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">num_tensors</span>

        <span class="n">tensors</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="p">:</span><span class="n">weight_index</span> <span class="o">+</span> <span class="n">num_tensors</span><span class="p">]</span>

        <span class="n">param</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>

        <span class="n">weight_index</span> <span class="o">+=</span> <span class="n">num_tensors</span>

      <span class="k">else</span><span class="p">:</span>

        <span class="n">weight</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="p">]</span>

        <span class="n">ref_shape</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">shape</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">ref_shape</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>

          <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span>

              <span class="s1">&#39;Layer weight shape </span><span class="si">%s</span><span class="s1"> not compatible with provided weight &#39;</span>

              <span class="s1">&#39;shape </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ref_shape</span><span class="p">,</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

        <span class="n">weight_value_tuples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">param</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>

        <span class="n">weight_index</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">backend</span><span class="o">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">weight_value_tuples</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="summary_2">summary</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">summary</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">line_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">print_fn</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
</code></pre></div>

<p>Prints a string summary of the network.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>line_length</td>
<td>None</td>
<td>Total length of printed lines</td>
<td></td>
</tr>
<tr>
<td>(e.g. set this to adapt the display to different</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>terminal window sizes).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>positions</td>
<td>None</td>
<td>Relative or absolute positions of log elements</td>
<td></td>
</tr>
<tr>
<td>in each line. If not provided,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>defaults to <code>[.33, .55, .67, 1.]</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>print_fn</td>
<td>None</td>
<td>Print function to use. Defaults to <code>print</code>.</td>
<td></td>
</tr>
<tr>
<td>It will be called on each line of the summary.</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>You can set it to a custom function</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>in order to capture the string summary.</td>
<td><code>print</code></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ValueError</td>
<td>if <code>summary()</code> is called before the model is built.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">line_length</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="n">positions</span><span class="o">=</span><span class="k">None</span><span class="p">,</span> <span class="n">print_fn</span><span class="o">=</span><span class="k">None</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Prints a string summary of the network.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        line_length: Total length of printed lines</span>

<span class="s2">            (e.g. set this to adapt the display to different</span>

<span class="s2">            terminal window sizes).</span>

<span class="s2">        positions: Relative or absolute positions of log elements</span>

<span class="s2">            in each line. If not provided,</span>

<span class="s2">            defaults to `[.33, .55, .67, 1.]`.</span>

<span class="s2">        print_fn: Print function to use. Defaults to `print`.</span>

<span class="s2">            It will be called on each line of the summary.</span>

<span class="s2">            You can set it to a custom function</span>

<span class="s2">            in order to capture the string summary.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ValueError: if `summary()` is called before the model is built.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="k">not</span> <span class="n">self</span><span class="p">.</span><span class="n">built</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ValueError</span><span class="p">(</span><span class="s1">&#39;This model has not yet been built. &#39;</span>

                       <span class="s1">&#39;Build the model first by calling `build()` or calling &#39;</span>

                       <span class="s1">&#39;`fit()` with some data, or specify &#39;</span>

                       <span class="s1">&#39;an `input_shape` argument in the first layer(s) for &#39;</span>

                       <span class="s1">&#39;automatic build.&#39;</span><span class="p">)</span>

    <span class="n">layer_utils</span><span class="p">.</span><span class="n">print_summary</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                              <span class="n">line_length</span><span class="o">=</span><span class="n">line_length</span><span class="p">,</span>

                              <span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span>

                              <span class="n">print_fn</span><span class="o">=</span><span class="n">print_fn</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="test_on_batch_2">test_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Test the model on a single batch of samples.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be: - A Numpy array (or array-like), or a list</td>
<td></td>
</tr>
<tr>
<td>of arrays (in case the model has multiple inputs). - A TensorFlow</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>tensor, or a list of tensors (in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A dict mapping input names to the corresponding array/tensors, if</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>the model has named inputs.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy</td>
<td></td>
</tr>
<tr>
<td>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional array of the same length as x, containing</td>
<td></td>
</tr>
<tr>
<td>weights to apply to the model's loss for each sample. In the case of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>temporal data, you can pass a 2D array with shape (samples,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sequence_length), to apply a different weight to every timestep of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>every sample.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>reset_metrics</td>
<td>None</td>
<td>If <code>True</code>, the metrics returned will be only for this</td>
<td></td>
</tr>
<tr>
<td>batch. If <code>False</code>, the metrics will be statefully accumulated across</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>batches.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,</td>
<td></td>
</tr>
<tr>
<td>with each key being the name of the metric. If <code>False</code>, they are</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returned as a list.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar test loss (if the model has a single output and no metrics)</td>
</tr>
<tr>
<td>or list of scalars (if the model has multiple outputs</td>
<td></td>
</tr>
<tr>
<td>and/or metrics). The attribute <code>model.metrics_names</code> will give you</td>
<td></td>
</tr>
<tr>
<td>the display labels for the scalar outputs.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.test_on_batch</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of invalid user-provided arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">test_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                    <span class="n">x</span><span class="p">,</span>

                    <span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                    <span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

                    <span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Test the model on a single batch of samples.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input data. It could be: - A Numpy array (or array-like), or a list</span>

<span class="s2">          of arrays (in case the model has multiple inputs). - A TensorFlow</span>

<span class="s2">          tensor, or a list of tensors (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors, if</span>

<span class="s2">          the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar test loss (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">        RuntimeError: If `model.test_on_batch` is wrapped in `tf.function`.</span>

<span class="s2">        ValueError: In case of invalid user-provided arguments.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;test_on_batch&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">()</span><span class="o">:</span>

      <span class="n">iterator</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>

                                                    <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">test_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_test_function</span><span class="p">()</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">test_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">reset_metrics</span><span class="o">:</span>

      <span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

    <span class="k">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_dict</span><span class="o">:</span>

      <span class="k">return</span> <span class="k">logs</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">results</span> <span class="o">=</span> <span class="err">[</span><span class="k">logs</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="k">name</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">for</span> <span class="k">name</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="err">]</span>

      <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

        <span class="k">return</span> <span class="n">results</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

      <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

</details>
<h4 id="test_step_2">test_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">test_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span><span class="o">:</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="p">#</span> <span class="n">To</span> <span class="n">compute</span> <span class="n">the</span> <span class="n">loss</span> <span class="n">we</span> <span class="n">need</span> <span class="n">to</span> <span class="n">get</span> <span class="n">the</span> <span class="n">results</span> <span class="n">of</span> <span class="n">each</span> <span class="n">decoder</span> <span class="n">layer</span>

        <span class="p">#</span> <span class="n">Setting</span> <span class="n">training</span> <span class="n">to</span> <span class="n">True</span> <span class="n">will</span> <span class="n">provide</span> <span class="n">it</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>

        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="p">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mh">1</span><span class="o">:</span><span class="mh">3</span><span class="p">],</span> <span class="n">self</span><span class="p">.</span><span class="n">compute_dtype</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">+=</span> <span class="n">self</span><span class="p">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">None</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="n">self</span><span class="p">.</span><span class="n">loss_metric</span><span class="p">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="p">.</span><span class="nl">name:</span> <span class="n">m</span><span class="p">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="n">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics</span><span class="p">}</span>
</code></pre></div>

</details>
<h4 id="to_json_2">to_json</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a JSON string containing the network configuration.</p>
<p>To load a network from a JSON save file, use
<code>keras.models.model_from_json(json_string, custom_objects={})</code>.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments</td>
<td></td>
</tr>
<tr>
<td>to be passed to <code>json.dumps()</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A JSON string.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>

    <span class="sd">&quot;&quot;&quot;Returns a JSON string containing the network configuration.</span>

<span class="sd">    To load a network from a JSON save file, use</span>

<span class="sd">    `keras.models.model_from_json(json_string, custom_objects={})`.</span>

<span class="sd">    Arguments:</span>

<span class="sd">        **kwargs: Additional keyword arguments</span>

<span class="sd">            to be passed to `json.dumps()`.</span>

<span class="sd">    Returns:</span>

<span class="sd">        A JSON string.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_updated_config</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span>

        <span class="n">model_config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">json_utils</span><span class="o">.</span><span class="n">get_json_type</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="to_yaml_2">to_yaml</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">to_yaml</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>
<span class="p">)</span>
</code></pre></div>

<p>Returns a yaml string containing the network configuration.</p>
<p>To load a network from a yaml save file, use
<code>keras.models.model_from_yaml(yaml_string, custom_objects={})</code>.</p>
<p><code>custom_objects</code> should be a dictionary mapping
the names of custom losses / layers / etc to the corresponding
functions / classes.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>**kwargs</td>
<td>None</td>
<td>Additional keyword arguments</td>
<td></td>
</tr>
<tr>
<td>to be passed to <code>yaml.dump()</code>.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>A YAML string.</td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>ImportError</td>
<td>if yaml module is not found.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">to_yaml</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Returns a yaml string containing the network configuration.</span>

<span class="s2">    To load a network from a yaml save file, use</span>

<span class="s2">    `keras.models.model_from_yaml(yaml_string, custom_objects={})`.</span>

<span class="s2">    `custom_objects` should be a dictionary mapping</span>

<span class="s2">    the names of custom losses / layers / etc to the corresponding</span>

<span class="s2">    functions / classes.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        **kwargs: Additional keyword arguments</span>

<span class="s2">            to be passed to `yaml.dump()`.</span>

<span class="s2">    Returns:</span>

<span class="s2">        A YAML string.</span>

<span class="s2">    Raises:</span>

<span class="s2">        ImportError: if yaml module is not found.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="k">if</span> <span class="n">yaml</span> <span class="k">is</span> <span class="k">None</span><span class="o">:</span>

      <span class="n">raise</span> <span class="n">ImportError</span><span class="p">(</span>

          <span class="s1">&#39;Requires yaml module installed (`pip install pyyaml`).&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">yaml</span><span class="p">.</span><span class="n">dump</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">_updated_config</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>

</details>
<h4 id="train_on_batch_2">train_on_batch</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_on_batch</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">reset_metrics</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</code></pre></div>

<p>Runs a single gradient update on a single batch of data.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>x</td>
<td>None</td>
<td>Input data. It could be:</td>
<td></td>
</tr>
<tr>
<td>- A Numpy array (or array-like), or a list of arrays</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A TensorFlow tensor, or a list of tensors</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(in case the model has multiple inputs).</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>- A dict mapping input names to the corresponding array/tensors,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>if the model has named inputs.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>y</td>
<td>None</td>
<td>Target data. Like the input data <code>x</code>, it could be either Numpy</td>
<td></td>
</tr>
<tr>
<td>array(s) or TensorFlow tensor(s). It should be consistent with <code>x</code></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(you cannot have Numpy inputs and tensor targets, or inversely).</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>sample_weight</td>
<td>None</td>
<td>Optional array of the same length as x, containing</td>
<td></td>
</tr>
<tr>
<td>weights to apply to the model's loss for each sample. In the case of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>temporal data, you can pass a 2D array with shape (samples,</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sequence_length), to apply a different weight to every timestep of</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>every sample.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>class_weight</td>
<td>None</td>
<td>Optional dictionary mapping class indices (integers) to a</td>
<td></td>
</tr>
<tr>
<td>weight (float) to apply to the model's loss for the samples from this</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>class during training. This can be useful to tell the model to "pay</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>more attention" to samples from an under-represented class.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>reset_metrics</td>
<td>None</td>
<td>If <code>True</code>, the metrics returned will be only for this</td>
<td></td>
</tr>
<tr>
<td>batch. If <code>False</code>, the metrics will be statefully accumulated across</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>batches.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
<tr>
<td>return_dict</td>
<td>None</td>
<td>If <code>True</code>, loss and metric results are returned as a dict,</td>
<td></td>
</tr>
<tr>
<td>with each key being the name of the metric. If <code>False</code>, they are</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>returned as a list.</td>
<td>None</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>Scalar training loss</td>
</tr>
<tr>
<td>(if the model has a single output and no metrics)</td>
<td></td>
</tr>
<tr>
<td>or list of scalars (if the model has multiple outputs</td>
<td></td>
</tr>
<tr>
<td>and/or metrics). The attribute <code>model.metrics_names</code> will give you</td>
<td></td>
</tr>
<tr>
<td>the display labels for the scalar outputs.</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Raises:</strong></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>RuntimeError</td>
<td>If <code>model.train_on_batch</code> is wrapped in <code>tf.function</code>.</td>
</tr>
<tr>
<td>ValueError</td>
<td>In case of invalid user-provided arguments.</td>
</tr>
</tbody>
</table>
<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>  <span class="n">def</span> <span class="n">train_on_batch</span><span class="p">(</span><span class="n">self</span><span class="p">,</span>

                     <span class="n">x</span><span class="p">,</span>

                     <span class="n">y</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                     <span class="n">sample_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                     <span class="n">class_weight</span><span class="o">=</span><span class="k">None</span><span class="p">,</span>

                     <span class="n">reset_metrics</span><span class="o">=</span><span class="no">True</span><span class="p">,</span>

                     <span class="n">return_dict</span><span class="o">=</span><span class="no">False</span><span class="p">)</span><span class="o">:</span>

    <span class="s2">&quot;</span><span class="se">&quot;&quot;</span><span class="s2">Runs a single gradient update on a single batch of data.</span>

<span class="s2">    Arguments:</span>

<span class="s2">        x: Input data. It could be:</span>

<span class="s2">          - A Numpy array (or array-like), or a list of arrays</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A TensorFlow tensor, or a list of tensors</span>

<span class="s2">              (in case the model has multiple inputs).</span>

<span class="s2">          - A dict mapping input names to the corresponding array/tensors,</span>

<span class="s2">              if the model has named inputs.</span>

<span class="s2">        y: Target data. Like the input data `x`, it could be either Numpy</span>

<span class="s2">          array(s) or TensorFlow tensor(s). It should be consistent with `x`</span>

<span class="s2">          (you cannot have Numpy inputs and tensor targets, or inversely).</span>

<span class="s2">        sample_weight: Optional array of the same length as x, containing</span>

<span class="s2">          weights to apply to the model&#39;s loss for each sample. In the case of</span>

<span class="s2">          temporal data, you can pass a 2D array with shape (samples,</span>

<span class="s2">          sequence_length), to apply a different weight to every timestep of</span>

<span class="s2">          every sample.</span>

<span class="s2">        class_weight: Optional dictionary mapping class indices (integers) to a</span>

<span class="s2">          weight (float) to apply to the model&#39;s loss for the samples from this</span>

<span class="s2">          class during training. This can be useful to tell the model to &quot;</span><span class="n">pay</span>

          <span class="n">more</span> <span class="n">attention</span><span class="s2">&quot; to samples from an under-represented class.</span>

<span class="s2">        reset_metrics: If `True`, the metrics returned will be only for this</span>

<span class="s2">          batch. If `False`, the metrics will be statefully accumulated across</span>

<span class="s2">          batches.</span>

<span class="s2">        return_dict: If `True`, loss and metric results are returned as a dict,</span>

<span class="s2">          with each key being the name of the metric. If `False`, they are</span>

<span class="s2">          returned as a list.</span>

<span class="s2">    Returns:</span>

<span class="s2">        Scalar training loss</span>

<span class="s2">        (if the model has a single output and no metrics)</span>

<span class="s2">        or list of scalars (if the model has multiple outputs</span>

<span class="s2">        and/or metrics). The attribute `model.metrics_names` will give you</span>

<span class="s2">        the display labels for the scalar outputs.</span>

<span class="s2">    Raises:</span>

<span class="s2">      RuntimeError: If `model.train_on_batch` is wrapped in `tf.function`.</span>

<span class="s2">      ValueError: In case of invalid user-provided arguments.</span>

<span class="s2">    </span><span class="se">&quot;&quot;</span><span class="s2">&quot;</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_assert_compile_was_called</span><span class="p">()</span>

    <span class="n">self</span><span class="p">.</span><span class="n">_check_call_args</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span>

    <span class="n">_disallow_inside_tf_function</span><span class="p">(</span><span class="s1">&#39;train_on_batch&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">(),</span> <span class="err">\</span>

         <span class="n">training_utils</span><span class="p">.</span><span class="n">RespectCompiledTrainableState</span><span class="p">(</span><span class="n">self</span><span class="p">)</span><span class="o">:</span>

      <span class="n">iterator</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="p">.</span><span class="n">single_batch_iterator</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>

                                                    <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span>

                                                    <span class="n">class_weight</span><span class="p">)</span>

      <span class="n">self</span><span class="p">.</span><span class="n">train_function</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">make_train_function</span><span class="p">()</span>

      <span class="k">logs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">train_function</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">reset_metrics</span><span class="o">:</span>

      <span class="n">self</span><span class="p">.</span><span class="n">reset_metrics</span><span class="p">()</span>

    <span class="k">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="p">.</span><span class="n">to_numpy_or_python_type</span><span class="p">(</span><span class="k">logs</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">return_dict</span><span class="o">:</span>

      <span class="k">return</span> <span class="k">logs</span>

    <span class="k">else</span><span class="o">:</span>

      <span class="n">results</span> <span class="o">=</span> <span class="err">[</span><span class="k">logs</span><span class="p">.</span><span class="k">get</span><span class="p">(</span><span class="k">name</span><span class="p">,</span> <span class="k">None</span><span class="p">)</span> <span class="k">for</span> <span class="k">name</span> <span class="k">in</span> <span class="n">self</span><span class="p">.</span><span class="n">metrics_names</span><span class="err">]</span>

      <span class="k">if</span> <span class="n">len</span><span class="p">(</span><span class="n">results</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="o">:</span>

        <span class="k">return</span> <span class="n">results</span><span class="err">[</span><span class="mi">0</span><span class="err">]</span>

      <span class="k">return</span> <span class="n">results</span>
</code></pre></div>

</details>
<h4 id="train_step_2">train_step</h4>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span>
<span class="p">)</span>
</code></pre></div>

<details class="example"><summary>View Source</summary><div class="codehilite"><pre><span></span><code>    <span class="n">def</span> <span class="n">train_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">expand_1d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">ground_truths</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">data_adapter</span><span class="o">.</span><span class="n">unpack_x_y_sample_weight</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="n">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>

            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">True</span><span class="p">)</span>

            <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">DatasetField</span><span class="o">.</span><span class="n">IMAGES</span><span class="p">])[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_dtype</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">ground_truths</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">)</span>

            <span class="n">loss</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compiled_loss</span><span class="p">(</span><span class="n">None</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">None</span><span class="p">,</span> <span class="n">regularization_losses</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">losses</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span> <span class="n">tape</span><span class="o">=</span><span class="n">tape</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">loss_metric</span><span class="o">.</span><span class="n">update_state</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="p">:</span> <span class="n">m</span><span class="o">.</span><span class="n">result</span><span class="p">()</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">}</span>
</code></pre></div>

</details>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../../dataset/utils/" title="Utils" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Utils
              </span>
            </div>
          </a>
        
        
          <a href="../factory/" title="Factory" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Factory
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Powered by
        <a href="http://timothycrosley.github.io/portray">portray.</a>
        You too can
        <a href="http://timothycrosley.github.io/portray">
          portray</a>
        your Python project well using automatic documentation.
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../../../assets/javascripts/vendor.2d1db4bd.min.js"></script>
      <script src="../../../../assets/javascripts/bundle.6627ddf3.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
      
      <script>
        app = initialize({
          base: "../../../..",
          features: [],
          search: Object.assign({
            worker: "../../../../assets/javascripts/worker/search.5eca75d3.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
    
  </body>
</html>